{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84d3fe20-55ed-4b91-b52a-fab6c7502f67",
   "metadata": {},
   "source": [
    "# see the situation :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6836d838-9aaf-4ef0-bdc8-5d342f683f00",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%echo` not found.\n"
     ]
    }
   ],
   "source": [
    "%echo \"Total: $(du -ch *.log | grep total)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4dba44b5-9927-4282-8a06-776a938ca24c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path                                                          Size\n",
      "-----------------------------------------------------------------\n",
      "minicpmv_o_2_6_model                               17432640217.00 MMB\n",
      "my_model                                           16211274105.00 MMB\n",
      "llama.cpp                                          253349403.00 MMB\n",
      "MiniCPM_lightning.ipynb                              292800.00 MMB\n",
      "232-modele-cv-francais.docx                          195967.00 MMB\n",
      "1131w-uHRaEYx8dVI (1).webp                           119898.00 MMB\n",
      "cv.webp                                              119898.00 MMB\n",
      "232-modele-cv-francais.pdf                           116536.00 MMB\n",
      "cv.pdf                                               116536.00 MMB\n",
      "cv2.path                                             116536.00 MMB\n",
      "cv2.pdf                                              116536.00 MMB\n",
      "promt.ipynb                                           52867.00 MMB\n",
      "nohup.out                                             37701.00 MMB\n",
      "Untitled.ipynb                                        17732.00 MMB\n",
      "trypromptingMiniCPMo26.ipynb                          14321.00 MMB\n",
      "vllm.log                                               8782.00 MMB\n",
      "upload_file.ipynb                                      7055.00 MMB\n",
      "cv_analysis_output_minicpm_o_2_6.txt                   2299.00 MMB\n",
      "requirements_MiniCPM_2_6.txt                            180.00 MMB\n",
      "requirements_MiniCPM_V_2_6.txt                           98.00 MMB\n",
      "main.py                                                  33.00 MMB\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "def get_size(path):\n",
    "    \"\"\"Calculate size of a file or directory (recursive) in bytes\"\"\"\n",
    "    if path.is_file():\n",
    "        return path.stat().st_size\n",
    "    return sum(f.stat().st_size for f in path.glob('**/*') if f.is_file())\n",
    "\n",
    "def list_sizes(target_dir='.', sort_by='size', reverse=True, human_readable=True, \n",
    "              include_hidden=False, max_depth=None, unit='auto'):\n",
    "    \"\"\"\n",
    "    List sizes of files and directories with formatting options.\n",
    "    \n",
    "    Args:\n",
    "        target_dir (str): Directory path (default: current dir)\n",
    "        sort_by (str): 'size', 'name', or 'none'\n",
    "        reverse (bool): Sort descending (default: True)\n",
    "        human_readable (bool): Format sizes (default: True)\n",
    "        include_hidden (bool): Show hidden items (default: False)\n",
    "        max_depth (int): None=recursive, 0=current dir only, 1=+1 subdir level\n",
    "        unit (str): 'auto'(smart), 'B', 'KB', 'MB', 'GB', 'TB' (forced unit)\n",
    "    \n",
    "    Returns:\n",
    "        list: [(path, size_str), ...] sorted tuples\n",
    "    \"\"\"\n",
    "    target = Path(target_dir)\n",
    "    if not target.exists():\n",
    "        raise FileNotFoundError(f\"Directory not found: {target_dir}\")\n",
    "    \n",
    "    items = []\n",
    "    for item in target.iterdir():\n",
    "        if not include_hidden and item.name.startswith('.'):\n",
    "            continue\n",
    "            \n",
    "        if max_depth is None or max_depth >= 0:\n",
    "            size = get_size(item)\n",
    "            items.append((item, size))\n",
    "    \n",
    "    # Sorting\n",
    "    if sort_by == 'size':\n",
    "        items.sort(key=lambda x: x[1], reverse=reverse)\n",
    "    elif sort_by == 'name':\n",
    "        items.sort(key=lambda x: x[0].name, reverse=reverse)\n",
    "    \n",
    "    # Formatting\n",
    "    def format_size(bytes_size):\n",
    "        if not human_readable:\n",
    "            return str(bytes_size)\n",
    "        \n",
    "        units = ['B', 'KB', 'MB', 'GB', 'TB']\n",
    "        if unit != 'auto':\n",
    "            units = [unit]\n",
    "        \n",
    "        size = float(bytes_size)\n",
    "        unit_idx = 0\n",
    "        \n",
    "        while size >= 1024 and unit_idx < len(units)-1 and units[unit_idx] != unit:\n",
    "            size /= 1024\n",
    "            unit_idx += 1\n",
    "            \n",
    "        return f\"{size:.2f} {units[unit_idx]}\".rstrip('B') + units[unit_idx]\n",
    "    \n",
    "    return [(str(item[0]), format_size(item[1])) for item in items]\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    print(f\"{'Path':<50} {'Size':>15}\")\n",
    "    print('-' * 65)\n",
    "    for path, size in list_sizes(max_depth=1, unit='MB'):\n",
    "        print(f\"{path:<50} {size:>15}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01613a4e-4ee0-4b40-8927-f935e2c0db70",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1729/3099177714.py:3: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n",
      "  import pkg_resources\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Python Environment Details\n",
      "==================================================\n",
      "Python version: 3.10.10 (main, Mar 21 2023, 18:45:11) [GCC 11.2.0]\n",
      "Python executable: /home/zeus/miniconda3/envs/cloudspace/bin/python\n",
      "Platform: Linux-6.8.0-1031-gcp-x86_64-with-glibc2.31\n",
      "\n",
      "==================================================\n",
      "PyTorch Installation Details\n",
      "==================================================\n",
      "PyTorch version: 2.7.0+cu126\n",
      "CUDA available: True\n",
      "CUDA version: 12.6\n",
      "cuDNN version: 90501\n",
      "Current device: 0\n",
      "Device name: NVIDIA L4\n",
      "\n",
      "==================================================\n",
      "Flash Attention Prerequisites\n",
      "==================================================\n",
      "CUDA Toolkit (nvcc): V12.1.105\n",
      "cuDNN headers: Found\n",
      "\n",
      "Build Tools:\n",
      "gcc: gcc (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0\n",
      "cmake: cmake version 3.16.3\n",
      "ninja: 1.11.1.git.kitware.jobserver-1\n",
      "\n",
      "==================================================\n",
      "Related Package Versions\n",
      "==================================================\n",
      "torch: 2.7.0\n",
      "torchvision: 0.22.0\n",
      "torchaudio: 2.7.0\n",
      "flash-attn: Not installed\n",
      "einops: 0.8.1\n",
      "transformers: 4.52.4\n",
      "numpy: 1.26.4\n",
      "pillow: 11.2.1\n",
      "\n",
      "==================================================\n",
      "CUDA Toolkit Components\n",
      "==================================================\n",
      "nvidia-cuda-runtime-cu12: 12.6.77\n",
      "nvidia-cudnn-cu12: 9.5.1.17\n",
      "nvidia-nccl-cu12: 2.26.2\n",
      "nvidia-cublas-cu12: 12.6.4.1\n",
      "\n",
      "==================================================\n",
      "Environment Check Complete\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "def check_pytorch_installation():\n",
    "    import torch\n",
    "    import pkg_resources\n",
    "    import sys\n",
    "    import platform\n",
    "    import subprocess\n",
    "    from typing import Optional\n",
    "\n",
    "    def run_command(cmd: str) -> Optional[str]:\n",
    "        try:\n",
    "            return subprocess.check_output(cmd, shell=True, stderr=subprocess.PIPE).decode().strip()\n",
    "        except:\n",
    "            return None\n",
    "\n",
    "    # --- Python and System Info ---\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"Python Environment Details\")\n",
    "    print(\"=\"*50)\n",
    "    print(f\"Python version: {sys.version}\")\n",
    "    print(f\"Python executable: {sys.executable}\")\n",
    "    print(f\"Platform: {platform.platform()}\")\n",
    "\n",
    "    # --- PyTorch Core Checks ---\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"PyTorch Installation Details\")\n",
    "    print(\"=\"*50)\n",
    "    print(f\"PyTorch version: {torch.__version__}\")\n",
    "    print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"CUDA version: {torch.version.cuda}\")\n",
    "        print(f\"cuDNN version: {torch.backends.cudnn.version()}\")\n",
    "        print(f\"Current device: {torch.cuda.current_device()}\")\n",
    "        print(f\"Device name: {torch.cuda.get_device_name(0)}\")\n",
    "\n",
    "    # --- Critical Flash Attention Checks ---\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"Flash Attention Prerequisites\")\n",
    "    print(\"=\"*50)\n",
    "\n",
    "    # 1. Check CUDA Toolkit (nvcc)\n",
    "    nvcc_version = run_command(\"nvcc --version | grep 'release' | awk '{print $6}'\")\n",
    "    print(f\"CUDA Toolkit (nvcc): {nvcc_version if nvcc_version else 'NOT FOUND'}\")\n",
    "\n",
    "    # 2. Check cuDNN (if CUDA is available)\n",
    "    if torch.cuda.is_available():\n",
    "        cudnn_version = run_command(\"grep -m1 CUDNN_MAJOR -A2 /usr/include/cudnn_version.h 2>/dev/null || echo 'NOT FOUND'\")\n",
    "        print(f\"cuDNN headers: {'Found' if 'CUDNN_MAJOR' in str(cudnn_version) else 'NOT FOUND'}\")\n",
    "\n",
    "    # 3. Check build tools (gcc, cmake, ninja)\n",
    "    print(\"\\nBuild Tools:\")\n",
    "    print(f\"gcc: {run_command('gcc --version | head -n1') or 'NOT FOUND'}\")\n",
    "    print(f\"cmake: {run_command('cmake --version | head -n1') or 'NOT FOUND'}\")\n",
    "    print(f\"ninja: {run_command('ninja --version') or 'NOT FOUND'}\")\n",
    "\n",
    "    # --- Package Versions ---\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"Related Package Versions\")\n",
    "    print(\"=\"*50)\n",
    "    packages = [\n",
    "        'torch', 'torchvision', 'torchaudio', \n",
    "        'flash-attn', 'einops', 'transformers',\n",
    "        'numpy', 'pillow'\n",
    "    ]\n",
    "    for pkg in packages:\n",
    "        try:\n",
    "            version = pkg_resources.get_distribution(pkg).version\n",
    "            print(f\"{pkg}: {version}\")\n",
    "        except:\n",
    "            print(f\"{pkg}: Not installed\")\n",
    "\n",
    "    # --- CUDA Toolkit Components ---\n",
    "    try:\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"CUDA Toolkit Components\")\n",
    "        print(\"=\"*50)\n",
    "        cuda_pkgs = [\n",
    "            'nvidia-cuda-runtime-cu12', 'nvidia-cudnn-cu12',\n",
    "            'nvidia-nccl-cu12', 'nvidia-cublas-cu12'\n",
    "        ]\n",
    "        for pkg in cuda_pkgs:\n",
    "            try:\n",
    "                version = pkg_resources.get_distribution(pkg).version\n",
    "                print(f\"{pkg}: {version}\")\n",
    "            except:\n",
    "                print(f\"{pkg}: Not found\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\nError checking CUDA packages: {e}\")\n",
    "\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"Environment Check Complete\")\n",
    "    print(\"=\"*50)\n",
    "\n",
    "# Run the check\n",
    "check_pytorch_installation()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e35aa34-41e2-43c1-8441-9a14392f64a4",
   "metadata": {},
   "source": [
    "## Setup :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ddcd82c-bd9f-4a8f-a1a3-9b4c0f91a68c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: modelscope in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (1.27.1)\n",
      "Requirement already satisfied: requests>=2.25 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from modelscope) (2.32.4)\n",
      "Requirement already satisfied: setuptools in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from modelscope) (78.1.1)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from modelscope) (4.67.1)\n",
      "Requirement already satisfied: urllib3>=1.26 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from modelscope) (2.4.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests>=2.25->modelscope) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests>=2.25->modelscope) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests>=2.25->modelscope) (2025.4.26)\n"
     ]
    }
   ],
   "source": [
    "#Before downloading, install ModelScope first by using the following command\n",
    "\n",
    "!pip install modelscope"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a4ce167-a248-43b0-8587-28aeceb34bc5",
   "metadata": {},
   "source": [
    "- for vllm inference ==> vllm just for PyTorch (.bin, .safetensors) not for gguf file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aae590f2-06b1-4887-b0f5-0c044a97dc62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2mUsing Python 3.10.10 environment at: /home/zeus/miniconda3/envs/cloudspace\u001b[0m\n",
      "\u001b[2mAudited \u001b[1m1 package\u001b[0m \u001b[2min 155ms\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!uv pip install vllm --torch-backend=auto"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e3fd2f-5b09-45df-bb29-555009bfdf11",
   "metadata": {},
   "source": [
    "- test model with vllm inference to see if there s a time gain "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ff217b-d269-4116-a913-2d7b334e2d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#another way aconrding to the documentation is the same as the next one\n",
    "\n",
    "!nohup vllm serve /teamspace/studios/this_studio/.cache/modelscope/hub/models/OpenBMB/MiniCPM-o-2_6 &"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59d6df5-ffeb-42d2-88ac-798e1a174ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!tail -n 30 nohup.out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6416f6d8-7152-4a6c-86b3-24d5871b459f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls /teamspace/studios/this_studio/.cache/modelscope/hub/models/OpenBMB/MiniCPM-o-2_6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "861db2ed-10e9-42a2-978d-981e36c07c8b",
   "metadata": {},
   "source": [
    "## libraries : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68f3d2bc-3784-4a32-9349-11cc61a4de26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test.py\n",
    "import torch\n",
    "from PIL import Image\n",
    "from modelscope import AutoModel, AutoTokenizer\n",
    "\n",
    "import json\n",
    "import os\n",
    "from os.path import join\n",
    "import random\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e79f2316-30c4-459d-bd63-35bfc3c533a2",
   "metadata": {},
   "source": [
    "## MiniCPM_V_2_6 :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8dd0610-bb67-448a-90cd-e494c46681c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing requirements_MiniCPM_V_2_6.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile requirements_MiniCPM_V_2_6.txt\n",
    "Pillow==10.1.0\n",
    "torch==2.1.2\n",
    "torchvision==0.16.2\n",
    "transformers==4.40.0\n",
    "sentencepiece==0.1.99\n",
    "decord\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30a8836-a29e-49e3-87b9-e0acad0d0b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements_MiniCPM_V_2_6.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5167238b-98e4-4f86-b0be-1f9951d367de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/teamspace/studios/this_studio\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ab10a2-047a-4174-a6b5-d4ed156e5916",
   "metadata": {},
   "source": [
    "## MiniCPM-o-2_6-gguf & MiniCPM-o-2_6 :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27075a97-5e68-4364-86ad-5173ee61f1d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting requirements_MiniCPM_2_6.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile requirements_MiniCPM_2_6.txt\n",
    "Pillow==10.1.0\n",
    "torch==2.3.1\n",
    "torchaudio==2.3.1\n",
    "torchvision==0.18.1\n",
    "transformers==4.44.2\n",
    "librosa==0.9.0\n",
    "soundfile==0.12.1\n",
    "vector-quantize-pytorch==1.18.5\n",
    "vocos==0.1.0\n",
    "decord\n",
    "moviepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2a9546e-72b4-44cd-a87c-3a0547dcb1f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting Pillow==10.1.0 (from -r requirements_MiniCPM_2_6.txt (line 1))\n",
      "  Downloading Pillow-10.1.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (9.5 kB)\n",
      "Collecting torch==2.3.1 (from -r requirements_MiniCPM_2_6.txt (line 2))\n",
      "  Downloading torch-2.3.1-cp310-cp310-manylinux1_x86_64.whl.metadata (26 kB)\n",
      "Collecting torchaudio==2.3.1 (from -r requirements_MiniCPM_2_6.txt (line 3))\n",
      "  Downloading torchaudio-2.3.1-cp310-cp310-manylinux1_x86_64.whl.metadata (6.4 kB)\n",
      "Collecting torchvision==0.18.1 (from -r requirements_MiniCPM_2_6.txt (line 4))\n",
      "  Downloading torchvision-0.18.1-cp310-cp310-manylinux1_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting transformers==4.44.2 (from -r requirements_MiniCPM_2_6.txt (line 5))\n",
      "  Downloading transformers-4.44.2-py3-none-any.whl.metadata (43 kB)\n",
      "Requirement already satisfied: librosa==0.9.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from -r requirements_MiniCPM_2_6.txt (line 6)) (0.9.0)\n",
      "Requirement already satisfied: soundfile==0.12.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from -r requirements_MiniCPM_2_6.txt (line 7)) (0.12.1)\n",
      "Requirement already satisfied: vector-quantize-pytorch==1.18.5 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from -r requirements_MiniCPM_2_6.txt (line 8)) (1.18.5)\n",
      "Requirement already satisfied: vocos==0.1.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from -r requirements_MiniCPM_2_6.txt (line 9)) (0.1.0)\n",
      "Requirement already satisfied: decord in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from -r requirements_MiniCPM_2_6.txt (line 10)) (0.6.0)\n",
      "Requirement already satisfied: moviepy in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from -r requirements_MiniCPM_2_6.txt (line 11)) (2.2.1)\n",
      "Requirement already satisfied: filelock in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch==2.3.1->-r requirements_MiniCPM_2_6.txt (line 2)) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch==2.3.1->-r requirements_MiniCPM_2_6.txt (line 2)) (4.14.0)\n",
      "Requirement already satisfied: sympy in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch==2.3.1->-r requirements_MiniCPM_2_6.txt (line 2)) (1.14.0)\n",
      "Requirement already satisfied: networkx in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch==2.3.1->-r requirements_MiniCPM_2_6.txt (line 2)) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch==2.3.1->-r requirements_MiniCPM_2_6.txt (line 2)) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch==2.3.1->-r requirements_MiniCPM_2_6.txt (line 2)) (2025.5.1)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.3.1->-r requirements_MiniCPM_2_6.txt (line 2))\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.3.1->-r requirements_MiniCPM_2_6.txt (line 2))\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.3.1->-r requirements_MiniCPM_2_6.txt (line 2))\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.3.1->-r requirements_MiniCPM_2_6.txt (line 2))\n",
      "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.3.1->-r requirements_MiniCPM_2_6.txt (line 2))\n",
      "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.3.1->-r requirements_MiniCPM_2_6.txt (line 2))\n",
      "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.2.106 (from torch==2.3.1->-r requirements_MiniCPM_2_6.txt (line 2))\n",
      "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.3.1->-r requirements_MiniCPM_2_6.txt (line 2))\n",
      "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.3.1->-r requirements_MiniCPM_2_6.txt (line 2))\n",
      "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-nccl-cu12==2.20.5 (from torch==2.3.1->-r requirements_MiniCPM_2_6.txt (line 2))\n",
      "  Downloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.1.105 (from torch==2.3.1->-r requirements_MiniCPM_2_6.txt (line 2))\n",
      "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting triton==2.3.1 (from torch==2.3.1->-r requirements_MiniCPM_2_6.txt (line 2))\n",
      "  Downloading triton-2.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: numpy in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torchvision==0.18.1->-r requirements_MiniCPM_2_6.txt (line 4)) (1.26.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers==4.44.2->-r requirements_MiniCPM_2_6.txt (line 5)) (0.33.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers==4.44.2->-r requirements_MiniCPM_2_6.txt (line 5)) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers==4.44.2->-r requirements_MiniCPM_2_6.txt (line 5)) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers==4.44.2->-r requirements_MiniCPM_2_6.txt (line 5)) (2024.11.6)\n",
      "Requirement already satisfied: requests in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers==4.44.2->-r requirements_MiniCPM_2_6.txt (line 5)) (2.32.4)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers==4.44.2->-r requirements_MiniCPM_2_6.txt (line 5)) (0.5.3)\n",
      "Collecting tokenizers<0.20,>=0.19 (from transformers==4.44.2->-r requirements_MiniCPM_2_6.txt (line 5))\n",
      "  Downloading tokenizers-0.19.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers==4.44.2->-r requirements_MiniCPM_2_6.txt (line 5)) (4.67.1)\n",
      "Requirement already satisfied: audioread>=2.1.5 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from librosa==0.9.0->-r requirements_MiniCPM_2_6.txt (line 6)) (3.0.1)\n",
      "Requirement already satisfied: scipy>=1.2.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from librosa==0.9.0->-r requirements_MiniCPM_2_6.txt (line 6)) (1.11.4)\n",
      "Requirement already satisfied: scikit-learn>=0.19.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from librosa==0.9.0->-r requirements_MiniCPM_2_6.txt (line 6)) (1.3.2)\n",
      "Requirement already satisfied: joblib>=0.14 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from librosa==0.9.0->-r requirements_MiniCPM_2_6.txt (line 6)) (1.5.1)\n",
      "Requirement already satisfied: decorator>=4.0.10 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from librosa==0.9.0->-r requirements_MiniCPM_2_6.txt (line 6)) (5.2.1)\n",
      "Requirement already satisfied: resampy>=0.2.2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from librosa==0.9.0->-r requirements_MiniCPM_2_6.txt (line 6)) (0.4.3)\n",
      "Requirement already satisfied: numba>=0.45.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from librosa==0.9.0->-r requirements_MiniCPM_2_6.txt (line 6)) (0.61.2)\n",
      "Requirement already satisfied: pooch>=1.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from librosa==0.9.0->-r requirements_MiniCPM_2_6.txt (line 6)) (1.8.2)\n",
      "Requirement already satisfied: cffi>=1.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from soundfile==0.12.1->-r requirements_MiniCPM_2_6.txt (line 7)) (1.17.1)\n",
      "Requirement already satisfied: einops>=0.8.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from vector-quantize-pytorch==1.18.5->-r requirements_MiniCPM_2_6.txt (line 8)) (0.8.1)\n",
      "Requirement already satisfied: einx>=0.3.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from vector-quantize-pytorch==1.18.5->-r requirements_MiniCPM_2_6.txt (line 8)) (0.3.0)\n",
      "Requirement already satisfied: encodec==0.1.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from vocos==0.1.0->-r requirements_MiniCPM_2_6.txt (line 9)) (0.1.1)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.3.1->-r requirements_MiniCPM_2_6.txt (line 2)) (12.6.85)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.44.2->-r requirements_MiniCPM_2_6.txt (line 5)) (1.1.5)\n",
      "Requirement already satisfied: imageio<3.0,>=2.5 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from moviepy->-r requirements_MiniCPM_2_6.txt (line 11)) (2.37.0)\n",
      "Requirement already satisfied: imageio_ffmpeg>=0.2.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from moviepy->-r requirements_MiniCPM_2_6.txt (line 11)) (0.6.0)\n",
      "Requirement already satisfied: proglog<=1.0.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from moviepy->-r requirements_MiniCPM_2_6.txt (line 11)) (0.1.12)\n",
      "Requirement already satisfied: python-dotenv>=0.10 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from moviepy->-r requirements_MiniCPM_2_6.txt (line 11)) (1.1.0)\n",
      "Requirement already satisfied: pycparser in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from cffi>=1.0->soundfile==0.12.1->-r requirements_MiniCPM_2_6.txt (line 7)) (2.22)\n",
      "Requirement already satisfied: frozendict in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from einx>=0.3.0->vector-quantize-pytorch==1.18.5->-r requirements_MiniCPM_2_6.txt (line 8)) (2.4.6)\n",
      "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from numba>=0.45.1->librosa==0.9.0->-r requirements_MiniCPM_2_6.txt (line 6)) (0.44.0)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from pooch>=1.0->librosa==0.9.0->-r requirements_MiniCPM_2_6.txt (line 6)) (4.3.8)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests->transformers==4.44.2->-r requirements_MiniCPM_2_6.txt (line 5)) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests->transformers==4.44.2->-r requirements_MiniCPM_2_6.txt (line 5)) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests->transformers==4.44.2->-r requirements_MiniCPM_2_6.txt (line 5)) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests->transformers==4.44.2->-r requirements_MiniCPM_2_6.txt (line 5)) (2025.4.26)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from scikit-learn>=0.19.1->librosa==0.9.0->-r requirements_MiniCPM_2_6.txt (line 6)) (3.6.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from jinja2->torch==2.3.1->-r requirements_MiniCPM_2_6.txt (line 2)) (3.0.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from sympy->torch==2.3.1->-r requirements_MiniCPM_2_6.txt (line 2)) (1.3.0)\n",
      "Downloading Pillow-10.1.0-cp310-cp310-manylinux_2_28_x86_64.whl (3.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m73.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading torch-2.3.1-cp310-cp310-manylinux1_x86_64.whl (779.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m779.1/779.1 MB\u001b[0m \u001b[31m70.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading torchaudio-2.3.1-cp310-cp310-manylinux1_x86_64.whl (3.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m83.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading torchvision-0.18.1-cp310-cp310-manylinux1_x86_64.whl (7.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m179.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading transformers-4.44.2-py3-none-any.whl (9.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m137.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m90.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m112.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m115.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m53.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m52.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m107.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m115.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m95.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m46.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.2/176.2 MB\u001b[0m \u001b[31m105.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
      "Downloading triton-2.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (168.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.1/168.1 MB\u001b[0m \u001b[31m115.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.19.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m136.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: triton, Pillow, nvidia-nvtx-cu12, nvidia-nccl-cu12, nvidia-cusparse-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusolver-cu12, nvidia-cudnn-cu12, torch, tokenizers, transformers, torchvision, torchaudio\n",
      "\u001b[2K  Attempting uninstall: triton\n",
      "\u001b[2K    Found existing installation: triton 3.3.0\n",
      "\u001b[2K    Uninstalling triton-3.3.0:\n",
      "\u001b[2K      Successfully uninstalled triton-3.3.0\n",
      "\u001b[2K  Attempting uninstall: Pillow━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 0/18\u001b[0m [triton]\n",
      "\u001b[2K    Found existing installation: pillow 11.2.10m \u001b[32m 0/18\u001b[0m [triton]\n",
      "\u001b[2K    Uninstalling pillow-11.2.1:━━━━━━━━━━━━━\u001b[0m \u001b[32m 0/18\u001b[0m [triton]\n",
      "\u001b[2K      Successfully uninstalled pillow-11.2.1\u001b[0m \u001b[32m 0/18\u001b[0m [triton]\n",
      "\u001b[2K  Attempting uninstall: nvidia-nvtx-cu12━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 1/18\u001b[0m [Pillow]\n",
      "\u001b[2K    Found existing installation: nvidia-nvtx-cu12 12.6.77━━━━━\u001b[0m \u001b[32m 1/18\u001b[0m [Pillow]\n",
      "\u001b[2K    Uninstalling nvidia-nvtx-cu12-12.6.77:━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 1/18\u001b[0m [Pillow]\n",
      "\u001b[2K      Successfully uninstalled nvidia-nvtx-cu12-12.6.77━━━━━━━\u001b[0m \u001b[32m 1/18\u001b[0m [Pillow]\n",
      "\u001b[2K  Attempting uninstall: nvidia-nccl-cu12━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 1/18\u001b[0m [Pillow]\n",
      "\u001b[2K    Found existing installation: nvidia-nccl-cu12 2.26.2━━━━━━\u001b[0m \u001b[32m 1/18\u001b[0m [Pillow]\n",
      "\u001b[2K    Uninstalling nvidia-nccl-cu12-2.26.2:━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 1/18\u001b[0m [Pillow]\n",
      "\u001b[2K      Successfully uninstalled nvidia-nccl-cu12-2.26.2━━━━━━━━\u001b[0m \u001b[32m 1/18\u001b[0m [Pillow]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cusparse-cu12━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 3/18\u001b[0m [nvidia-nccl-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cusparse-cu12 12.5.4.2\u001b[0m \u001b[32m 3/18\u001b[0m [nvidia-nccl-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cusparse-cu12-12.5.4.2:━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 3/18\u001b[0m [nvidia-nccl-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cusparse-cu12-12.5.4.2━━\u001b[0m \u001b[32m 3/18\u001b[0m [nvidia-nccl-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-curand-cu12━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 4/18\u001b[0m [nvidia-cusparse-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-curand-cu12 10.3.7.77━\u001b[0m \u001b[32m 4/18\u001b[0m [nvidia-cusparse-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-curand-cu12-10.3.7.77:━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 4/18\u001b[0m [nvidia-cusparse-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-curand-cu12-10.3.7.77━━━\u001b[0m \u001b[32m 4/18\u001b[0m [nvidia-cusparse-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cufft-cu12━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 5/18\u001b[0m [nvidia-curand-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cufft-cu12 11.3.0.4━━━\u001b[0m \u001b[32m 5/18\u001b[0m [nvidia-curand-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cufft-cu12-11.3.0.4:━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 5/18\u001b[0m [nvidia-curand-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cufft-cu12-11.3.0.4━━━━━\u001b[0m \u001b[32m 5/18\u001b[0m [nvidia-curand-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cuda-runtime-cu12━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 6/18\u001b[0m [nvidia-cufft-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cuda-runtime-cu12 12.6.77m \u001b[32m 6/18\u001b[0m [nvidia-cufft-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cuda-runtime-cu12-12.6.77:━━━━━━━━━━━━\u001b[0m \u001b[32m 6/18\u001b[0m [nvidia-cufft-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cuda-runtime-cu12-12.6.77━━━\u001b[0m \u001b[32m 7/18\u001b[0m [nvidia-cuda-runtime-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cuda-nvrtc-cu12━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 7/18\u001b[0m [nvidia-cuda-runtime-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cuda-nvrtc-cu12 12.6.77[0m \u001b[32m 7/18\u001b[0m [nvidia-cuda-runtime-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cuda-nvrtc-cu12-12.6.77:━━━━━━━━━━━━━━\u001b[0m \u001b[32m 7/18\u001b[0m [nvidia-cuda-runtime-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.6.77━\u001b[0m \u001b[32m 7/18\u001b[0m [nvidia-cuda-runtime-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cuda-cupti-cu12━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 8/18\u001b[0m [nvidia-cuda-nvrtc-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cuda-cupti-cu12 12.6.80[0m \u001b[32m 8/18\u001b[0m [nvidia-cuda-nvrtc-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cuda-cupti-cu12-12.6.80:━━━━━━━━━━━━━━\u001b[0m \u001b[32m 8/18\u001b[0m [nvidia-cuda-nvrtc-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cuda-cupti-cu12-12.6.80━\u001b[0m \u001b[32m 8/18\u001b[0m [nvidia-cuda-nvrtc-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cublas-cu12\u001b[90m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 9/18\u001b[0m [nvidia-cuda-cupti-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cublas-cu12 12.6.4.1━━\u001b[0m \u001b[32m 9/18\u001b[0m [nvidia-cuda-cupti-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cublas-cu12-12.6.4.1:━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 9/18\u001b[0m [nvidia-cuda-cupti-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cublas-cu12-12.6.4.1━━━━\u001b[0m \u001b[32m 9/18\u001b[0m [nvidia-cuda-cupti-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cusolver-cu12\u001b[90m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10/18\u001b[0m [nvidia-cublas-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cusolver-cu12 11.7.1.2\u001b[0m \u001b[32m10/18\u001b[0m [nvidia-cublas-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cusolver-cu12-11.7.1.2:━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10/18\u001b[0m [nvidia-cublas-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cusolver-cu12-11.7.1.2━━\u001b[0m \u001b[32m10/18\u001b[0m [nvidia-cublas-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cudnn-cu12╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11/18\u001b[0m [nvidia-cusolver-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cudnn-cu12 9.5.1.17━━━\u001b[0m \u001b[32m11/18\u001b[0m [nvidia-cusolver-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cudnn-cu12-9.5.1.17:90m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11/18\u001b[0m [nvidia-cusolver-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cudnn-cu12-9.5.1.17━━━━━\u001b[0m \u001b[32m11/18\u001b[0m [nvidia-cusolver-cu12]\n",
      "\u001b[2K  Attempting uninstall: torch━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━\u001b[0m \u001b[32m12/18\u001b[0m [nvidia-cudnn-cu12]\n",
      "\u001b[2K    Found existing installation: torch 2.7.0\u001b[90m━━━━━━━━━━━━━\u001b[0m \u001b[32m12/18\u001b[0m [nvidia-cudnn-cu12]\n",
      "\u001b[2K    Uninstalling torch-2.7.0:━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m13/18\u001b[0m [torch]nn-cu12]\n",
      "\u001b[2K      Successfully uninstalled torch-2.7.091m╸\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m13/18\u001b[0m [torch]\n",
      "\u001b[2K  Attempting uninstall: tokenizers━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m13/18\u001b[0m [torch]\n",
      "\u001b[2K    Found existing installation: tokenizers 0.21.2m━━━━━━━━━━━\u001b[0m \u001b[32m13/18\u001b[0m [torch]\n",
      "\u001b[2K    Uninstalling tokenizers-0.21.2:m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m13/18\u001b[0m [torch]\n",
      "\u001b[2K      Successfully uninstalled tokenizers-0.21.290m━━━━━━━━━━━\u001b[0m \u001b[32m13/18\u001b[0m [torch]\n",
      "\u001b[2K  Attempting uninstall: transformers\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m13/18\u001b[0m [torch]\n",
      "\u001b[2K    Found existing installation: transformers 4.52.4━━━━━━━━━━\u001b[0m \u001b[32m13/18\u001b[0m [torch]\n",
      "\u001b[2K    Uninstalling transformers-4.52.4:━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━\u001b[0m \u001b[32m15/18\u001b[0m [transformers]\n",
      "\u001b[2K      Successfully uninstalled transformers-4.52.4m\u001b[90m━━━━━━\u001b[0m \u001b[32m15/18\u001b[0m [transformers]\n",
      "\u001b[2K  Attempting uninstall: torchvision━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━\u001b[0m \u001b[32m15/18\u001b[0m [transformers]\n",
      "\u001b[2K    Found existing installation: torchvision 0.22.0\u001b[90m━━━━━━\u001b[0m \u001b[32m15/18\u001b[0m [transformers]\n",
      "\u001b[2K    Uninstalling torchvision-0.22.0:━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━\u001b[0m \u001b[32m15/18\u001b[0m [transformers]\n",
      "\u001b[2K      Successfully uninstalled torchvision-0.22.00m\u001b[90m━━━━━━\u001b[0m \u001b[32m15/18\u001b[0m [transformers]\n",
      "\u001b[2K  Attempting uninstall: torchaudio━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━\u001b[0m \u001b[32m16/18\u001b[0m [torchvision]\n",
      "\u001b[2K    Found existing installation: torchaudio 2.7.0\u001b[0m\u001b[90m━━━━\u001b[0m \u001b[32m16/18\u001b[0m [torchvision]\n",
      "\u001b[2K    Uninstalling torchaudio-2.7.0:━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━\u001b[0m \u001b[32m16/18\u001b[0m [torchvision]\n",
      "\u001b[2K      Successfully uninstalled torchaudio-2.7.0m╸\u001b[0m\u001b[90m━━━━\u001b[0m \u001b[32m16/18\u001b[0m [torchvision]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18/18\u001b[0m [torchaudio]8\u001b[0m [torchaudio]\n",
      "\u001b[1A\u001b[2K\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "mistral-common 1.6.2 requires pillow>=10.3.0, but you have pillow 10.1.0 which is incompatible.\n",
      "vllm 0.9.1 requires tokenizers>=0.21.1, but you have tokenizers 0.19.1 which is incompatible.\n",
      "vllm 0.9.1 requires torch==2.7.0, but you have torch 2.3.1 which is incompatible.\n",
      "vllm 0.9.1 requires torchaudio==2.7.0, but you have torchaudio 2.3.1 which is incompatible.\n",
      "vllm 0.9.1 requires torchvision==0.22.0, but you have torchvision 0.18.1 which is incompatible.\n",
      "vllm 0.9.1 requires transformers>=4.51.1, but you have transformers 4.44.2 which is incompatible.\n",
      "xformers 0.0.30 requires torch==2.7.0, but you have torch 2.3.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed Pillow-10.1.0 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvtx-cu12-12.1.105 tokenizers-0.19.1 torch-2.3.1 torchaudio-2.3.1 torchvision-0.18.1 transformers-4.44.2 triton-2.3.1\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements_MiniCPM_2_6.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "671bd9ce-9001-4391-9d41-f64d57a0bb77",
   "metadata": {},
   "source": [
    "# Download Model :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d9c340-3ff8-4168-96e1-4fe673417718",
   "metadata": {},
   "source": [
    "## MiniCPM-V-2_6 :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ae76fe-24ad-40f6-b1e9-fbc9f238b283",
   "metadata": {},
   "outputs": [],
   "source": [
    "!modelscope download --model OpenBMB/MiniCPM-V-2_6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c025fe50-016b-441d-8d59-28e5ebe55f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "!modelscope download --model OpenBMB/MiniCPM-V-2_6 --local_dir ./minicpmv_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0e291036-3e71-49c6-b916-13073f2b2108",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Model from https://www.modelscope.cn to directory: /teamspace/studios/this_studio/.cache/modelscope/hub/models/OpenBMB/MiniCPM-V-2_6\n"
     ]
    }
   ],
   "source": [
    "#Model Download\n",
    "from modelscope import snapshot_download\n",
    "model_dir = snapshot_download('OpenBMB/MiniCPM-V-2_6')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "991cf523-74ed-409a-9322-4aa5dcb3b9e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/teamspace/studios/this_studio/.cache/modelscope/hub/models/OpenBMB/MiniCPM-V-2_6'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "514afec1-b1db-42b8-87b8-6429d42e2c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mv '/teamspace/studios/this_studio/.cache/modelscope/hub/models/OpenBMB/MiniCPM-V-2_6' '/teamspace/studios/this_studio/my_model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b7e0c6-962f-471b-be00-b57931a01867",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daba04b4-742f-4b5f-a755-fd3b04187f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the full model repo\n",
    "\n",
    "!modelscope download --model OpenBMB/MiniCPM-V-2_6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "161f23cf-71f5-45ac-86da-2548b8906212",
   "metadata": {},
   "source": [
    "## MiniCPM-o-2_6-gguf :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6eae09b-1735-4bfe-8108-f49926993b6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " _   .-')                _ .-') _     ('-.             .-')                              _ (`-.    ('-.\n",
      "( '.( OO )_             ( (  OO) )  _(  OO)           ( OO ).                           ( (OO  ) _(  OO)\n",
      " ,--.   ,--.).-'),-----. \\     .'_ (,------.,--.     (_)---\\_)   .-----.  .-'),-----.  _.`     \\(,------.\n",
      " |   `.'   |( OO'  .-.  ',`'--..._) |  .---'|  |.-') /    _ |   '  .--./ ( OO'  .-.  '(__...--'' |  .---'\n",
      " |         |/   |  | |  ||  |  \\  ' |  |    |  | OO )\\  :` `.   |  |('-. /   |  | |  | |  /  | | |  |\n",
      " |  |'.'|  |\\_) |  |\\|  ||  |   ' |(|  '--. |  |`-' | '..`''.) /_) |OO  )\\_) |  |\\|  | |  |_.' |(|  '--.\n",
      " |  |   |  |  \\ |  | |  ||  |   / : |  .--'(|  '---.'.-._)   \\ ||  |`-'|   \\ |  | |  | |  .___.' |  .--'\n",
      " |  |   |  |   `'  '-'  '|  '--'  / |  `---.|      | \\       /(_'  '--'\\    `'  '-'  ' |  |      |  `---.\n",
      " `--'   `--'     `-----' `-------'  `------'`------'  `-----'    `-----'      `-----'  `--'      `------'\n",
      "\n",
      "Downloading Model from https://www.modelscope.cn to directory: /teamspace/studios/this_studio/.cache/modelscope/hub/models/OpenBMB/MiniCPM-o-2_6-gguf\n",
      "\n",
      "Successfully Downloaded from model OpenBMB/MiniCPM-o-2_6-gguf.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!modelscope download --model OpenBMB/MiniCPM-o-2_6-gguf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "875434b3-a817-48b4-a4f9-92eecc0e60c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model-7.6B-F16.gguf\tModel-7.6B-Q5_0.gguf\tREADME.md\n",
      "Model-7.6B-Q4_0.gguf\tModel-7.6B-Q5_1.gguf\tconfiguration.json\n",
      "Model-7.6B-Q4_1.gguf\tModel-7.6B-Q5_K_M.gguf\tmmproj-model-f16.gguf\n",
      "Model-7.6B-Q4_K_M.gguf\tModel-7.6B-Q6_K.gguf\n",
      "Model-7.6B-Q4_K_S.gguf\tModel-7.6B-Q8_0.gguf\n"
     ]
    }
   ],
   "source": [
    "!ls /teamspace/studios/this_studio/.cache/modelscope/hub/models/OpenBMB/MiniCPM-o-2_6-gguf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ed7233-9531-410e-a67b-cdd7b1318a5c",
   "metadata": {},
   "source": [
    "## MiniCPM-o-2_6 :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8273aafb-0c3b-482d-b83c-61ab92e18121",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " _   .-')                _ .-') _     ('-.             .-')                              _ (`-.    ('-.\n",
      "( '.( OO )_             ( (  OO) )  _(  OO)           ( OO ).                           ( (OO  ) _(  OO)\n",
      " ,--.   ,--.).-'),-----. \\     .'_ (,------.,--.     (_)---\\_)   .-----.  .-'),-----.  _.`     \\(,------.\n",
      " |   `.'   |( OO'  .-.  ',`'--..._) |  .---'|  |.-') /    _ |   '  .--./ ( OO'  .-.  '(__...--'' |  .---'\n",
      " |         |/   |  | |  ||  |  \\  ' |  |    |  | OO )\\  :` `.   |  |('-. /   |  | |  | |  /  | | |  |\n",
      " |  |'.'|  |\\_) |  |\\|  ||  |   ' |(|  '--. |  |`-' | '..`''.) /_) |OO  )\\_) |  |\\|  | |  |_.' |(|  '--.\n",
      " |  |   |  |  \\ |  | |  ||  |   / : |  .--'(|  '---.'.-._)   \\ ||  |`-'|   \\ |  | |  | |  .___.' |  .--'\n",
      " |  |   |  |   `'  '-'  '|  '--'  / |  `---.|      | \\       /(_'  '--'\\    `'  '-'  ' |  |      |  `---.\n",
      " `--'   `--'     `-----' `-------'  `------'`------'  `-----'    `-----'      `-----'  `--'      `------'\n",
      "\n",
      "Downloading Model from https://www.modelscope.cn to directory: /teamspace/studios/this_studio/minicpmv_o_2_6_model\n",
      "Processing 40 items:   0%|                          | 0.00/40.0 [00:00<?, ?it/s]\n",
      "Downloading [added_tokens.json]:   0%|              | 0.00/1.37k [00:00<?, ?B/s]\u001b[A\n",
      "\n",
      "Downloading [assets/input_examples/assistant_default_female_voice.wav]:   0%| | \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading [assets/input_examples/assistant_male_voice.wav]:   0%| | 0.00/141k \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [assets/input_examples/assistant_female_voice.wav]:   0%| | 0.00/230\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [assets/input_examples/audio_understanding.mp3]:   0%| | 0.00/314k [\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [config.json]:   0%|                    | 0.00/3.36k [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [assets/input_examples/chi-english-1.wav]:   0%| | 0.00/481k [00:00<\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [configuration.json]:   0%|              | 0.00/43.0 [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [configuration.json]: 100%|███████| 43.0/43.0 [00:00<00:00, 51.3B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Processing 40 items:   2%|▍                  | 1.00/40.0 [00:00<00:33, 1.17it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [configuration_minicpm.py]:   0%|       | 0.00/7.38k [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [added_tokens.json]: 100%|█████| 1.37k/1.37k [00:00<00:00, 1.45kB/s]\u001b[A\n",
      "Processing 40 items:   5%|▉                  | 2.00/40.0 [00:00<00:16, 2.37it/s]\n",
      "Downloading [assets/input_examples/cxk_original.wav]:   0%| | 0.00/375k [00:00<?\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [config.json]: 100%|███████████| 3.36k/3.36k [00:01<00:00, 3.33kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [assets/demo.wav]:   0%|                | 0.00/1.39M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [assets/input_examples/assistant_female_voice.wav]: 100%|█| 230k/230\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Processing 40 items:  10%|█▉                 | 4.00/40.0 [00:01<00:07, 5.02it/s]\n",
      "\n",
      "\n",
      "\n",
      "Downloading [assets/input_examples/exciting-emotion.wav]:   0%| | 0.00/680k [00:\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [assets/input_examples/audio_understanding.mp3]: 100%|█| 314k/314k [\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [assets/input_examples/fast-pace.wav]:   0%| | 0.00/963k [00:00<?, ?\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Downloading [assets/input_examples/assistant_default_female_voice.wav]: 100%|█| \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading [assets/input_examples/icl_20.wav]:   0%| | 0.00/604k [00:00<?, ?B/s\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading [assets/input_examples/assistant_male_voice.wav]: 100%|█| 141k/141k \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Processing 40 items:  18%|███▎               | 7.00/40.0 [00:01<00:03, 9.60it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [assets/input_examples/chi-english-1.wav]: 100%|█| 481k/481k [00:01<\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [assets/input_examples/indian-accent.wav]:   0%| | 0.00/1.34M [00:00\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [configuration_minicpm.py]: 100%|█| 7.38k/7.38k [00:00<00:00, 8.39kB\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Processing 40 items:  22%|████▎              | 9.00/40.0 [00:01<00:05, 6.08it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading [image_processing_minicpmv.py]: 100%|█| 16.3k/16.3k [00:00<00:00, 19\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00001-of-00004.safetensors]:   0%| | 0.00/4.54G [00:00<?, ?B/\u001b[A\u001b[A\u001b[A\n",
      "Downloading [assets/input_examples/cxk_original.wav]: 100%|█| 375k/375k [00:01<0\u001b[A\n",
      "\n",
      "Processing 40 items:  28%|█████▏             | 11.0/40.0 [00:02<00:05, 5.58it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [assets/demo.wav]: 100%|███████| 1.39M/1.39M [00:01<00:00, 1.24MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   0%| | 0.00/4.03G [00:00<?, ?B/\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [assets/input_examples/exciting-emotion.wav]: 100%|█| 680k/680k [00:\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:   0%| | 0.00/2.99G [00:00<?, ?B/\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Downloading [assets/input_examples/icl_20.wav]: 100%|█| 604k/604k [00:01<00:00, \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Processing 40 items:  35%|██████▋            | 14.0/40.0 [00:02<00:03, 7.35it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [assets/input_examples/fast-pace.wav]: 100%|█| 963k/963k [00:01<00:0\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [modeling_minicpmo.py]:   0%|            | 0.00/137k [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [assets/input_examples/indian-accent.wav]: 100%|█| 1.34M/1.34M [00:0\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Processing 40 items:  40%|███████▌           | 16.0/40.0 [00:02<00:02, 8.57it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [modeling_navit_siglip.py]:   0%|       | 0.00/41.1k [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [merges.txt]:   0%|            | 3.80k/1.59M [00:01<08:57, 3.10kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [merges.txt]:  10%|█▍            | 164k/1.59M [00:01<00:09, 166kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [merges.txt]:  35%|████▉         | 576k/1.59M [00:01<00:01, 650kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading [merges.txt]: 100%|████████████| 1.59M/1.59M [00:01<00:00, 1.07MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading [model.safetensors.index.json]:   3%| | 3.80k/130k [00:00<00:30, 4.2\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [preprocessor_config.json]:   0%|         | 0.00/714 [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model.safetensors.index.json]: 100%|█| 130k/130k [00:00<00:00, 139k\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Processing 40 items:  45%|████████▌          | 18.0/40.0 [00:03<00:04, 4.95it/s]\n",
      "\n",
      "Downloading [modeling_minicpmo.py]: 100%|█████| 137k/137k [00:00<00:00, 159kB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [README.md]:   0%|                      | 0.00/49.2k [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading [model-00001-of-00004.safetensors]:   0%| | 6.00M/4.54G [00:01<13:03\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [modeling_navit_siglip.py]:   9%| | 3.81k/41.1k [00:00<00:09, 4.06kB\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading [modeling_navit_siglip.py]: 100%|█| 41.1k/41.1k [00:01<00:00, 41.9kB\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Processing 40 items:  50%|█████████▌         | 20.0/40.0 [00:03<00:03, 5.89it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   0%| | 1.00M/4.03G [00:01<1:32:\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:   0%| | 1.00M/2.99G [00:01<1:08:\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading [model-00001-of-00004.safetensors]:   0%| | 18.0M/4.54G [00:01<03:59\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   0%| | 6.00M/4.03G [00:01<12:53\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:   0%| | 7.00M/2.99G [00:01<08:03\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading [model-00001-of-00004.safetensors]:   1%| | 24.0M/4.54G [00:01<03:01\u001b[A\u001b[A\u001b[A\n",
      "Downloading [model-00002-of-00004.safetensors]:   0%| | 1.00M/4.59G [00:01<2:06:\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:   0%| | 14.0M/2.99G [00:01<03:40\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading [model-00001-of-00004.safetensors]:   1%| | 31.0M/4.54G [00:01<02:17\u001b[A\u001b[A\u001b[A\n",
      "Downloading [model-00002-of-00004.safetensors]:   0%| | 7.00M/4.59G [00:01<14:36\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   0%| | 9.00M/4.03G [00:01<09:44\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:   1%| | 19.0M/2.99G [00:01<02:51\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [model-00002-of-00004.safetensors]:   0%| | 10.0M/4.59G [00:01<10:14\u001b[A\n",
      "\n",
      "\n",
      "Downloading [model-00001-of-00004.safetensors]:   1%| | 37.0M/4.54G [00:01<02:13\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   0%| | 12.0M/4.03G [00:01<07:09\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [model-00002-of-00004.safetensors]:   0%| | 15.0M/4.59G [00:01<06:08\u001b[A\n",
      "\n",
      "Downloading [processing_minicpmo.py]: 100%|█| 19.5k/19.5k [00:00<00:00, 24.4kB/s\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Processing 40 items:  52%|█████████▉         | 21.0/40.0 [00:04<00:04, 3.99it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   0%| | 15.0M/4.03G [00:01<05:36\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading [model-00001-of-00004.safetensors]:   1%| | 42.0M/4.54G [00:02<02:24\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:   1%| | 24.0M/2.99G [00:02<02:55\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [model-00002-of-00004.safetensors]:   0%| | 20.0M/4.59G [00:02<04:25\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   0%| | 18.0M/4.03G [00:02<04:57\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [README.md]: 100%|█████████████| 49.2k/49.2k [00:00<00:00, 52.2kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Processing 40 items:  55%|██████████▍        | 22.0/40.0 [00:04<00:04, 4.24it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [assets/chattts_tokenizer/special_tokens_map.json]:   0%| | 0.00/7.6\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [preprocessor_config.json]: 100%|████| 714/714 [00:01<00:00, 681B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [special_tokens_map.json]:   0%|        | 0.00/5.23k [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [model-00002-of-00004.safetensors]:   1%| | 24.0M/4.59G [00:02<03:48\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:   1%| | 28.0M/2.99G [00:02<02:42\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading [model-00001-of-00004.safetensors]:   1%| | 47.0M/4.54G [00:02<02:38\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   1%| | 22.0M/4.03G [00:02<03:54\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [resampler.py]:  11%|█         | 3.81k/34.8k [00:00<00:07, 4.09kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [resampler.py]: 100%|██████████| 34.8k/34.8k [00:00<00:00, 35.8kB/s]\u001b[A\n",
      "Processing 40 items:  60%|███████████▍       | 24.0/40.0 [00:04<00:02, 5.44it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [tokenization_minicpmo_fast.py]:   0%|  | 0.00/2.97k [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:   1%| | 31.0M/2.99G [00:02<02:31\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   1%| | 26.0M/4.03G [00:02<03:18\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [model-00002-of-00004.safetensors]:   1%| | 33.0M/4.59G [00:02<02:50\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:   1%| | 36.0M/2.99G [00:02<02:03\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   1%| | 30.0M/4.03G [00:02<02:54\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [model-00002-of-00004.safetensors]:   1%| | 38.0M/4.59G [00:02<02:32\u001b[A\n",
      "\n",
      "\n",
      "Downloading [model-00001-of-00004.safetensors]:   1%| | 51.0M/4.54G [00:02<03:34\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:   1%| | 41.0M/2.99G [00:02<01:47\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   1%| | 33.0M/4.03G [00:02<02:55\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [model-00002-of-00004.safetensors]:   1%| | 43.0M/4.59G [00:02<02:21\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:   2%| | 46.0M/2.99G [00:02<01:38\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [model-00002-of-00004.safetensors]:   1%| | 48.0M/4.59G [00:02<02:11\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   1%| | 36.0M/4.03G [00:02<03:03\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:   2%| | 50.0M/2.99G [00:02<01:34\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading [model-00001-of-00004.safetensors]:   1%| | 54.0M/4.54G [00:02<04:21\u001b[A\u001b[A\u001b[A\n",
      "Downloading [model-00002-of-00004.safetensors]:   1%| | 53.0M/4.59G [00:02<02:06\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   1%| | 39.0M/4.03G [00:02<03:03\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:   2%| | 55.0M/2.99G [00:02<01:28\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [special_tokens_map.json]: 100%|█| 5.23k/5.23k [00:00<00:00, 6.50kB/\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Processing 40 items:  62%|███████████▉       | 25.0/40.0 [00:05<00:04, 3.57it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [assets/chattts_tokenizer/tokenizer.json]:   0%| | 0.00/438k [00:00<\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [assets/chattts_tokenizer/special_tokens_map.json]: 100%|█| 7.66k/7.\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [tokenizer.json]:   0%|                 | 0.00/6.71M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [model-00002-of-00004.safetensors]:   1%| | 58.0M/4.59G [00:03<02:02\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   1%| | 42.0M/4.03G [00:03<03:02\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:   2%| | 60.0M/2.99G [00:03<01:25\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading [model-00001-of-00004.safetensors]:   1%| | 57.0M/4.54G [00:03<05:01\u001b[A\u001b[A\u001b[A\n",
      "Downloading [model-00002-of-00004.safetensors]:   1%| | 62.0M/4.59G [00:03<02:07\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [tokenization_minicpmo_fast.py]: 100%|█| 2.97k/2.97k [00:00<00:00, 3\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Processing 40 items:  68%|████████████▊      | 27.0/40.0 [00:05<00:02, 4.64it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [tokenizer_config.json]:   0%|          | 0.00/13.7k [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:   2%| | 64.0M/2.99G [00:03<01:25\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Downloading [assets/Skiing.mp4]:  12%|▋     | 1.00M/8.14M [00:01<00:08, 844kB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   1%| | 45.0M/4.03G [00:03<03:07\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [model-00002-of-00004.safetensors]:   1%| | 66.0M/4.59G [00:03<02:26\u001b[A\n",
      "\n",
      "\n",
      "Downloading [model-00001-of-00004.safetensors]:   1%| | 59.0M/4.54G [00:03<05:33\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   1%| | 48.0M/4.03G [00:03<03:06\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Downloading [assets/Skiing.mp4]:  49%|██▍  | 4.00M/8.14M [00:01<00:01, 3.74MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:   2%| | 68.0M/2.99G [00:03<01:40\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   1%| | 51.0M/4.03G [00:03<03:05\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Downloading [assets/Skiing.mp4]: 100%|█████| 8.14M/8.14M [00:01<00:00, 5.54MB/s]\u001b[A\u001b[A\n",
      "Processing 40 items:  70%|█████████████▎     | 28.0/40.0 [00:05<00:02, 4.22it/s]\n",
      "\n",
      "Downloading [assets/chattts_tokenizer/tokenizer_config.json]:   0%| | 0.00/10.8k\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:   2%| | 72.0M/2.99G [00:03<01:43\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [model-00002-of-00004.safetensors]:   1%| | 70.0M/4.59G [00:03<02:55\u001b[A\n",
      "\n",
      "\n",
      "Downloading [model-00001-of-00004.safetensors]:   1%| | 61.0M/4.54G [00:03<06:27\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   1%| | 54.0M/4.03G [00:03<03:06\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:   2%| | 76.0M/2.99G [00:03<01:59\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   1%| | 57.0M/4.03G [00:03<03:01\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [model-00002-of-00004.safetensors]:   2%| | 73.0M/4.59G [00:03<03:30\u001b[A\n",
      "\n",
      "\n",
      "Downloading [model-00001-of-00004.safetensors]:   1%| | 63.0M/4.54G [00:03<07:07\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [assets/chattts_tokenizer/tokenizer.json]:   1%| | 3.80k/438k [00:00\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   1%| | 60.0M/4.03G [00:03<03:02\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:   3%| | 79.0M/2.99G [00:03<02:08\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [tokenizer.json]:   0%|        | 3.80k/6.71M [00:00<27:20, 4.29kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [model-00002-of-00004.safetensors]:   2%| | 76.0M/4.59G [00:04<03:55\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [assets/chattts_tokenizer/tokenizer.json]: 100%|█| 438k/438k [00:01<\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Processing 40 items:  72%|█████████████▊     | 29.0/40.0 [00:06<00:03, 3.35it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   2%| | 63.0M/4.03G [00:04<03:01\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:   3%| | 82.0M/2.99G [00:04<02:11\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [tokenizer.json]:   4%|▎         | 256k/6.71M [00:01<00:19, 342kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [tokenizer_config.json]: 100%|█| 13.7k/13.7k [00:00<00:00, 15.7kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [utils.py]:   0%|                       | 0.00/7.07k [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading [model-00001-of-00004.safetensors]:   1%| | 65.0M/4.54G [00:04<07:43\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   2%| | 66.0M/4.03G [00:04<02:58\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [model-00002-of-00004.safetensors]:   2%| | 79.0M/4.59G [00:04<04:14\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [tokenizer.json]:  21%|█▋      | 1.38M/6.71M [00:01<00:02, 2.16MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:   3%| | 85.0M/2.99G [00:04<02:16\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [tokenizer.json]:  68%|█████▍  | 4.55M/6.71M [00:01<00:00, 7.88MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   2%| | 69.0M/4.03G [00:04<02:56\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [tokenizer.json]: 100%|████████| 6.71M/6.71M [00:01<00:00, 5.38MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00001-of-00004.safetensors]:   1%| | 67.0M/4.54G [00:04<08:08\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Processing 40 items:  78%|██████████████▋    | 31.0/40.0 [00:06<00:02, 4.05it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Downloading [assets/chattts_tokenizer/tokenizer_config.json]: 100%|█| 10.8k/10.8\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading [assets/Vocos.pt]:   0%|                | 0.00/51.8M [00:00<?, ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:   3%| | 88.0M/2.99G [00:04<02:19\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   2%| | 72.0M/4.03G [00:04<02:54\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [model-00002-of-00004.safetensors]:   2%| | 83.0M/4.59G [00:04<04:33\u001b[A\n",
      "\n",
      "\n",
      "Downloading [model-00001-of-00004.safetensors]:   1%| | 68.0M/4.54G [00:04<08:18\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:   3%| | 91.0M/2.99G [00:04<02:21\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   2%| | 75.0M/4.03G [00:04<02:53\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [model-00002-of-00004.safetensors]:   2%| | 85.0M/4.59G [00:04<04:37\u001b[A\n",
      "\n",
      "\n",
      "Downloading [model-00001-of-00004.safetensors]:   1%| | 69.0M/4.54G [00:04<08:29\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:   3%| | 94.0M/2.99G [00:04<02:22\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   2%| | 78.0M/4.03G [00:04<02:54\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [model-00002-of-00004.safetensors]:   2%| | 87.0M/4.59G [00:04<04:41\u001b[A\n",
      "\n",
      "\n",
      "Downloading [model-00001-of-00004.safetensors]:   2%| | 70.0M/4.54G [00:04<08:22\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   2%| | 81.0M/4.03G [00:04<02:53\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:   3%| | 97.0M/2.99G [00:04<02:22\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading [model-00001-of-00004.safetensors]:   2%| | 71.0M/4.54G [00:04<08:29\u001b[A\u001b[A\u001b[A\n",
      "Downloading [model-00002-of-00004.safetensors]:   2%| | 89.0M/4.59G [00:04<04:44\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   2%| | 84.0M/4.03G [00:04<02:53\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading [model-00001-of-00004.safetensors]:   2%| | 72.0M/4.54G [00:05<08:41\u001b[A\u001b[A\u001b[A\n",
      "Downloading [model-00002-of-00004.safetensors]:   2%| | 91.0M/4.59G [00:04<04:46\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:   3%| | 100M/2.99G [00:04<02:23,\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [utils.py]: 100%|██████████████| 7.07k/7.07k [00:00<00:00, 8.15kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Processing 40 items:  82%|███████████████▋   | 33.0/40.0 [00:07<00:01, 3.66it/s]\n",
      "\n",
      "\n",
      "Downloading [model-00001-of-00004.safetensors]:   2%| | 73.0M/4.54G [00:05<08:45\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   2%| | 87.0M/4.03G [00:05<02:55\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [model-00002-of-00004.safetensors]:   2%| | 93.0M/4.59G [00:05<04:44\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:   3%| | 103M/2.99G [00:05<02:21,\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   2%| | 90.0M/4.03G [00:05<02:46\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading [model-00001-of-00004.safetensors]:   2%| | 74.0M/4.54G [00:05<08:52\u001b[A\u001b[A\u001b[A\n",
      "Downloading [model-00002-of-00004.safetensors]:   2%| | 95.0M/4.59G [00:05<04:45\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:   3%| | 106M/2.99G [00:05<02:19,\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [vocab.json]:   0%|            | 3.80k/2.65M [00:00<10:43, 4.31kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   2%| | 93.0M/4.03G [00:05<02:45\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [model-00002-of-00004.safetensors]:   2%| | 97.0M/4.59G [00:05<04:43\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:   4%| | 109M/2.99G [00:05<02:21,\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [vocab.json]:   6%|▊             | 156k/2.65M [00:01<00:12, 209kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading [model-00001-of-00004.safetensors]:   2%| | 76.0M/4.54G [00:05<08:39\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   2%| | 96.0M/4.03G [00:05<02:40\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [model-00002-of-00004.safetensors]:   2%| | 99.0M/4.59G [00:05<04:46\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [assets/input_examples/Trump_WEF_2018_10s.mp3]: 100%|█| 157k/157k [0\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Processing 40 items:  85%|████████████████▏  | 34.0/40.0 [00:07<00:01, 3.15it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [vocab.json]:  25%|███▏         | 676k/2.65M [00:01<00:02, 1.02MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:   4%| | 112M/2.99G [00:05<02:18,\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading [model-00001-of-00004.safetensors]:   2%| | 77.0M/4.54G [00:05<08:40\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Downloading [assets/Vocos.pt]:   2%|▏       | 1.00M/51.8M [00:01<00:58, 904kB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   2%| | 99.0M/4.03G [00:05<02:42\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [model-00002-of-00004.safetensors]:   2%| | 101M/4.59G [00:05<04:43,\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [vocab.json]: 100%|████████████| 2.65M/2.65M [00:01<00:00, 2.22MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Processing 40 items:  88%|████████████████▋  | 35.0/40.0 [00:07<00:01, 3.66it/s]\n",
      "\n",
      "\n",
      "Downloading [model-00001-of-00004.safetensors]:   2%| | 78.0M/4.54G [00:05<08:44\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   2%| | 102M/4.03G [00:05<02:39,\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Downloading [assets/Vocos.pt]:  10%|▋      | 5.00M/51.8M [00:01<00:09, 5.29MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:   4%| | 115M/2.99G [00:05<02:20,\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [model-00002-of-00004.safetensors]:   2%| | 103M/4.59G [00:05<04:35,\u001b[A\n",
      "\n",
      "\n",
      "Downloading [model-00001-of-00004.safetensors]:   2%| | 79.0M/4.54G [00:05<08:29\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   3%| | 105M/4.03G [00:05<02:40,\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Downloading [assets/Vocos.pt]:  19%|█▎     | 10.0M/51.8M [00:01<00:03, 11.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:   4%| | 118M/2.99G [00:05<02:18,\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [model-00002-of-00004.safetensors]:   2%| | 105M/4.59G [00:05<04:36,\u001b[A\n",
      "\n",
      "\n",
      "Downloading [model-00001-of-00004.safetensors]:   2%| | 80.0M/4.54G [00:05<08:35\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   3%| | 108M/4.03G [00:05<02:41,\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Downloading [assets/Vocos.pt]:  31%|██▏    | 16.0M/51.8M [00:01<00:02, 18.3MB/s]\u001b[A\u001b[A\n",
      "Downloading [model-00002-of-00004.safetensors]:   2%| | 107M/4.59G [00:05<04:35,\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:   4%| | 121M/2.99G [00:05<02:16,\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading [model-00001-of-00004.safetensors]:   2%| | 81.0M/4.54G [00:06<08:39\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   3%| | 111M/4.03G [00:05<02:41,\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Downloading [assets/Vocos.pt]:  44%|███    | 23.0M/51.8M [00:01<00:01, 26.7MB/s]\u001b[A\u001b[A\n",
      "Downloading [model-00002-of-00004.safetensors]:   2%| | 109M/4.59G [00:06<04:34,\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:   4%| | 124M/2.99G [00:06<02:16,\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   3%| | 114M/4.03G [00:06<02:41,\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Downloading [assets/Vocos.pt]:  60%|████▏  | 31.0M/51.8M [00:01<00:00, 37.3MB/s]\u001b[A\u001b[A\n",
      "Downloading [model-00002-of-00004.safetensors]:   2%| | 111M/4.59G [00:06<04:37,\u001b[A\n",
      "\n",
      "\n",
      "Downloading [model-00001-of-00004.safetensors]:   2%| | 83.0M/4.54G [00:06<08:30\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:   4%| | 127M/2.99G [00:06<02:14,\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Downloading [assets/Vocos.pt]:  71%|████▉  | 37.0M/51.8M [00:01<00:00, 42.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   3%| | 117M/4.03G [00:06<02:41,\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [model-00002-of-00004.safetensors]:   2%| | 113M/4.59G [00:06<04:35,\u001b[A\n",
      "\n",
      "\n",
      "Downloading [model-00001-of-00004.safetensors]:   2%| | 84.0M/4.54G [00:06<08:34\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:   4%| | 130M/2.99G [00:06<02:14,\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Downloading [assets/Vocos.pt]:  85%|█████▉ | 44.0M/51.8M [00:02<00:00, 46.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   3%| | 120M/4.03G [00:06<02:41,\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [model-00002-of-00004.safetensors]:   2%| | 115M/4.59G [00:06<04:36,\u001b[A\n",
      "\n",
      "Downloading [assets/Vocos.pt]: 100%|███████| 51.8M/51.8M [00:02<00:00, 25.8MB/s]\u001b[A\u001b[A\n",
      "Processing 40 items:  90%|█████████████████  | 36.0/40.0 [00:08<00:01, 2.39it/s]\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:   4%| | 133M/2.99G [00:06<02:15,\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   3%| | 123M/4.03G [00:06<02:41,\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [model-00002-of-00004.safetensors]:   2%| | 117M/4.59G [00:06<04:29,\u001b[A\n",
      "\n",
      "\n",
      "Downloading [model-00001-of-00004.safetensors]:   2%| | 86.0M/4.54G [00:06<08:23\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   3%| | 126M/4.03G [00:06<02:39,\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:   4%| | 136M/2.99G [00:06<02:13,\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading [model-00001-of-00004.safetensors]:   2%| | 87.0M/4.54G [00:06<08:26\u001b[A\u001b[A\u001b[A\n",
      "Downloading [model-00002-of-00004.safetensors]:   3%| | 119M/4.59G [00:06<04:30,\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   3%| | 129M/4.03G [00:06<02:32,\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [model-00002-of-00004.safetensors]:   3%| | 121M/4.59G [00:06<04:30,\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:   5%| | 139M/2.99G [00:06<02:12,\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   3%| | 132M/4.03G [00:06<02:34,\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading [model-00001-of-00004.safetensors]:   2%| | 89.0M/4.54G [00:06<08:20\u001b[A\u001b[A\u001b[A\n",
      "Downloading [model-00002-of-00004.safetensors]:   3%| | 123M/4.59G [00:06<04:32,\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:   5%| | 142M/2.99G [00:06<02:11,\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   3%| | 135M/4.03G [00:06<02:36,\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading [model-00001-of-00004.safetensors]:   2%| | 90.0M/4.54G [00:07<08:15\u001b[A\u001b[A\u001b[A\n",
      "Downloading [model-00002-of-00004.safetensors]:   3%| | 125M/4.59G [00:07<04:23,\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:   5%| | 145M/2.99G [00:06<02:11,\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading [model-00001-of-00004.safetensors]:   2%| | 91.0M/4.54G [00:07<08:14\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   3%| | 138M/4.03G [00:07<02:37,\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [model-00002-of-00004.safetensors]:   3%| | 127M/4.59G [00:07<04:27,\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:   5%| | 148M/2.99G [00:07<02:11,\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading [model-00001-of-00004.safetensors]:   2%| | 92.0M/4.54G [00:07<08:22\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   3%| | 141M/4.03G [00:07<02:37,\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [model-00002-of-00004.safetensors]:   3%| | 129M/4.59G [00:07<04:26,\u001b[A\n",
      "\n",
      "\n",
      "Downloading [model-00001-of-00004.safetensors]:   2%| | 93.0M/4.54G [00:07<08:10\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:   5%| | 151M/2.99G [00:07<02:11,\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   3%| | 144M/4.03G [00:07<02:38,\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [model-00002-of-00004.safetensors]:   3%| | 131M/4.59G [00:07<04:25,\u001b[A\n",
      "\n",
      "\n",
      "Downloading [model-00001-of-00004.safetensors]:   2%| | 94.0M/4.54G [00:07<08:20\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   4%| | 147M/4.03G [00:07<02:36,\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:   5%| | 154M/2.99G [00:07<02:11,\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [model-00002-of-00004.safetensors]:   3%| | 133M/4.59G [00:07<04:28,\u001b[A\n",
      "\n",
      "\n",
      "Downloading [model-00001-of-00004.safetensors]:   2%| | 95.0M/4.54G [00:07<08:21\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   4%| | 150M/4.03G [00:07<02:31,\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:   5%| | 157M/2.99G [00:07<02:10,\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [model-00002-of-00004.safetensors]:   3%| | 135M/4.59G [00:07<04:30,\u001b[A\n",
      "\n",
      "\n",
      "Downloading [model-00001-of-00004.safetensors]:   2%| | 96.0M/4.54G [00:07<08:09\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   4%| | 153M/4.03G [00:07<02:32,\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [model-00002-of-00004.safetensors]:   3%| | 137M/4.59G [00:07<04:27,\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:   5%| | 160M/2.99G [00:07<02:09,\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading [model-00001-of-00004.safetensors]:   2%| | 97.0M/4.54G [00:07<08:18\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   4%| | 156M/4.03G [00:07<02:34,\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [model-00002-of-00004.safetensors]:   3%| | 139M/4.59G [00:07<04:20,\u001b[A\n",
      "\n",
      "\n",
      "Downloading [model-00001-of-00004.safetensors]:   2%| | 98.0M/4.54G [00:07<08:09\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:   5%| | 163M/2.99G [00:07<02:11,\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   4%| | 159M/4.03G [00:07<02:36,\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [model-00002-of-00004.safetensors]:   3%| | 141M/4.59G [00:07<04:24,\u001b[A\n",
      "\n",
      "\n",
      "Downloading [model-00001-of-00004.safetensors]:   2%| | 99.0M/4.54G [00:08<08:09\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:   5%| | 166M/2.99G [00:07<02:11,\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   4%| | 162M/4.03G [00:07<02:36,\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [model-00002-of-00004.safetensors]:   3%| | 143M/4.59G [00:08<04:22,\u001b[A\n",
      "\n",
      "\n",
      "Downloading [model-00001-of-00004.safetensors]:   2%| | 100M/4.54G [00:08<08:11,\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:   6%| | 169M/2.99G [00:08<02:09,\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   4%| | 165M/4.03G [00:08<02:36,\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading [model-00001-of-00004.safetensors]:   2%| | 101M/4.54G [00:08<08:03,\u001b[A\u001b[A\u001b[A\n",
      "Downloading [model-00002-of-00004.safetensors]:   3%| | 145M/4.59G [00:08<04:26,\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:   6%| | 172M/2.99G [00:08<02:07,\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   4%| | 168M/4.03G [00:08<02:32,\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading [model-00001-of-00004.safetensors]:   2%| | 102M/4.54G [00:08<08:11,\u001b[A\u001b[A\u001b[A\n",
      "Downloading [model-00002-of-00004.safetensors]:   3%| | 147M/4.59G [00:08<04:26,\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   4%| | 171M/4.03G [00:08<02:30,\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:   6%| | 175M/2.99G [00:08<02:09,\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [model-00002-of-00004.safetensors]:   3%| | 149M/4.59G [00:08<04:27,\u001b[A\n",
      "\n",
      "\n",
      "Downloading [model-00001-of-00004.safetensors]:   2%| | 104M/4.54G [00:08<08:04,\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   4%| | 174M/4.03G [00:08<02:32,\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [model-00002-of-00004.safetensors]:   3%| | 151M/4.59G [00:08<04:20,\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:   6%| | 178M/2.99G [00:08<02:09,\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   4%| | 177M/4.03G [00:08<02:34,\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [model-00002-of-00004.safetensors]:   3%| | 153M/4.59G [00:08<04:21,\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:   6%| | 181M/2.99G [00:08<02:09,\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading [model-00001-of-00004.safetensors]:   2%| | 106M/4.54G [00:08<07:57,\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   4%| | 180M/4.03G [00:08<02:36,\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [model-00002-of-00004.safetensors]:   3%| | 155M/4.59G [00:08<04:22,\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:   6%| | 184M/2.99G [00:08<02:07,\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   4%| | 183M/4.03G [00:08<02:31,\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [model-00002-of-00004.safetensors]:   3%| | 157M/4.59G [00:08<04:24,\u001b[A\n",
      "\n",
      "\n",
      "Downloading [model-00001-of-00004.safetensors]:   2%| | 108M/4.54G [00:08<07:53,\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:   6%| | 187M/2.99G [00:08<02:07,\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [model-00002-of-00004.safetensors]:   3%| | 159M/4.59G [00:08<04:25,\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   5%| | 186M/4.03G [00:08<03:02,\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:   6%| | 190M/2.99G [00:08<02:08,\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [model-00002-of-00004.safetensors]:   3%| | 161M/4.59G [00:09<04:25,\u001b[A\n",
      "\n",
      "\n",
      "Downloading [model-00001-of-00004.safetensors]:   2%| | 110M/4.54G [00:09<07:50,\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:   6%| | 193M/2.99G [00:09<02:07,\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [model-00002-of-00004.safetensors]:   3%| | 163M/4.59G [00:09<05:03,\u001b[A\n",
      "\n",
      "\n",
      "Downloading [model-00001-of-00004.safetensors]:   2%| | 112M/4.54G [00:09<07:41,\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:   6%| | 196M/2.99G [00:09<02:07,\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   5%| | 189M/4.03G [00:09<04:09,\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading [model-00001-of-00004.safetensors]:   2%| | 113M/4.54G [00:09<07:39,\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:   6%| | 199M/2.99G [00:09<02:07,\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [model-00002-of-00004.safetensors]:   4%| | 165M/4.59G [00:09<05:43,\u001b[A\n",
      "\n",
      "\n",
      "Downloading [model-00001-of-00004.safetensors]:   2%| | 114M/4.54G [00:09<07:39,\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   5%| | 191M/4.03G [00:09<04:54,\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:   7%| | 202M/2.99G [00:09<02:07,\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading [model-00001-of-00004.safetensors]:   2%| | 115M/4.54G [00:09<07:45,\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading [model-00001-of-00004.safetensors]:   2%| | 116M/4.54G [00:09<08:18,\u001b[A\u001b[A\u001b[A\n",
      "Downloading [model-00002-of-00004.safetensors]:   4%| | 167M/4.59G [00:09<07:23,\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:   7%| | 205M/2.99G [00:09<02:29,\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading [model-00001-of-00004.safetensors]:   3%| | 117M/4.54G [00:10<09:24,\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   5%| | 193M/4.03G [00:09<06:27,\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:   7%| | 208M/2.99G [00:09<02:38,\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading [model-00001-of-00004.safetensors]:   3%| | 118M/4.54G [00:10<10:35,\u001b[A\u001b[A\u001b[A\n",
      "Downloading [model-00002-of-00004.safetensors]:   4%| | 169M/4.59G [00:10<10:12,\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:   7%| | 210M/2.99G [00:10<03:17,\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading [model-00001-of-00004.safetensors]:   3%| | 119M/4.54G [00:10<11:48,\u001b[A\u001b[A\u001b[A\n",
      "Downloading [model-00002-of-00004.safetensors]:   4%| | 170M/4.59G [00:10<11:11,\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:   7%| | 212M/2.99G [00:10<03:53,\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading [model-00001-of-00004.safetensors]:   3%| | 120M/4.54G [00:10<12:46,\u001b[A\u001b[A\u001b[A\n",
      "Downloading [model-00002-of-00004.safetensors]:   4%| | 171M/4.59G [00:10<12:08,\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   5%| | 195M/4.03G [00:10<11:14,\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading [model-00001-of-00004.safetensors]:   3%| | 121M/4.54G [00:10<13:45,\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:   7%| | 214M/2.99G [00:10<04:40,\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [model-00002-of-00004.safetensors]:   4%| | 172M/4.59G [00:10<13:21,\u001b[A\n",
      "\n",
      "\n",
      "Downloading [model-00001-of-00004.safetensors]:   3%| | 122M/4.54G [00:11<15:17,\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   5%| | 196M/4.03G [00:11<13:22,\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:   7%| | 216M/2.99G [00:11<05:31,\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [model-00002-of-00004.safetensors]:   4%| | 173M/4.59G [00:11<15:39,\u001b[A\n",
      "\n",
      "\n",
      "Downloading [model-00001-of-00004.safetensors]:   3%| | 123M/4.54G [00:11<16:24,\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:   7%| | 217M/2.99G [00:11<05:42,\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:   7%| | 218M/2.99G [00:11<06:04,\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   5%| | 197M/4.03G [00:11<15:08,\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading [model-00001-of-00004.safetensors]:   3%| | 124M/4.54G [00:11<17:04,\u001b[A\u001b[A\u001b[A\n",
      "Downloading [model-00002-of-00004.safetensors]:   4%| | 174M/4.59G [00:11<18:45,\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:   7%| | 219M/2.99G [00:11<06:23,\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading [model-00001-of-00004.safetensors]:   3%| | 125M/4.54G [00:11<17:10,\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:   7%| | 220M/2.99G [00:11<06:34,\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   5%| | 198M/4.03G [00:11<16:37,\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:   7%| | 221M/2.99G [00:11<06:43,\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [model-00002-of-00004.safetensors]:   4%| | 175M/4.59G [00:11<20:59,\u001b[A\n",
      "\n",
      "\n",
      "Downloading [model-00001-of-00004.safetensors]:   3%| | 126M/4.54G [00:12<17:08,\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:   7%| | 222M/2.99G [00:11<06:49,\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   5%| | 199M/4.03G [00:12<17:39,\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading [model-00001-of-00004.safetensors]:   3%| | 127M/4.54G [00:12<17:29,\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:   7%| | 223M/2.99G [00:12<06:56,\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [model-00002-of-00004.safetensors]:   4%| | 176M/4.59G [00:12<22:23,\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:   7%| | 224M/2.99G [00:12<06:48,\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading [model-00001-of-00004.safetensors]:   3%| | 128M/4.54G [00:12<17:08,\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   5%| | 200M/4.03G [00:12<18:23,\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:   7%| | 225M/2.99G [00:12<06:58,\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [model-00002-of-00004.safetensors]:   4%| | 177M/4.59G [00:12<23:07,\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:   7%| | 226M/2.99G [00:12<06:50,\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading [model-00001-of-00004.safetensors]:   3%| | 129M/4.54G [00:12<17:16,\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   5%| | 201M/4.03G [00:12<18:39,\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:   7%| | 227M/2.99G [00:12<06:52,\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading [model-00001-of-00004.safetensors]:   3%| | 130M/4.54G [00:12<17:02,\u001b[A\u001b[A\u001b[A\n",
      "Downloading [model-00002-of-00004.safetensors]:   4%| | 178M/4.59G [00:12<23:17,\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:   7%| | 228M/2.99G [00:12<06:49,\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   5%| | 202M/4.03G [00:12<18:44,\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading [model-00001-of-00004.safetensors]:   3%| | 131M/4.54G [00:13<16:43,\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:   7%| | 229M/2.99G [00:12<06:52,\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:   8%| | 230M/2.99G [00:13<06:45,\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [model-00002-of-00004.safetensors]:   4%| | 179M/4.59G [00:13<23:06,\u001b[A\n",
      "\n",
      "\n",
      "Downloading [model-00001-of-00004.safetensors]:   3%| | 132M/4.54G [00:13<16:21,\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   5%| | 203M/4.03G [00:13<18:31,\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:   8%| | 231M/2.99G [00:13<06:45,\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading [model-00001-of-00004.safetensors]:   3%| | 133M/4.54G [00:13<16:05,\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:   8%| | 232M/2.99G [00:13<06:44,\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [model-00002-of-00004.safetensors]:   4%| | 180M/4.59G [00:13<22:55,\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   5%| | 204M/4.03G [00:13<18:20,\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:   8%| | 233M/2.99G [00:13<06:45,\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading [model-00001-of-00004.safetensors]:   3%| | 134M/4.54G [00:13<15:54,\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:   8%| | 234M/2.99G [00:13<06:36,\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [model-00002-of-00004.safetensors]:   4%| | 181M/4.59G [00:13<22:26,\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   5%| | 205M/4.03G [00:13<18:00,\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading [model-00001-of-00004.safetensors]:   3%| | 135M/4.54G [00:13<15:44,\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:   8%| | 235M/2.99G [00:13<06:39,\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:   8%| | 236M/2.99G [00:13<06:39,\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [model-00002-of-00004.safetensors]:   4%| | 182M/4.59G [00:14<21:51,\u001b[A\n",
      "\n",
      "\n",
      "Downloading [model-00001-of-00004.safetensors]:   3%| | 136M/4.54G [00:14<15:22,\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   5%| | 206M/4.03G [00:14<17:34,\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:   8%| | 237M/2.99G [00:14<06:34,\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading [model-00001-of-00004.safetensors]:   3%| | 137M/4.54G [00:14<14:57,\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:   8%| | 238M/2.99G [00:14<06:33,\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [model-00002-of-00004.safetensors]:   4%| | 183M/4.59G [00:14<21:15,\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   5%| | 207M/4.03G [00:14<17:10,\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:   8%| | 239M/2.99G [00:14<06:32,\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading [model-00001-of-00004.safetensors]:   3%| | 138M/4.54G [00:14<15:00,\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   5%| | 208M/4.03G [00:14<16:47,\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [model-00002-of-00004.safetensors]:   4%| | 184M/4.59G [00:14<20:42,\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:   8%| | 240M/2.99G [00:14<06:25,\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading [model-00001-of-00004.safetensors]:   3%| | 139M/4.54G [00:14<14:35,\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:   8%| | 241M/2.99G [00:14<06:19,\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   5%| | 209M/4.03G [00:14<16:21,\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading [model-00001-of-00004.safetensors]:   3%| | 140M/4.54G [00:14<14:28,\u001b[A\u001b[A\u001b[A\n",
      "Downloading [model-00002-of-00004.safetensors]:   4%| | 185M/4.59G [00:14<20:12,\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:   8%| | 242M/2.99G [00:14<06:22,\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:   8%| | 243M/2.99G [00:14<06:15,\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading [model-00001-of-00004.safetensors]:   3%| | 141M/4.54G [00:15<14:00,\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   5%| | 210M/4.03G [00:14<15:58,\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [model-00002-of-00004.safetensors]:   4%| | 186M/4.59G [00:15<19:36,\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:   8%| | 244M/2.99G [00:15<06:16,\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading [model-00001-of-00004.safetensors]:   3%| | 142M/4.54G [00:15<13:58,\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:   8%| | 245M/2.99G [00:15<06:10,\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   5%| | 211M/4.03G [00:15<15:39,\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [model-00002-of-00004.safetensors]:   4%| | 187M/4.59G [00:15<19:10,\u001b[A\n",
      "\n",
      "\n",
      "Downloading [model-00001-of-00004.safetensors]:   3%| | 143M/4.54G [00:15<13:56,\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:   8%| | 246M/2.99G [00:15<06:08,\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   5%| | 212M/4.03G [00:15<15:12,\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:   8%| | 247M/2.99G [00:15<06:05,\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading [model-00001-of-00004.safetensors]:   3%| | 144M/4.54G [00:15<13:34,\u001b[A\u001b[A\u001b[A\n",
      "Downloading [model-00002-of-00004.safetensors]:   4%| | 188M/4.59G [00:15<18:36,\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:   8%| | 248M/2.99G [00:15<06:03,\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   5%| | 213M/4.03G [00:15<14:55,\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading [model-00001-of-00004.safetensors]:   3%| | 145M/4.54G [00:15<13:25,\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:   8%| | 249M/2.99G [00:15<06:03,\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [model-00002-of-00004.safetensors]:   4%| | 189M/4.59G [00:15<18:04,\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:   8%| | 250M/2.99G [00:15<05:59,\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading [model-00001-of-00004.safetensors]:   3%| | 146M/4.54G [00:15<13:11,\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   5%| | 214M/4.03G [00:15<14:37,\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [model-00002-of-00004.safetensors]:   4%| | 190M/4.59G [00:15<17:46,\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:   8%| | 251M/2.99G [00:15<05:58,\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading [model-00001-of-00004.safetensors]:   3%| | 147M/4.54G [00:16<13:04,\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   5%| | 215M/4.03G [00:16<14:17,\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:   8%| | 252M/2.99G [00:16<05:54,\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [model-00002-of-00004.safetensors]:   4%| | 191M/4.59G [00:16<17:19,\u001b[A\n",
      "\n",
      "\n",
      "Downloading [model-00001-of-00004.safetensors]:   3%| | 148M/4.54G [00:16<12:56,\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:   8%| | 253M/2.99G [00:16<05:51,\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   5%| | 216M/4.03G [00:16<14:03,\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:   8%| | 254M/2.99G [00:16<05:48,\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading [model-00001-of-00004.safetensors]:   3%| | 149M/4.54G [00:16<12:45,\u001b[A\u001b[A\u001b[A\n",
      "Downloading [model-00002-of-00004.safetensors]:   4%| | 192M/4.59G [00:16<16:59,\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:   8%| | 255M/2.99G [00:16<05:46,\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   5%| | 217M/4.03G [00:16<13:43,\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading [model-00001-of-00004.safetensors]:   3%| | 150M/4.54G [00:16<12:37,\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:   8%| | 256M/2.99G [00:16<05:45,\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [model-00002-of-00004.safetensors]:   4%| | 193M/4.59G [00:16<16:33,\u001b[A\n",
      "\n",
      "\n",
      "Downloading [model-00001-of-00004.safetensors]:   3%| | 151M/4.54G [00:16<12:28,\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   5%| | 218M/4.03G [00:16<13:30,\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:   8%| | 257M/2.99G [00:16<05:40,\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [model-00002-of-00004.safetensors]:   4%| | 194M/4.59G [00:16<16:17,\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:   8%| | 258M/2.99G [00:16<05:33,\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading [model-00001-of-00004.safetensors]:   3%| | 152M/4.54G [00:16<12:16,\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   5%| | 219M/4.03G [00:16<13:15,\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:   8%| | 259M/2.99G [00:16<05:35,\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading [model-00001-of-00004.safetensors]:   3%| | 153M/4.54G [00:17<12:09,\u001b[A\u001b[A\u001b[A\n",
      "Downloading [model-00002-of-00004.safetensors]:   4%| | 195M/4.59G [00:17<15:56,\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:   8%| | 260M/2.99G [00:16<05:31,\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   5%| | 220M/4.03G [00:17<12:58,\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading [model-00001-of-00004.safetensors]:   3%| | 154M/4.54G [00:17<12:01,\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:   9%| | 261M/2.99G [00:17<05:28,\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [model-00002-of-00004.safetensors]:   4%| | 196M/4.59G [00:17<15:33,\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   5%| | 221M/4.03G [00:17<12:46,\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:   9%| | 262M/2.99G [00:17<05:29,\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading [model-00001-of-00004.safetensors]:   3%| | 155M/4.54G [00:17<11:59,\u001b[A\u001b[A\u001b[A\n",
      "Downloading [model-00002-of-00004.safetensors]:   4%| | 197M/4.59G [00:17<15:12,\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:   9%| | 263M/2.99G [00:17<05:32,\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   5%| | 222M/4.03G [00:17<12:33,\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading [model-00001-of-00004.safetensors]:   3%| | 156M/4.54G [00:17<11:50,\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:   9%| | 264M/2.99G [00:17<05:25,\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [model-00002-of-00004.safetensors]:   4%| | 198M/4.59G [00:17<15:06,\u001b[A\n",
      "\n",
      "\n",
      "Downloading [model-00001-of-00004.safetensors]:   3%| | 157M/4.54G [00:17<11:36,\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   5%| | 223M/4.03G [00:17<12:25,\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:   9%| | 265M/2.99G [00:17<05:26,\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:   9%| | 266M/2.99G [00:17<05:19,\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading [model-00001-of-00004.safetensors]:   3%| | 158M/4.54G [00:17<11:39,\u001b[A\u001b[A\u001b[A\n",
      "Downloading [model-00002-of-00004.safetensors]:   4%| | 199M/4.59G [00:17<14:52,\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   5%| | 224M/4.03G [00:17<12:10,\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:   9%| | 267M/2.99G [00:17<05:23,\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading [model-00001-of-00004.safetensors]:   3%| | 159M/4.54G [00:18<11:21,\u001b[A\u001b[A\u001b[A\n",
      "Downloading [model-00002-of-00004.safetensors]:   4%| | 200M/4.59G [00:17<14:33,\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:   9%| | 268M/2.99G [00:17<05:20,\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   5%| | 225M/4.03G [00:17<12:02,\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading [model-00001-of-00004.safetensors]:   3%| | 160M/4.54G [00:18<11:19,\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:   9%| | 269M/2.99G [00:18<05:18,\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [model-00002-of-00004.safetensors]:   4%| | 201M/4.59G [00:18<14:20,\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   5%| | 226M/4.03G [00:18<11:50,\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:   9%| | 270M/2.99G [00:18<05:14,\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading [model-00001-of-00004.safetensors]:   3%| | 161M/4.54G [00:18<11:16,\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:   9%| | 271M/2.99G [00:18<05:17,\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [model-00002-of-00004.safetensors]:   4%| | 202M/4.59G [00:18<14:09,\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   5%| | 227M/4.03G [00:18<11:45,\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading [model-00001-of-00004.safetensors]:   3%| | 162M/4.54G [00:18<11:05,\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:   9%| | 272M/2.99G [00:18<05:09,\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading [model-00001-of-00004.safetensors]:   4%| | 163M/4.54G [00:18<11:01,\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   6%| | 228M/4.03G [00:18<11:30,\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [model-00002-of-00004.safetensors]:   4%| | 203M/4.59G [00:18<13:57,\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:   9%| | 273M/2.99G [00:18<05:08,\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading [model-00001-of-00004.safetensors]:   4%| | 164M/4.54G [00:18<10:54,\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:   9%| | 274M/2.99G [00:18<05:13,\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   6%| | 229M/4.03G [00:18<11:27,\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [model-00002-of-00004.safetensors]:   4%| | 204M/4.59G [00:18<13:38,\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:   9%| | 275M/2.99G [00:18<05:04,\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading [model-00001-of-00004.safetensors]:   4%| | 165M/4.54G [00:18<10:53,\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   6%| | 230M/4.03G [00:18<11:15,\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:   9%| | 276M/2.99G [00:18<05:04,\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [model-00002-of-00004.safetensors]:   4%| | 205M/4.59G [00:18<13:31,\u001b[A\n",
      "\n",
      "\n",
      "Downloading [model-00001-of-00004.safetensors]:   4%| | 166M/4.54G [00:19<10:43,\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:   9%| | 277M/2.99G [00:18<05:05,\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   6%| | 231M/4.03G [00:18<11:02,\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [model-00002-of-00004.safetensors]:   4%| | 206M/4.59G [00:19<13:16,\u001b[A\n",
      "\n",
      "\n",
      "Downloading [model-00001-of-00004.safetensors]:   4%| | 167M/4.54G [00:19<10:34,\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:   9%| | 278M/2.99G [00:19<05:01,\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:   9%| | 279M/2.99G [00:19<05:02,\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   6%| | 232M/4.03G [00:19<11:01,\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading [model-00001-of-00004.safetensors]:   4%| | 168M/4.54G [00:19<10:36,\u001b[A\u001b[A\u001b[A\n",
      "Downloading [model-00002-of-00004.safetensors]:   4%| | 207M/4.59G [00:19<13:09,\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:   9%| | 280M/2.99G [00:19<04:59,\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading [model-00001-of-00004.safetensors]:   4%| | 169M/4.54G [00:19<10:28,\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   6%| | 233M/4.03G [00:19<10:52,\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [model-00002-of-00004.safetensors]:   4%| | 208M/4.59G [00:19<13:00,\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:   9%| | 281M/2.99G [00:19<04:57,\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading [model-00001-of-00004.safetensors]:   4%| | 170M/4.54G [00:19<10:22,\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:   9%| | 282M/2.99G [00:19<04:56,\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   6%| | 234M/4.03G [00:19<10:38,\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [model-00002-of-00004.safetensors]:   4%| | 209M/4.59G [00:19<12:50,\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:   9%| | 283M/2.99G [00:19<04:54,\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading [model-00001-of-00004.safetensors]:   4%| | 171M/4.54G [00:19<10:22,\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   6%| | 235M/4.03G [00:19<10:35,\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [model-00002-of-00004.safetensors]:   4%| | 210M/4.59G [00:19<12:42,\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:   9%| | 284M/2.99G [00:19<04:58,\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading [model-00001-of-00004.safetensors]:   4%| | 172M/4.54G [00:19<10:11,\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   6%| | 236M/4.03G [00:19<10:29,\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [model-00002-of-00004.safetensors]:   4%| | 211M/4.59G [00:19<12:31,\u001b[A\n",
      "\n",
      "\n",
      "Downloading [model-00001-of-00004.safetensors]:   4%| | 173M/4.54G [00:19<10:08,\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:   9%| | 286M/2.99G [00:19<04:51,\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   6%| | 237M/4.03G [00:19<10:17,\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading [model-00001-of-00004.safetensors]:   4%| | 174M/4.54G [00:20<10:00,\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:   9%| | 287M/2.99G [00:19<04:47,\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [model-00002-of-00004.safetensors]:   5%| | 212M/4.59G [00:20<12:23,\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:   9%| | 288M/2.99G [00:20<04:47,\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   6%| | 238M/4.03G [00:20<10:12,\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading [model-00001-of-00004.safetensors]:   4%| | 175M/4.54G [00:20<09:58,\u001b[A\u001b[A\u001b[A\n",
      "Downloading [model-00002-of-00004.safetensors]:   5%| | 213M/4.59G [00:20<12:10,\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:   9%| | 289M/2.99G [00:20<04:45,\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading [model-00001-of-00004.safetensors]:   4%| | 176M/4.54G [00:20<10:02,\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   6%| | 239M/4.03G [00:20<10:11,\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:   9%| | 290M/2.99G [00:20<04:45,\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [model-00002-of-00004.safetensors]:   5%| | 214M/4.59G [00:20<12:05,\u001b[A\n",
      "\n",
      "\n",
      "Downloading [model-00001-of-00004.safetensors]:   4%| | 177M/4.54G [00:20<09:53,\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   6%| | 240M/4.03G [00:20<10:03,\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [model-00002-of-00004.safetensors]:   5%| | 215M/4.59G [00:20<11:52,\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:  10%| | 292M/2.99G [00:20<04:44,\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading [model-00001-of-00004.safetensors]:   4%| | 178M/4.54G [00:20<09:46,\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   6%| | 241M/4.03G [00:20<09:53,\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [model-00002-of-00004.safetensors]:   5%| | 216M/4.59G [00:20<11:41,\u001b[A\n",
      "\n",
      "\n",
      "Downloading [model-00001-of-00004.safetensors]:   4%| | 179M/4.54G [00:20<09:44,\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:  10%| | 294M/2.99G [00:20<04:38,\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   6%| | 242M/4.03G [00:20<09:53,\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading [model-00001-of-00004.safetensors]:   4%| | 180M/4.54G [00:20<09:34,\u001b[A\u001b[A\u001b[A\n",
      "Downloading [model-00002-of-00004.safetensors]:   5%| | 217M/4.59G [00:20<11:45,\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:  10%| | 295M/2.99G [00:20<04:38,\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   6%| | 243M/4.03G [00:20<09:50,\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading [model-00001-of-00004.safetensors]:   4%| | 181M/4.54G [00:21<09:35,\u001b[A\u001b[A\u001b[A\n",
      "Downloading [model-00002-of-00004.safetensors]:   5%| | 218M/4.59G [00:20<11:35,\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:  10%| | 297M/2.99G [00:20<04:38,\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   6%| | 244M/4.03G [00:20<09:37,\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading [model-00001-of-00004.safetensors]:   4%| | 182M/4.54G [00:21<09:35,\u001b[A\u001b[A\u001b[A\n",
      "Downloading [model-00002-of-00004.safetensors]:   5%| | 219M/4.59G [00:21<11:16,\u001b[A\n",
      "\n",
      "\n",
      "Downloading [model-00001-of-00004.safetensors]:   4%| | 183M/4.54G [00:21<09:20,\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   6%| | 245M/4.03G [00:21<09:36,\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:  10%| | 299M/2.99G [00:21<04:36,\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [model-00002-of-00004.safetensors]:   5%| | 220M/4.59G [00:21<11:22,\u001b[A\n",
      "\n",
      "\n",
      "Downloading [model-00001-of-00004.safetensors]:   4%| | 184M/4.54G [00:21<09:10,\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   6%| | 246M/4.03G [00:21<09:28,\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [model-00002-of-00004.safetensors]:   5%| | 221M/4.59G [00:21<11:07,\u001b[A\n",
      "\n",
      "\n",
      "Downloading [model-00001-of-00004.safetensors]:   4%| | 185M/4.54G [00:21<09:08,\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:  10%| | 301M/2.99G [00:21<04:31,\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   6%| | 247M/4.03G [00:21<09:30,\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading [model-00001-of-00004.safetensors]:   4%| | 186M/4.54G [00:21<08:55,\u001b[A\u001b[A\u001b[A\n",
      "Downloading [model-00002-of-00004.safetensors]:   5%| | 222M/4.59G [00:21<11:03,\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   6%| | 248M/4.03G [00:21<09:11,\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:  10%| | 303M/2.99G [00:21<04:30,\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading [model-00001-of-00004.safetensors]:   4%| | 187M/4.54G [00:21<08:41,\u001b[A\u001b[A\u001b[A\n",
      "Downloading [model-00002-of-00004.safetensors]:   5%| | 223M/4.59G [00:21<10:32,\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   6%| | 249M/4.03G [00:21<09:16,\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [model-00002-of-00004.safetensors]:   5%| | 224M/4.59G [00:21<10:20,\u001b[A\n",
      "\n",
      "\n",
      "Downloading [model-00001-of-00004.safetensors]:   4%| | 188M/4.54G [00:21<10:50,\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   6%| | 250M/4.03G [00:21<09:08,\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:  10%| | 305M/2.99G [00:21<05:25,\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [model-00002-of-00004.safetensors]:   5%| | 225M/4.59G [00:21<10:11,\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   6%| | 251M/4.03G [00:21<09:01,\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [model-00002-of-00004.safetensors]:   5%| | 226M/4.59G [00:22<09:57,\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:  10%| | 306M/2.99G [00:22<05:48,\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading [model-00001-of-00004.safetensors]:   4%| | 189M/4.54G [00:22<13:26,\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   6%| | 252M/4.03G [00:22<09:06,\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [model-00002-of-00004.safetensors]:   5%| | 227M/4.59G [00:22<09:28,\u001b[A\n",
      "Downloading [model-00002-of-00004.safetensors]:   5%| | 228M/4.59G [00:22<09:04,\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:  10%| | 307M/2.99G [00:22<06:24,\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   6%| | 253M/4.03G [00:22<08:53,\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [model-00002-of-00004.safetensors]:   5%| | 229M/4.59G [00:22<08:59,\u001b[A\n",
      "\n",
      "\n",
      "Downloading [model-00001-of-00004.safetensors]:   4%| | 190M/4.54G [00:22<16:09,\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   6%| | 254M/4.03G [00:22<08:46,\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:  10%| | 308M/2.99G [00:22<06:49,\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [model-00002-of-00004.safetensors]:   5%| | 230M/4.59G [00:22<08:44,\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   6%| | 255M/4.03G [00:22<08:47,\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:  10%| | 309M/2.99G [00:22<07:02,\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   6%| | 256M/4.03G [00:22<08:44,\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading [model-00001-of-00004.safetensors]:   4%| | 191M/4.54G [00:22<17:41,\u001b[A\u001b[A\u001b[A\n",
      "Downloading [model-00002-of-00004.safetensors]:   5%| | 232M/4.59G [00:22<08:19,\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:  10%| | 310M/2.99G [00:22<07:15,\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   6%| | 257M/4.03G [00:22<08:40,\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [model-00002-of-00004.safetensors]:   5%| | 234M/4.59G [00:22<07:54,\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   6%| | 258M/4.03G [00:22<08:30,\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading [model-00001-of-00004.safetensors]:   4%| | 192M/4.54G [00:23<18:42,\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:  10%| | 311M/2.99G [00:22<07:31,\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   6%| | 259M/4.03G [00:23<08:23,\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [model-00002-of-00004.safetensors]:   5%| | 236M/4.59G [00:23<07:34,\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:  10%| | 312M/2.99G [00:23<07:34,\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   6%| | 260M/4.03G [00:23<08:30,\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading [model-00001-of-00004.safetensors]:   4%| | 193M/4.54G [00:23<18:59,\u001b[A\u001b[A\u001b[A\n",
      "Downloading [model-00002-of-00004.safetensors]:   5%| | 238M/4.59G [00:23<07:17,\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:  10%| | 313M/2.99G [00:23<07:35,\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   6%| | 261M/4.03G [00:23<08:26,\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [model-00002-of-00004.safetensors]:   5%| | 240M/4.59G [00:23<06:58,\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   6%| | 262M/4.03G [00:23<08:20,\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:  10%| | 314M/2.99G [00:23<07:37,\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading [model-00001-of-00004.safetensors]:   4%| | 194M/4.54G [00:23<19:25,\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   6%| | 263M/4.03G [00:23<08:16,\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [model-00002-of-00004.safetensors]:   5%| | 242M/4.59G [00:23<06:42,\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:  10%| | 315M/2.99G [00:23<07:30,\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   6%| | 264M/4.03G [00:23<08:13,\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [model-00002-of-00004.safetensors]:   5%| | 244M/4.59G [00:23<06:26,\u001b[A\n",
      "\n",
      "\n",
      "Downloading [model-00001-of-00004.safetensors]:   4%| | 195M/4.54G [00:23<19:19,\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:  10%| | 316M/2.99G [00:23<07:29,\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   6%| | 265M/4.03G [00:23<08:13,\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [model-00002-of-00004.safetensors]:   5%| | 246M/4.59G [00:23<06:13,\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   6%| | 266M/4.03G [00:23<08:06,\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:  10%| | 317M/2.99G [00:23<07:25,\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading [model-00001-of-00004.safetensors]:   4%| | 196M/4.54G [00:24<19:07,\u001b[A\u001b[A\u001b[A\n",
      "Downloading [model-00002-of-00004.safetensors]:   5%| | 248M/4.59G [00:24<05:58,\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   6%| | 267M/4.03G [00:24<08:01,\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:  10%| | 318M/2.99G [00:24<07:26,\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   6%| | 268M/4.03G [00:24<08:02,\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [model-00002-of-00004.safetensors]:   5%| | 250M/4.59G [00:24<06:14,\u001b[A\n",
      "\n",
      "\n",
      "Downloading [model-00001-of-00004.safetensors]:   4%| | 197M/4.54G [00:24<18:52,\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:  10%| | 319M/2.99G [00:24<07:13,\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   7%| | 269M/4.03G [00:24<07:58,\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   7%| | 270M/4.03G [00:24<07:51,\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:  10%| | 320M/2.99G [00:24<08:08,\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   7%| | 271M/4.03G [00:24<07:42,\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [model-00002-of-00004.safetensors]:   5%| | 252M/4.59G [00:24<07:55,\u001b[A\n",
      "\n",
      "\n",
      "Downloading [model-00001-of-00004.safetensors]:   4%| | 198M/4.54G [00:24<20:07,\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   7%| | 272M/4.03G [00:24<07:36,\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:  10%| | 321M/2.99G [00:24<08:47,\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   7%| | 273M/4.03G [00:24<07:38,\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading [model-00001-of-00004.safetensors]:   4%| | 199M/4.54G [00:25<20:55,\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   7%| | 274M/4.03G [00:24<07:41,\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:  11%| | 322M/2.99G [00:24<09:00,\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [model-00002-of-00004.safetensors]:   5%| | 254M/4.59G [00:24<09:55,\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   7%| | 275M/4.03G [00:25<07:38,\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:  11%| | 323M/2.99G [00:25<09:10,\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   7%| | 276M/4.03G [00:25<07:30,\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [model-00002-of-00004.safetensors]:   5%| | 255M/4.59G [00:25<10:32,\u001b[A\n",
      "\n",
      "\n",
      "Downloading [model-00001-of-00004.safetensors]:   4%| | 200M/4.54G [00:25<21:29,\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   7%| | 277M/4.03G [00:25<07:34,\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [model-00002-of-00004.safetensors]:   5%| | 256M/4.59G [00:25<11:12,\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:  11%| | 324M/2.99G [00:25<09:12,\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   7%| | 278M/4.03G [00:25<07:23,\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading [model-00001-of-00004.safetensors]:   4%| | 201M/4.54G [00:25<21:12,\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   7%| | 279M/4.03G [00:25<07:18,\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [model-00002-of-00004.safetensors]:   5%| | 257M/4.59G [00:25<11:42,\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:  11%| | 325M/2.99G [00:25<09:14,\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   7%| | 280M/4.03G [00:25<07:13,\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [model-00002-of-00004.safetensors]:   5%| | 258M/4.59G [00:25<12:05,\u001b[A\n",
      "\n",
      "\n",
      "Downloading [model-00001-of-00004.safetensors]:   4%| | 202M/4.54G [00:25<20:51,\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:  11%| | 326M/2.99G [00:25<09:09,\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   7%| | 282M/4.03G [00:25<06:59,\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [model-00002-of-00004.safetensors]:   6%| | 259M/4.59G [00:25<12:17,\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   7%| | 283M/4.03G [00:25<06:54,\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:  11%| | 327M/2.99G [00:25<09:09,\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading [model-00001-of-00004.safetensors]:   4%| | 203M/4.54G [00:26<20:35,\u001b[A\u001b[A\u001b[A\n",
      "Downloading [model-00002-of-00004.safetensors]:   6%| | 260M/4.59G [00:26<12:30,\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   7%| | 285M/4.03G [00:26<06:35,\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:  11%| | 328M/2.99G [00:26<08:53,\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   7%| | 286M/4.03G [00:26<06:35,\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [model-00002-of-00004.safetensors]:   6%| | 261M/4.59G [00:26<12:37,\u001b[A\n",
      "\n",
      "\n",
      "Downloading [model-00001-of-00004.safetensors]:   4%| | 204M/4.54G [00:26<20:09,\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:  11%| | 329M/2.99G [00:26<08:58,\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   7%| | 288M/4.03G [00:26<06:21,\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [model-00002-of-00004.safetensors]:   6%| | 262M/4.59G [00:26<13:25,\u001b[A\n",
      "\n",
      "\n",
      "Downloading [model-00001-of-00004.safetensors]:   4%| | 205M/4.54G [00:26<19:41,\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:  11%| | 330M/2.99G [00:26<08:56,\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   7%| | 290M/4.03G [00:26<06:11,\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [model-00002-of-00004.safetensors]:   6%| | 263M/4.59G [00:26<14:42,\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:  11%| | 331M/2.99G [00:26<08:40,\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   7%| | 292M/4.03G [00:26<05:59,\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading [model-00001-of-00004.safetensors]:   4%| | 206M/4.54G [00:26<19:21,\u001b[A\u001b[A\u001b[A\n",
      "Downloading [model-00002-of-00004.safetensors]:   6%| | 264M/4.59G [00:26<15:17,\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:  11%| | 332M/2.99G [00:26<08:45,\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   7%| | 294M/4.03G [00:26<05:52,\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading [model-00001-of-00004.safetensors]:   4%| | 207M/4.54G [00:27<19:01,\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:  11%| | 333M/2.99G [00:27<08:34,\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   7%| | 296M/4.03G [00:27<05:42,\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [model-00002-of-00004.safetensors]:   6%| | 265M/4.59G [00:27<15:38,\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   7%| | 298M/4.03G [00:27<05:32,\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:  11%| | 334M/2.99G [00:27<08:31,\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading [model-00001-of-00004.safetensors]:   4%| | 208M/4.54G [00:27<18:43,\u001b[A\u001b[A\u001b[A\n",
      "Downloading [model-00002-of-00004.safetensors]:   6%| | 266M/4.59G [00:27<15:51,\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   7%| | 300M/4.03G [00:27<05:16,\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:  11%| | 335M/2.99G [00:27<08:20,\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading [model-00001-of-00004.safetensors]:   4%| | 209M/4.54G [00:27<18:28,\u001b[A\u001b[A\u001b[A\n",
      "Downloading [model-00002-of-00004.safetensors]:   6%| | 267M/4.59G [00:27<15:57,\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   7%| | 302M/4.03G [00:27<05:11,\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:  11%| | 336M/2.99G [00:27<08:19,\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   7%| | 304M/4.03G [00:27<05:03,\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading [model-00001-of-00004.safetensors]:   5%| | 210M/4.54G [00:27<18:22,\u001b[A\u001b[A\u001b[A\n",
      "Downloading [model-00002-of-00004.safetensors]:   6%| | 268M/4.59G [00:27<15:48,\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:  11%| | 337M/2.99G [00:27<08:12,\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   7%| | 306M/4.03G [00:27<04:53,\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:  11%| | 338M/2.99G [00:27<08:03,\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [model-00002-of-00004.safetensors]:   6%| | 269M/4.59G [00:28<15:42,\u001b[A\n",
      "\n",
      "\n",
      "Downloading [model-00001-of-00004.safetensors]:   5%| | 211M/4.54G [00:28<17:56,\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   7%| | 308M/4.03G [00:27<04:45,\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   8%| | 310M/4.03G [00:28<04:34,\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:  11%| | 339M/2.99G [00:28<07:55,\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [model-00002-of-00004.safetensors]:   6%| | 270M/4.59G [00:28<15:38,\u001b[A\n",
      "\n",
      "\n",
      "Downloading [model-00001-of-00004.safetensors]:   5%| | 212M/4.54G [00:28<17:38,\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   8%| | 312M/4.03G [00:28<04:31,\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:  11%| | 340M/2.99G [00:28<07:49,\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   8%| | 314M/4.03G [00:28<04:22,\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [model-00002-of-00004.safetensors]:   6%| | 271M/4.59G [00:28<15:38,\u001b[A\n",
      "\n",
      "\n",
      "Downloading [model-00001-of-00004.safetensors]:   5%| | 213M/4.54G [00:28<17:11,\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:  11%| | 341M/2.99G [00:28<07:47,\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   8%| | 316M/4.03G [00:28<04:13,\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [model-00002-of-00004.safetensors]:   6%| | 272M/4.59G [00:28<15:24,\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   8%| | 318M/4.03G [00:28<04:06,\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:  11%| | 342M/2.99G [00:28<07:40,\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading [model-00001-of-00004.safetensors]:   5%| | 214M/4.54G [00:28<16:56,\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   8%| | 320M/4.03G [00:28<04:02,\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:  11%| | 343M/2.99G [00:28<07:31,\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [model-00002-of-00004.safetensors]:   6%| | 273M/4.59G [00:28<15:12,\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   8%| | 322M/4.03G [00:28<03:53,\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading [model-00001-of-00004.safetensors]:   5%| | 215M/4.54G [00:28<16:41,\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:  11%| | 344M/2.99G [00:28<07:28,\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   8%| | 324M/4.03G [00:28<03:51,\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading [model-00001-of-00004.safetensors]:   5%| | 216M/4.54G [00:29<16:24,\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   8%| | 326M/4.03G [00:29<03:45,\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:  11%| | 345M/2.99G [00:29<07:23,\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   8%| | 328M/4.03G [00:29<03:38,\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [model-00002-of-00004.safetensors]:   6%| | 274M/4.59G [00:29<19:44,\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:  11%| | 346M/2.99G [00:29<07:19,\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading [model-00001-of-00004.safetensors]:   5%| | 217M/4.54G [00:29<16:07,\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   8%| | 330M/4.03G [00:29<03:33,\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   8%| | 332M/4.03G [00:29<03:28,\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:  11%| | 347M/2.99G [00:29<07:12,\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading [model-00001-of-00004.safetensors]:   5%| | 218M/4.54G [00:29<15:46,\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   8%| | 334M/4.03G [00:29<03:28,\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:  11%| | 348M/2.99G [00:29<07:10,\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [model-00002-of-00004.safetensors]:   6%| | 275M/4.59G [00:29<22:04,\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   8%| | 337M/4.03G [00:29<03:16,\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading [model-00001-of-00004.safetensors]:   5%| | 219M/4.54G [00:29<15:25,\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:  11%| | 349M/2.99G [00:29<07:04,\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   8%| | 339M/4.03G [00:29<03:17,\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:  11%| | 350M/2.99G [00:29<06:59,\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading [model-00001-of-00004.safetensors]:   5%| | 220M/4.54G [00:29<15:05,\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   8%| | 342M/4.03G [00:29<03:07,\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [model-00002-of-00004.safetensors]:   6%| | 276M/4.59G [00:29<23:22,\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:  11%| | 351M/2.99G [00:29<06:59,\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   8%| | 345M/4.03G [00:30<03:03,\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading [model-00001-of-00004.safetensors]:   5%| | 221M/4.54G [00:30<14:59,\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:  11%| | 352M/2.99G [00:30<06:49,\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   8%| | 348M/4.03G [00:30<03:01,\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading [model-00001-of-00004.safetensors]:   5%| | 222M/4.54G [00:30<14:39,\u001b[A\u001b[A\u001b[A\n",
      "Downloading [model-00002-of-00004.safetensors]:   6%| | 277M/4.59G [00:30<23:45,\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   8%| | 351M/4.03G [00:30<02:57,\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:  12%| | 353M/2.99G [00:30<06:49,\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   9%| | 354M/4.03G [00:30<02:55,\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading [model-00001-of-00004.safetensors]:   5%| | 223M/4.54G [00:30<14:23,\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:  12%| | 354M/2.99G [00:30<06:43,\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   9%| | 357M/4.03G [00:30<02:51,\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [model-00002-of-00004.safetensors]:   6%| | 278M/4.59G [00:30<23:46,\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:  12%| | 355M/2.99G [00:30<06:40,\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading [model-00001-of-00004.safetensors]:   5%| | 224M/4.54G [00:30<14:22,\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   9%| | 360M/4.03G [00:30<02:40,\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:  12%| | 356M/2.99G [00:30<06:37,\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   9%| | 363M/4.03G [00:30<02:34,\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading [model-00001-of-00004.safetensors]:   5%| | 225M/4.54G [00:30<13:58,\u001b[A\u001b[A\u001b[A\n",
      "Downloading [model-00002-of-00004.safetensors]:   6%| | 279M/4.59G [00:30<23:31,\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:  12%| | 357M/2.99G [00:30<06:36,\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   9%| | 366M/4.03G [00:30<02:31,\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading [model-00001-of-00004.safetensors]:   5%| | 226M/4.54G [00:31<13:46,\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:  12%| | 358M/2.99G [00:30<06:24,\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   9%| | 369M/4.03G [00:31<02:32,\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   9%| | 372M/4.03G [00:31<02:31,\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:  12%| | 359M/2.99G [00:31<06:26,\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading [model-00001-of-00004.safetensors]:   5%| | 227M/4.54G [00:31<13:40,\u001b[A\u001b[A\u001b[A\n",
      "Downloading [model-00002-of-00004.safetensors]:   6%| | 280M/4.59G [00:31<22:58,\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   9%| | 376M/4.03G [00:31<02:21,\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:  12%| | 360M/2.99G [00:31<06:21,\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading [model-00001-of-00004.safetensors]:   5%| | 228M/4.54G [00:31<13:21,\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   9%| | 379M/4.03G [00:31<02:22,\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:  12%| | 361M/2.99G [00:31<06:20,\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [model-00002-of-00004.safetensors]:   6%| | 281M/4.59G [00:31<22:28,\u001b[A\n",
      "\n",
      "\n",
      "Downloading [model-00001-of-00004.safetensors]:   5%| | 229M/4.54G [00:31<13:09,\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   9%| | 383M/4.03G [00:31<02:27,\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:  12%| | 362M/2.99G [00:31<06:17,\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00003-of-00004.safetensors]:   9%| | 386M/4.03G [00:31<02:30,\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading [model-00001-of-00004.safetensors]:   5%| | 230M/4.54G [00:31<13:09,\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading [model-00004-of-00004.safetensors]:  12%| | 363M/2.99G [00:31<06:13,\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading [model-00002-of-00004.safetensors]:   6%| | 282M/4.59G [00:31<21:50,\u001b[A"
     ]
    }
   ],
   "source": [
    "!modelscope download --model OpenBMB/MiniCPM-o-2_6 --local_dir ./minicpmv_o_2_6_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "72c01e58-144c-4e29-bf55-67f3ced76e43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " _   .-')                _ .-') _     ('-.             .-')                              _ (`-.    ('-.\n",
      "( '.( OO )_             ( (  OO) )  _(  OO)           ( OO ).                           ( (OO  ) _(  OO)\n",
      " ,--.   ,--.).-'),-----. \\     .'_ (,------.,--.     (_)---\\_)   .-----.  .-'),-----.  _.`     \\(,------.\n",
      " |   `.'   |( OO'  .-.  ',`'--..._) |  .---'|  |.-') /    _ |   '  .--./ ( OO'  .-.  '(__...--'' |  .---'\n",
      " |         |/   |  | |  ||  |  \\  ' |  |    |  | OO )\\  :` `.   |  |('-. /   |  | |  | |  /  | | |  |\n",
      " |  |'.'|  |\\_) |  |\\|  ||  |   ' |(|  '--. |  |`-' | '..`''.) /_) |OO  )\\_) |  |\\|  | |  |_.' |(|  '--.\n",
      " |  |   |  |  \\ |  | |  ||  |   / : |  .--'(|  '---.'.-._)   \\ ||  |`-'|   \\ |  | |  | |  .___.' |  .--'\n",
      " |  |   |  |   `'  '-'  '|  '--'  / |  `---.|      | \\       /(_'  '--'\\    `'  '-'  ' |  |      |  `---.\n",
      " `--'   `--'     `-----' `-------'  `------'`------'  `-----'    `-----'      `-----'  `--'      `------'\n",
      "\n",
      "Downloading Model from https://www.modelscope.cn to directory: /teamspace/studios/this_studio/.cache/modelscope/hub/models/OpenBMB/MiniCPM-o-2_6\n",
      "\n",
      "Successfully Downloaded from model OpenBMB/MiniCPM-o-2_6.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!modelscope download --model OpenBMB/MiniCPM-o-2_6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7cda7dbc-d7e3-4680-bde5-52e9a25d6fbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "README.md\t\t\t  model.safetensors.index.json\n",
      "added_tokens.json\t\t  modeling_minicpmo.py\n",
      "assets\t\t\t\t  modeling_navit_siglip.py\n",
      "config.json\t\t\t  preprocessor_config.json\n",
      "configuration.json\t\t  processing_minicpmo.py\n",
      "configuration_minicpm.py\t  resampler.py\n",
      "image_processing_minicpmv.py\t  special_tokens_map.json\n",
      "merges.txt\t\t\t  tokenization_minicpmo_fast.py\n",
      "model-00001-of-00004.safetensors  tokenizer.json\n",
      "model-00002-of-00004.safetensors  tokenizer_config.json\n",
      "model-00003-of-00004.safetensors  utils.py\n",
      "model-00004-of-00004.safetensors  vocab.json\n"
     ]
    }
   ],
   "source": [
    "!ls /teamspace/studios/this_studio/.cache/modelscope/hub/models/OpenBMB/MiniCPM-o-2_6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ecba8a-7e56-4d62-9a6d-b4cec43d99b8",
   "metadata": {},
   "source": [
    "# inference : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "203fd430-3b18-4adb-b040-3e63f5fa33af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.7.0+cu126\n",
      "CUDA version: 12.6\n",
      "CUDA available: True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA version: {torch.version.cuda}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "840c8ce0-a960-4b00-84de-750241317c1e",
   "metadata": {},
   "source": [
    "## exp 1 :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb930f7-2033-457c-b4a8-5c309f983160",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install llama-cpp-python --prefer-binary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a673b0-bbd2-410f-86cc-1bdc82f748cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ubuntu/Debian\n",
    "!sudo apt update\n",
    "!sudo apt install -y build-essential cmake python3-dev libopenblas-dev\n",
    "\n",
    "# Optional: For faster compilation\n",
    "!pip install ninja\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b33bf03-0546-4a41-83b1-70c5966ee943",
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo apt update\n",
    "!sudo apt install -y libomp-dev\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09485a05-6bf8-4439-b4bd-4ef746de0362",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install llama-cpp-python==0.3.9\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b417fc8-961a-4086-970f-1ca57a56081b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'llama_cpp'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mllama_cpp\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Llama\n\u001b[1;32m      2\u001b[0m model_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/teamspace/studios/this_studio/.cache/modelscope/hub/models/OpenBMB/MiniCPM-o-2_6-gguf\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      3\u001b[0m llm \u001b[38;5;241m=\u001b[39m Llama(model_path\u001b[38;5;241m=\u001b[39mmodel_path, n_ctx\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2048\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'llama_cpp'"
     ]
    }
   ],
   "source": [
    "from llama_cpp import Llama\n",
    "model_path = \"/teamspace/studios/this_studio/.cache/modelscope/hub/models/OpenBMB/MiniCPM-o-2_6-gguf\"\n",
    "llm = Llama(model_path=model_path, n_ctx=2048)\n",
    "your_image_tensor = \"1131w-uHRaEYx8dVI (1).webp\"\n",
    "output = llm(\"What is in this image?\", images=[your_image_tensor])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9b3032-7ce2-4410-b9f2-c4b75ac20e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_cpp import Llama\n",
    "\n",
    "llm = Llama(\n",
    "      model_path=\"./models/7B/llama-model.gguf\",\n",
    "      # n_gpu_layers=-1, # Uncomment to use GPU acceleration\n",
    "      # seed=1337, # Uncomment to set a specific seed\n",
    "      # n_ctx=2048, # Uncomment to increase the context window\n",
    ")\n",
    "output = llm(\n",
    "      \"Q: Name the planets in the solar system? A: \", # Prompt\n",
    "      max_tokens=32, # Generate up to 32 tokens, set to None to generate up to the end of the context window\n",
    "      stop=[\"Q:\", \"\\n\"], # Stop generating just before the model would generate a new question\n",
    "      echo=True # Echo the prompt back in the output\n",
    ") # Generate a completion, can also call create_completion\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd724e5-bd2d-440c-8033-a020e3b2a87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------the previous was just trying----------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c563b9e-2e57-4df2-be8a-c5af14c64d16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bd582895-056b-4194-9e8f-8387ed237019",
   "metadata": {},
   "source": [
    "## MiniCPM-V-2_6 :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "20f70524-05fa-4d30-aaf4-0074c8ddb302",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/teamspace/studios/this_studio\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8cc89fc2-2eb1-49b5-9671-26af0b2d13dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting addict\n",
      "  Downloading addict-2.4.0-py3-none-any.whl.metadata (1.0 kB)\n",
      "Downloading addict-2.4.0-py3-none-any.whl (3.8 kB)\n",
      "Installing collected packages: addict\n",
      "Successfully installed addict-2.4.0\n"
     ]
    }
   ],
   "source": [
    "!pip install addict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd5307f-f589-4d18-b507-33600200b216",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e02c25-1eb2-4de0-aa47-7e97d94de1ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test.py\n",
    "import torch\n",
    "from PIL import Image\n",
    "from modelscope import AutoModel, AutoTokenizer\n",
    "\n",
    "my_model_dir = \"/teamspace/studios/this_studio/my_model/MiniCPM-V-2_6\"\n",
    "model = AutoModel.from_pretrained(my_model_dir, trust_remote_code=True,\n",
    "    attn_implementation='sdpa', torch_dtype=torch.bfloat16) # sdpa or flash_attention_2, no eager\n",
    "model = model.eval().cuda()\n",
    "tokenizer = AutoTokenizer.from_pretrained(my_model_dir, trust_remote_code=True)\n",
    "\n",
    "image = Image.open('1131w-uHRaEYx8dVI (1).webp').convert('RGB')\n",
    "question = 'What is in the image?'\n",
    "msgs = [{'role': 'user', 'content': [image, question]}]\n",
    "\n",
    "res = model.chat(\n",
    "    image=None,\n",
    "    msgs=msgs,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "print(res)\n",
    "\n",
    "## if you want to use streaming, please make sure sampling=True and stream=True\n",
    "## the model.chat will return a generator\n",
    "\"\"\"\n",
    "res = model.chat(\n",
    "    image=None,\n",
    "    msgs=msgs,\n",
    "    tokenizer=tokenizer,\n",
    "    sampling=True,\n",
    "    stream=True\n",
    ")\n",
    "\n",
    "generated_text = \"\"\n",
    "for new_text in res:\n",
    "    generated_text += new_text\n",
    "    print(new_text, flush=True, end='')\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0f487f9-464b-4adb-889f-189f4c7576e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The image is a resume of an individual named Célia Naudin, who has experience in communication and marketing.\n"
     ]
    }
   ],
   "source": [
    "image = Image.open('1131w-uHRaEYx8dVI (1).webp').convert('RGB')\n",
    "question = 'What is in the image?'\n",
    "msgs = [{'role': 'user', 'content': [image, question]}]\n",
    "\n",
    "res = model.chat(\n",
    "    image=None,\n",
    "    msgs=msgs,\n",
    "    tokenizer=tokenizer,\n",
    "    system_prompt=\"you a professional OCR \"\n",
    ")\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1653f22-6343-487e-b77c-73606b13cd18",
   "metadata": {},
   "source": [
    "the following command for verifying if a problem is in flash attention :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d594522c-f669-44b0-a8f1-51c5fcb973e6",
   "metadata": {},
   "source": [
    "the previous command mention that there s a problem with flash attention , so do this command :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce3d816-e9ba-47a6-8618-2b22a43c042e",
   "metadata": {},
   "source": [
    "## OpenBMB/MiniCPM-o-2_6 :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed9e82c5-cec1-4d1d-97ce-61782b2a66d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/transformers/models/auto/image_processing_auto.py:513: FutureWarning: The image_processor_class argument is deprecated and will be removed in v4.42. Please use `slow_image_processor_class`, or `fast_image_processor_class` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "786de228e06d4a6b96963552274a4530",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `seen_tokens` attribute is deprecated and will be removed in v4.41. Use the `cache_position` model input instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the response of the model is :  The image is a resume (CV) for Célia Naudin. It includes her contact information, experiences, languages spoken, hobbies, education background, and skills.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nres = model.chat(\\n    image=None,\\n    msgs=msgs,\\n    tokenizer=tokenizer,\\n    sampling=True,\\n    stream=True\\n)\\n\\ngenerated_text = \"\"\\nfor new_text in res:\\n    generated_text += new_text\\n    print(new_text, flush=True, end=\\'\\')\\n\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test.py\n",
    "import torch\n",
    "from PIL import Image\n",
    "from modelscope import AutoModel, AutoTokenizer\n",
    "\n",
    "# to see the path you can execute the download command :\n",
    "\n",
    "my_model_dir = \"/teamspace/studios/this_studio/.cache/modelscope/hub/models/OpenBMB/MiniCPM-o-2_6\"\n",
    "\n",
    "model = AutoModel.from_pretrained(\n",
    "    my_model_dir,\n",
    "    trust_remote_code=True,\n",
    "    attn_implementation='sdpa', # sdpa or flash_attention_2\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    init_vision=True,\n",
    "    init_audio=True,\n",
    "    init_tts=True\n",
    ")\n",
    "model = model.eval().cuda()\n",
    "tokenizer = AutoTokenizer.from_pretrained(my_model_dir, trust_remote_code=True)\n",
    "\n",
    "# In addition to vision-only mode, tts processor and vocos also needs to be initialized\n",
    "model.init_tts()\n",
    "\n",
    "image = Image.open('1131w-uHRaEYx8dVI (1).webp').convert('RGB')\n",
    "question = 'What is in the image?'\n",
    "msgs = [{'role': 'user', 'content': [image, question]}]\n",
    "\n",
    "res = model.chat(\n",
    "    image=None,\n",
    "    msgs=msgs,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "print(\"the response of the model is : \",res)\n",
    "\n",
    "## if you want to use streaming, please make sure sampling=True and stream=True\n",
    "## the model.chat will return a generator\n",
    "\"\"\"\n",
    "res = model.chat(\n",
    "    image=None,\n",
    "    msgs=msgs,\n",
    "    tokenizer=tokenizer,\n",
    "    sampling=True,\n",
    "    stream=True\n",
    ")\n",
    "\n",
    "generated_text = \"\"\n",
    "for new_text in res:\n",
    "    generated_text += new_text\n",
    "    print(new_text, flush=True, end='')\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96bbb5ba-e80f-4bbc-a10d-87ecf6f40b6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the response of the model is :  L'image montre un CV de Célia Naudin, qui occupe le poste de Chargée de communication. Le document présente ses expériences professionnelles, ses compétences linguistiques et éducatives, ses centres d'intérêt et ses compétences.\n",
      "\n",
      "### Expériences\n",
      "- **Groupe Frame (2021 - 2026)**\n",
      "  - Chargée de communication\n",
      "  - Gestion de la stratégie de communication\n",
      "  - Développement des réseaux sociaux\n",
      "  - Production de contenus éditoriaux\n",
      "  - Organisation d'événements\n",
      "\n",
      "- **Bancollect (2019 - 2020)**\n",
      "  - Assistante communication en alternance\n",
      "  - Création et publication de contenu\n",
      "  - Participation à des projets de marketing\n",
      "  - Veille sur les tendances des réseaux sociaux\n",
      "\n",
      "### Éducation\n",
      "- **École Amédé Autran (2017 - 2020)**\n",
      "  - Master communication en alternance\n",
      "  - Licence marketing digital\n",
      "\n",
      "### Langues\n",
      "- Français courant\n",
      "- Anglais courant\n",
      "- Espagnol\n",
      "\n",
      "### Loisirs\n",
      "- Mode\n",
      "- Photographie\n",
      "- Voyage\n",
      "\n",
      "### Compétences\n",
      "- Réseaux sociaux\n",
      "- Graphisme\n",
      "- Référencement\n",
      "- Vidéo\n",
      "\n",
      "Le CV est bien organisé, mettant en avant les compétences et les responsabilités de Célia Naudin dans le domaine de la communication professionnelle.\n"
     ]
    }
   ],
   "source": [
    "image = Image.open('1131w-uHRaEYx8dVI (1).webp').convert('RGB')\n",
    "question = 'What is in the image?'\n",
    "msgs = [{'role': 'user', 'content': [image, question]},\n",
    "       {'role': 'system', 'content': 'you are a prfessional cv analyser, you will provide the answer in frensh language'}]\n",
    "\n",
    "res = model.chat(\n",
    "    image=None,\n",
    "    msgs=msgs,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "print(\"the response of the model is : \",res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed61f229-6aa7-41e0-a4d2-45bf15330034",
   "metadata": {},
   "source": [
    "## MiniCPM-o-2_6-gguf  :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "32b112d0-57bc-456e-ae55-6ca6987bbf18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/teamspace/studios/this_studio/llama.cpp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/IPython/core/magics/osm.py:417: UserWarning: using dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "%cd /teamspace/studios/this_studio/llama.cpp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cd9ca664-9308-40ed-88e0-8c74e5ed0a57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current directory: /teamspace/studios/this_studio\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "current_dir = os.getcwd()\n",
    "print(f\"Current directory: {current_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fa6d70e1-b190-4686-a59f-c65beee4e17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%rm -rf llama.cpp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fc294b73-ed1f-40f9-8ab2-c16ae5dc40fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/teamspace/studios/this_studio\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f9fdf2da-c030-4078-9a1d-3e13a8d60442",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'llama.cpp'...\n",
      "Warning: Permanently added the ECDSA host key for IP address '140.82.112.3' to the list of known hosts.\n",
      "git@github.com: Permission denied (publickey).\n",
      "fatal: Could not read from remote repository.\n",
      "\n",
      "Please make sure you have the correct access rights\n",
      "and the repository exists.\n",
      "\n",
      "\n",
      "\u001b[38;5;57m\u001b[1m⚡️ Tip\u001b[0m\tConnect GitHub to Studios: \u001b[4mhttps://lightning.ai/younessaznag/home?settings=integrations\u001b[0m\n",
      "\n",
      "[Errno 2] No such file or directory: 'llama.cpp'\n",
      "/teamspace/studios/this_studio\n",
      "fatal: not a git repository (or any parent up to mount point /teamspace/studios)\n",
      "Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/IPython/core/magics/osm.py:393: UserWarning: using bookmarks requires you to install the `pickleshare` library.\n",
      "  bkms = self.shell.db.get('bookmarks', {})\n"
     ]
    }
   ],
   "source": [
    "!git clone git@github.com:OpenBMB/llama.cpp.git\n",
    "%cd llama.cpp\n",
    "!git checkout minicpm-omni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fc499361",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# github.com:22 SSH-2.0-f27bdd3a\n",
      "# github.com:22 SSH-2.0-f27bdd3a\n",
      "# github.com:22 SSH-2.0-f27bdd3a\n",
      "# github.com:22 SSH-2.0-f27bdd3a\n",
      "# github.com:22 SSH-2.0-f27bdd3a\n",
      "Cloning into 'llama.cpp'...\n",
      "git@github.com: Permission denied (publickey).\n",
      "fatal: Could not read from remote repository.\n",
      "\n",
      "Please make sure you have the correct access rights\n",
      "and the repository exists.\n",
      "\n",
      "\n",
      "\u001b[38;5;57m\u001b[1m⚡️ Tip\u001b[0m\tConnect GitHub to Studios: \u001b[4mhttps://lightning.ai/younessaznag/home?settings=integrations\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!mkdir -p ~/.ssh\n",
    "!ssh-keyscan github.com >> ~/.ssh/known_hosts\n",
    "!git clone git@github.com:OpenBMB/llama.cpp.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "288fb090-a4f9-4de5-a79a-324d9748c686",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating public/private ed25519 key pair.\n",
      "Enter file in which to save the key (/home/zeus/.ssh/id_ed25519): ^C\n"
     ]
    }
   ],
   "source": [
    "!ssh-keygen -t ed25519 -C aznag_youness@yahoo.fr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fd750bec-ec55-491d-9e59-94597d9c8888",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'llama.cpp'...\n",
      "git@github.com: Permission denied (publickey).\n",
      "fatal: Could not read from remote repository.\n",
      "\n",
      "Please make sure you have the correct access rights\n",
      "and the repository exists.\n",
      "\n",
      "\n",
      "\u001b[38;5;57m\u001b[1m⚡️ Tip\u001b[0m\tConnect GitHub to Studios: \u001b[4mhttps://lightning.ai/younessaznag/home?settings=integrations\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!git clone git@github.com:OpenBMB/llama.cpp.git\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc703bb-e377-4258-b25b-a4da83248bff",
   "metadata": {},
   "source": [
    "## exp 2 (cv analyser prompt) :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e43aa434-80a3-4443-aaca-2d30c9f3a964",
   "metadata": {},
   "source": [
    "### prompt 1 :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fbcab8a3-4752-412d-8486-3db0c8bd7ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoProcessor, AutoModelForVision2Seq\n",
    "from PIL import Image\n",
    "import torch\n",
    "\n",
    "def build_cv_prompt(job_description: str, language: str = \"en\") -> str:\n",
    "    instructions = {\n",
    "        \"en\": {\n",
    "            \"extract\": \"Extract the following information from the resume:\",\n",
    "            \"fields\": [\n",
    "                \"- Full Name\",\n",
    "                \"- Contact Information (email, phone, LinkedIn, etc.)\",\n",
    "                \"- Education (degree, institution, graduation year)\",\n",
    "                \"- Work Experience (role, company, duration, responsibilities)\",\n",
    "                \"- Skills (technical, soft, languages)\",\n",
    "                \"- Certifications (if any)\",\n",
    "                \"- Projects (if any)\"\n",
    "            ],\n",
    "            \"match\": \"Match the extracted profile against the following job description:\",\n",
    "            \"rate\": \"Rate the candidate's suitability for this job on a scale from 0 to 100.\",\n",
    "            \"justify\": \"Justify your rating using bullet points.\",\n",
    "            \"summarize\": \"Summarize:\",\n",
    "            \"strengths\": \"- Candidate's strengths\",\n",
    "            \"weaknesses\": \"- Candidate's weaknesses\"\n",
    "        },\n",
    "        \"fr\": {\n",
    "            \"extract\": \"Extraire les informations suivantes du CV :\",\n",
    "            \"fields\": [\n",
    "                \"- Nom complet\",\n",
    "                \"- Coordonnées (email, téléphone, LinkedIn, etc.)\",\n",
    "                \"- Formation (diplôme, établissement, année d'obtention)\",\n",
    "                \"- Expérience professionnelle (poste, entreprise, durée, responsabilités)\",\n",
    "                \"- Compétences (techniques, générales, langues)\",\n",
    "                \"- Certifications (le cas échéant)\",\n",
    "                \"- Projets (le cas échéant)\"\n",
    "            ],\n",
    "            \"match\": \"Comparer le profil extrait avec la description de poste suivante :\",\n",
    "            \"rate\": \"Évaluer l'adéquation du candidat pour ce poste sur une échelle de 0 à 100.\",\n",
    "            \"justify\": \"Justifier votre évaluation avec des points clés.\",\n",
    "            \"summarize\": \"Résumer :\",\n",
    "            \"strengths\": \"- Points forts du candidat\",\n",
    "            \"weaknesses\": \"- Points faibles du candidat\"\n",
    "        },\n",
    "        \"es\": {\n",
    "            \"extract\": \"Extraer la siguiente información del currículum:\",\n",
    "            \"fields\": [\n",
    "                \"- Nombre completo\",\n",
    "                \"- Información de contacto (email, teléfono, LinkedIn, etc.)\",\n",
    "                \"- Educación (título, institución, año de graduación)\",\n",
    "                \"- Experiencia laboral (puesto, empresa, duración, responsabilidades)\",\n",
    "                \"- Habilidades (técnicas, blandas, idiomas)\",\n",
    "                \"- Certificaciones (si aplica)\",\n",
    "                \"- Proyectos (si aplica)\"\n",
    "            ],\n",
    "            \"match\": \"Comparar el perfil extraído con la siguiente descripción del puesto:\",\n",
    "            \"rate\": \"Calificar la idoneidad del candidato para este trabajo en una escala de 0 a 100.\",\n",
    "            \"justify\": \"Justificar su calificación con puntos clave.\",\n",
    "            \"summarize\": \"Resumir:\",\n",
    "            \"strengths\": \"- Fortalezas del candidato\",\n",
    "            \"weaknesses\": \"- Debilidades del candidato\"\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Get instructions for the specified language, default to English\n",
    "    lang = instructions.get(language, instructions[\"en\"])\n",
    "    \n",
    "    return f\"\"\"\n",
    "You must / Vous devez / Usted debe:\n",
    "1. {lang['extract']}\n",
    "   {chr(10).join(lang['fields'])}\n",
    "\n",
    "2. {lang['match']}\n",
    "---\n",
    "{job_description}\n",
    "---\n",
    "\n",
    "3. {lang['rate']}\n",
    "\n",
    "4. {lang['justify']}\n",
    "\n",
    "5. {lang['summarize']}\n",
    "   {lang['strengths']}\n",
    "   {lang['weaknesses']}\n",
    "\n",
    "Language of response: {language.upper()}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e4deee5a-9291-494a-8ec3-0c3ae904a7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def analyze_cv(cv_image_path: str, job_description: str, language: str):\n",
    "\n",
    "\n",
    "    # Load image\n",
    "    image = Image.open(cv_image_path).convert(\"RGB\")\n",
    "\n",
    "    # Build prompt\n",
    "    prompt = build_cv_prompt(job_description, language)\n",
    "\n",
    "    msgs = [{'role': 'user', 'content': [image, prompt]},\n",
    "            {'role': 'system', \n",
    "             'content': f\"You are a professional HR assistant AI that can analyze resumes from image input using OCR and answering in {language}.\"}\n",
    "            ]\n",
    "\n",
    "    response = model.chat(\n",
    "        image=None,\n",
    "        msgs=msgs,\n",
    "        tokenizer=tokenizer\n",
    "    )\n",
    "\n",
    "\n",
    "    return response\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6357dd33-0942-47d2-8514-adcdbca1735b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 0:00:39.459047\n",
      "🔍 CV Analysis Result:\n",
      " ### Informations extraites du CV :\n",
      "\n",
      "1. **Nom complet :**\n",
      "   - Célia Naudin\n",
      "\n",
      "2. **Coordonnées :**\n",
      "   - Téléphone : 123-456-7890\n",
      "   - Email : hello@reallygreatsite.com\n",
      "   - Adresse : 123 Anywhere St., Any City\n",
      "\n",
      "3. **Formation :**\n",
      "   - École Amédé Autran (2017 - 2020)\n",
      "   - Master communication en alternance\n",
      "   - Licence marketing digital\n",
      "\n",
      "4. **Expérience professionnelle :**\n",
      "   - **Groupe Frame** (2021 - 2026):\n",
      "     - Chargée de communication:\n",
      "       - Gestion de la stratégie de communication\n",
      "       - Développement des réseaux sociaux\n",
      "       - Production de contenus éditoriaux\n",
      "       - Organisation d'événements\n",
      "   - **Bancollect** (2019 - 2020):\n",
      "     - Assistante communication en alternance:\n",
      "       - Création et publication de contenu\n",
      "       - Participation à des projets de marketing\n",
      "       - Veille sur les tendances des réseaux sociaux\n",
      "\n",
      "5. **Compétences :**\n",
      "   - Réseaux sociaux\n",
      "   - Graphisme\n",
      "   - Référencement\n",
      "   - Vidéo\n",
      "\n",
      "### Comparaison avec le poste de data analyst :\n",
      "\n",
      "Le poste de data analyst exige des compétences en SQL, Python, Power BI ou Tableau, ainsi que de bonnes compétences en communication.\n",
      "\n",
      "### Évaluation de l'adéquation du candidat :\n",
      "\n",
      "Échelle de 0 à 100 : 30\n",
      "\n",
      "#### Justification :\n",
      "\n",
      "1. **Compétences en SQL, Python, Power BI ou Tableau :**\n",
      "   - L'image ne fournit aucune information sur ces compétences spécifiques.\n",
      "   \n",
      "2. **Communication :**\n",
      "   - L'image montre des compétences en communication, mais pas spécifiquement dans le contexte de data analyst.\n",
      "\n",
      "3. **Relevancy of Education:**\n",
      "   - Formation en communication et licence marketing digital suggèrent une forte compétence en marketing et en communication, qui sont essentielles pour un data analyst, mais non suffisantes pour le poste.\n",
      "\n",
      "### Points forts du candidat :\n",
      "\n",
      "- Absence de compétences spécifiques mentionnées dans la demande du poste (SQL, Python, Power BI ou Tableau).\n",
      "- Manque d'informations sur les compétences techniques nécessaires au poste de data analyst.\n",
      "\n",
      "### Points faibles du candidat :\n",
      "\n",
      "- Les compétences en communication et en marketing peuvent être transférables, mais ne sont pas directement liées aux compétences de data analyst.\n",
      "- L'absence de certifications ou de projets spécifiques dans le domaine de la data analytics est un point faible.\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "job = \"\"\"Looking for a data analyst with 3+ years of experience, strong in SQL, Python, and Power BI or Tableau. Good communication skills are a plus.\"\"\"\n",
    "lang = \"fr\"\n",
    "img_path = \"1131w-uHRaEYx8dVI (1).webp\"\n",
    "\n",
    "start = datetime.now()\n",
    "\n",
    "result = analyze_cv(cv_image_path=img_path, job_description=job, language=lang)\n",
    "\n",
    "end = datetime.now()\n",
    "\n",
    "elapsed = end - start\n",
    "print(f\"Elapsed time: {elapsed}\")\n",
    "print(\"🔍 CV Analysis Result:\\n\", result)\n",
    "\n",
    "# Save to a text file\n",
    "with open(\"cv_analysis_output_minicpm_o_2_6.txt\", \"w\", encoding=\"utf-8\") as file:\n",
    "    file.write(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ffa5fdd-235f-4622-871b-76115dedd228",
   "metadata": {},
   "source": [
    "### prompt 2 :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "54f23046-32d9-4133-83d4-18488a4d6636",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "You are a professional AI assistant trained to analyze candidate resumes and provide evaluations strictly in the specified language.\n",
    "\n",
    "## Your Task:\n",
    "Given a job description, evaluation criteria, and a candidate's CV, analyze the resume and return a JSON object with the following structure. The explanation and all textual values (justification, strengths, weaknesses) must be written in this language: **{output_language}**.\n",
    "\n",
    "### Output format (strictly JSON only, no extra text):\n",
    "{{\n",
    "  \"score\": 0,\n",
    "  \"strengths\": [],\n",
    "  \"weaknesses\": [],\n",
    "  \"matched_skills\": [],\n",
    "  \"missing_skills\": [],\n",
    "  \"final_recommendation\": \"\",\n",
    "  \"justification\": \"\"\n",
    "}}\n",
    "\n",
    "## Language:\n",
    "Respond in: **{output_language}**\n",
    "\n",
    "## Job Description:\n",
    "{job_description}\n",
    "\n",
    "## Evaluation Criteria:\n",
    "{evaluation_criteria}\n",
    "# Example:\n",
    "# {{\n",
    "#   \"required_experience_years\": 2,\n",
    "#   \"must_have_skills\": [\"Python\", \"NLP\", \"Transformers\"],\n",
    "#   \"nice_to_have_skills\": [\"Docker\", \"Streamlit\"],\n",
    "#   \"education\": \"Bachelor or higher\",\n",
    "#   \"languages_required\": [\"English\"]\n",
    "# }}\n",
    "\n",
    "IMPORTANT:\n",
    "- ALL text in the JSON fields MUST be written in **{output_language}**.\n",
    "- Do NOT use English. Even justification, strengths, and weaknesses must be fully translated.\n",
    "- Only use {output_language} vocabulary and grammar.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "387d9b65-c0c3-47da-ad62-56bf9876a3cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "You are a professional AI assistant trained to analyze candidate resumes and provide evaluations strictly in the \n",
       "specified language.\n",
       "\n",
       "## Your Task:\n",
       "Given a job description, evaluation criteria, and a candidate's CV, analyze the resume and return a JSON object \n",
       "with the following structure. The explanation and all textual values <span style=\"font-weight: bold\">(</span>justification, strengths, weaknesses<span style=\"font-weight: bold\">)</span> must be\n",
       "written in this language: **French**.\n",
       "\n",
       "### Output format <span style=\"font-weight: bold\">(</span>strictly JSON only, no extra text<span style=\"font-weight: bold\">)</span>:\n",
       "<span style=\"font-weight: bold\">{</span>\n",
       "  <span style=\"color: #008000; text-decoration-color: #008000\">\"score\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,\n",
       "  <span style=\"color: #008000; text-decoration-color: #008000\">\"strengths\"</span>: <span style=\"font-weight: bold\">[]</span>,\n",
       "  <span style=\"color: #008000; text-decoration-color: #008000\">\"weaknesses\"</span>: <span style=\"font-weight: bold\">[]</span>,\n",
       "  <span style=\"color: #008000; text-decoration-color: #008000\">\"matched_skills\"</span>: <span style=\"font-weight: bold\">[]</span>,\n",
       "  <span style=\"color: #008000; text-decoration-color: #008000\">\"missing_skills\"</span>: <span style=\"font-weight: bold\">[]</span>,\n",
       "  <span style=\"color: #008000; text-decoration-color: #008000\">\"final_recommendation\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"\"</span>,\n",
       "  <span style=\"color: #008000; text-decoration-color: #008000\">\"justification\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"\"</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "\n",
       "## Language:\n",
       "Respond in: **French**\n",
       "\n",
       "## Job Description:\n",
       "Looking for a data analyst with <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>+ years of experience, strong in SQL, Python, and Power BI or Tableau. Good \n",
       "communication skills are a plus.\n",
       "\n",
       "## Evaluation Criteria:\n",
       "<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">\"required_experience_years\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"must_have_skills\"</span>: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">\"Python\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"NLP\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"Transformers\"</span><span style=\"font-weight: bold\">]</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"nice_to_have_skills\"</span>: \n",
       "<span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">\"Docker\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"LangChain\"</span><span style=\"font-weight: bold\">]</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"education\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"Master\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"languages_required\"</span>: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">\"Fran\\u00e7ais\"</span><span style=\"font-weight: bold\">]}</span>\n",
       "# Example:\n",
       "# <span style=\"font-weight: bold\">{</span>\n",
       "#   <span style=\"color: #008000; text-decoration-color: #008000\">\"required_experience_years\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>,\n",
       "#   <span style=\"color: #008000; text-decoration-color: #008000\">\"must_have_skills\"</span>: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">\"Python\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"NLP\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"Transformers\"</span><span style=\"font-weight: bold\">]</span>,\n",
       "#   <span style=\"color: #008000; text-decoration-color: #008000\">\"nice_to_have_skills\"</span>: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">\"Docker\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"Streamlit\"</span><span style=\"font-weight: bold\">]</span>,\n",
       "#   <span style=\"color: #008000; text-decoration-color: #008000\">\"education\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"Bachelor or higher\"</span>,\n",
       "#   <span style=\"color: #008000; text-decoration-color: #008000\">\"languages_required\"</span>: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">\"English\"</span><span style=\"font-weight: bold\">]</span>\n",
       "# <span style=\"font-weight: bold\">}</span>\n",
       "\n",
       "IMPORTANT:\n",
       "- ALL text in the JSON fields MUST be written in **French**.\n",
       "- Do NOT use English. Even justification, strengths, and weaknesses must be fully translated.\n",
       "- Only use French vocabulary and grammar.\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "You are a professional AI assistant trained to analyze candidate resumes and provide evaluations strictly in the \n",
       "specified language.\n",
       "\n",
       "## Your Task:\n",
       "Given a job description, evaluation criteria, and a candidate's CV, analyze the resume and return a JSON object \n",
       "with the following structure. The explanation and all textual values \u001b[1m(\u001b[0mjustification, strengths, weaknesses\u001b[1m)\u001b[0m must be\n",
       "written in this language: **French**.\n",
       "\n",
       "### Output format \u001b[1m(\u001b[0mstrictly JSON only, no extra text\u001b[1m)\u001b[0m:\n",
       "\u001b[1m{\u001b[0m\n",
       "  \u001b[32m\"score\"\u001b[0m: \u001b[1;36m0\u001b[0m,\n",
       "  \u001b[32m\"strengths\"\u001b[0m: \u001b[1m[\u001b[0m\u001b[1m]\u001b[0m,\n",
       "  \u001b[32m\"weaknesses\"\u001b[0m: \u001b[1m[\u001b[0m\u001b[1m]\u001b[0m,\n",
       "  \u001b[32m\"matched_skills\"\u001b[0m: \u001b[1m[\u001b[0m\u001b[1m]\u001b[0m,\n",
       "  \u001b[32m\"missing_skills\"\u001b[0m: \u001b[1m[\u001b[0m\u001b[1m]\u001b[0m,\n",
       "  \u001b[32m\"final_recommendation\"\u001b[0m: \u001b[32m\"\"\u001b[0m,\n",
       "  \u001b[32m\"justification\"\u001b[0m: \u001b[32m\"\"\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n",
       "\n",
       "## Language:\n",
       "Respond in: **French**\n",
       "\n",
       "## Job Description:\n",
       "Looking for a data analyst with \u001b[1;36m3\u001b[0m+ years of experience, strong in SQL, Python, and Power BI or Tableau. Good \n",
       "communication skills are a plus.\n",
       "\n",
       "## Evaluation Criteria:\n",
       "\u001b[1m{\u001b[0m\u001b[32m\"required_experience_years\"\u001b[0m: \u001b[1;36m2\u001b[0m, \u001b[32m\"must_have_skills\"\u001b[0m: \u001b[1m[\u001b[0m\u001b[32m\"Python\"\u001b[0m, \u001b[32m\"NLP\"\u001b[0m, \u001b[32m\"Transformers\"\u001b[0m\u001b[1m]\u001b[0m, \u001b[32m\"nice_to_have_skills\"\u001b[0m: \n",
       "\u001b[1m[\u001b[0m\u001b[32m\"Docker\"\u001b[0m, \u001b[32m\"LangChain\"\u001b[0m\u001b[1m]\u001b[0m, \u001b[32m\"education\"\u001b[0m: \u001b[32m\"Master\"\u001b[0m, \u001b[32m\"languages_required\"\u001b[0m: \u001b[1m[\u001b[0m\u001b[32m\"Fran\\u00e7ais\"\u001b[0m\u001b[1m]\u001b[0m\u001b[1m}\u001b[0m\n",
       "# Example:\n",
       "# \u001b[1m{\u001b[0m\n",
       "#   \u001b[32m\"required_experience_years\"\u001b[0m: \u001b[1;36m2\u001b[0m,\n",
       "#   \u001b[32m\"must_have_skills\"\u001b[0m: \u001b[1m[\u001b[0m\u001b[32m\"Python\"\u001b[0m, \u001b[32m\"NLP\"\u001b[0m, \u001b[32m\"Transformers\"\u001b[0m\u001b[1m]\u001b[0m,\n",
       "#   \u001b[32m\"nice_to_have_skills\"\u001b[0m: \u001b[1m[\u001b[0m\u001b[32m\"Docker\"\u001b[0m, \u001b[32m\"Streamlit\"\u001b[0m\u001b[1m]\u001b[0m,\n",
       "#   \u001b[32m\"education\"\u001b[0m: \u001b[32m\"Bachelor or higher\"\u001b[0m,\n",
       "#   \u001b[32m\"languages_required\"\u001b[0m: \u001b[1m[\u001b[0m\u001b[32m\"English\"\u001b[0m\u001b[1m]\u001b[0m\n",
       "# \u001b[1m}\u001b[0m\n",
       "\n",
       "IMPORTANT:\n",
       "- ALL text in the JSON fields MUST be written in **French**.\n",
       "- Do NOT use English. Even justification, strengths, and weaknesses must be fully translated.\n",
       "- Only use French vocabulary and grammar.\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import json\n",
    "from rich import print\n",
    "\n",
    "job = \"\"\"Looking for a data analyst with 3+ years of experience, strong in SQL, Python, and Power BI or Tableau. Good communication skills are a plus.\"\"\"\n",
    "lang = \"French\"\n",
    "\n",
    "prompt = text.format(\n",
    "    job_description=job,\n",
    "    evaluation_criteria=json.dumps({\n",
    "        \"required_experience_years\": 2,\n",
    "        \"must_have_skills\": [\"Python\", \"NLP\", \"Transformers\"],\n",
    "        \"nice_to_have_skills\": [\"Docker\", \"LangChain\"],\n",
    "        \"education\": \"Master\",\n",
    "        \"languages_required\": [\"Français\"]\n",
    "    }),\n",
    "    output_language=lang\n",
    ")\n",
    "\n",
    "print(prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4724487a-a0da-4b5f-b4f6-e68db5d2d1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def analyze_cv(cv_image_path=img_path, job_description=job, language=lang):\n",
    "    \n",
    "    prompt = text.format(\n",
    "            job_description=job,\n",
    "            evaluation_criteria=json.dumps({\n",
    "                \"required_experience_years\": 2,\n",
    "                \"must_have_skills\": [\"Python\", \"NLP\", \"Transformers\"],\n",
    "                \"nice_to_have_skills\": [\"Docker\", \"LangChain\"],\n",
    "                \"education\": \"Master\",\n",
    "                \"languages_required\": [\"Français\"]\n",
    "            }),\n",
    "            output_language=lang\n",
    "    )\n",
    "\n",
    "        # Load image\n",
    "    image = Image.open(cv_image_path).convert(\"RGB\")\n",
    "\n",
    "    # Build prompt\n",
    "    prompt = build_cv_prompt(job_description)\n",
    "    msgs = [{'role': 'user', 'content': [image, prompt]}\n",
    "            ]\n",
    "\n",
    "    response = model.chat(\n",
    "        image=None,\n",
    "        msgs=msgs,\n",
    "        tokenizer=tokenizer,\n",
    "    )\n",
    "\n",
    "\n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fb618806-956e-4b78-9518-90ee789d4b96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Elapsed time: <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">0:00:34</span>.<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">705085</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Elapsed time: \u001b[1;92m0:00:34\u001b[0m.\u001b[1;36m705085\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">🔍 CV Analysis Result:\n",
       " ### Extracted Information:\n",
       "\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>. **Full Name**: Célia Naudin\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>. **Contact Information**:\n",
       "   - Email: hello@reallygreatsite.com\n",
       "   - Phone: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">123</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">456</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7890</span>\n",
       "   - Address: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">123</span> Anywhere St., Any City\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>. **Education**:\n",
       "   - École Amédé Autran <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2017</span> - <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2020</span><span style=\"font-weight: bold\">)</span>\n",
       "   - Master in Communication en alternance\n",
       "   - Licence Marketing Digital\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>. **Work Experience**:\n",
       "   - **Groupe Frame <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2021</span> - <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2026</span><span style=\"font-weight: bold\">)</span>**: Chargée de communication\n",
       "     - Management of communication strategy\n",
       "     - Development of social networks\n",
       "     - Content editorial production\n",
       "     - Event organization\n",
       "   - **Bancollect <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2019</span> - <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2020</span><span style=\"font-weight: bold\">)</span>**: Assistant Communication en alternance\n",
       "     - Content creation and publication\n",
       "     - Participation in marketing projects\n",
       "     - Monitoring trends on social networks\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>. **Skills**:\n",
       "   - Languages: French, English, Spanish\n",
       "   - Competencies: Social media, Graphic design, SEO, Video\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span>. **Certifications/Projects**: Not specified\n",
       "\n",
       "### Job Match Analysis:\n",
       "\n",
       "The job description is for a data analyst with experience in SQL, Python, Power BI, or Tableau.\n",
       "\n",
       "- **Relevance to Job Description**:\n",
       "  - The resume does not mention any specific technical skills like SQL, Python, Power BI, or Tableau.\n",
       "  - There are no certifications related to data analysis mentioned.\n",
       "\n",
       "### Suitability Rating <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span><span style=\"font-weight: bold\">)</span>:\n",
       "\n",
       "**Rating: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span>**\n",
       "\n",
       "### Justification:\n",
       "\n",
       "- **Strengths**:\n",
       "  - Strong background in communications and digital marketing.\n",
       "  - Proficient in multiple languages including English and Spanish.\n",
       "  - Demonstrated ability to manage content strategies and organize events.\n",
       "\n",
       "- **Weaknesses**:\n",
       "  - Lack of relevant technical skills such as SQL, Python, Power BI, or Tableau.\n",
       "  - No evidence of education or work experience directly related to data analysis.\n",
       "  - No certifications that indicate proficiency in data-related tools or methodologies.\n",
       "\n",
       "### Summary:\n",
       "\n",
       "**Strengths**:\n",
       "- Effective communicator with strong organizational skills.\n",
       "- Multilingual capabilities can be beneficial in diverse teams.\n",
       "- Familiarity with graphic design and video editing could complement certain aspects of data visualization.\n",
       "\n",
       "**Weaknesses**:\n",
       "- Inadequate preparation for roles requiring advanced technical expertise in data analytics.\n",
       "- Limited professional exposure to the required skill set according to the job description.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "🔍 CV Analysis Result:\n",
       " ### Extracted Information:\n",
       "\n",
       "\u001b[1;36m1\u001b[0m. **Full Name**: Célia Naudin\n",
       "\u001b[1;36m2\u001b[0m. **Contact Information**:\n",
       "   - Email: hello@reallygreatsite.com\n",
       "   - Phone: \u001b[1;36m123\u001b[0m-\u001b[1;36m456\u001b[0m-\u001b[1;36m7890\u001b[0m\n",
       "   - Address: \u001b[1;36m123\u001b[0m Anywhere St., Any City\n",
       "\u001b[1;36m3\u001b[0m. **Education**:\n",
       "   - École Amédé Autran \u001b[1m(\u001b[0m\u001b[1;36m2017\u001b[0m - \u001b[1;36m2020\u001b[0m\u001b[1m)\u001b[0m\n",
       "   - Master in Communication en alternance\n",
       "   - Licence Marketing Digital\n",
       "\u001b[1;36m4\u001b[0m. **Work Experience**:\n",
       "   - **Groupe Frame \u001b[1m(\u001b[0m\u001b[1;36m2021\u001b[0m - \u001b[1;36m2026\u001b[0m\u001b[1m)\u001b[0m**: Chargée de communication\n",
       "     - Management of communication strategy\n",
       "     - Development of social networks\n",
       "     - Content editorial production\n",
       "     - Event organization\n",
       "   - **Bancollect \u001b[1m(\u001b[0m\u001b[1;36m2019\u001b[0m - \u001b[1;36m2020\u001b[0m\u001b[1m)\u001b[0m**: Assistant Communication en alternance\n",
       "     - Content creation and publication\n",
       "     - Participation in marketing projects\n",
       "     - Monitoring trends on social networks\n",
       "\u001b[1;36m5\u001b[0m. **Skills**:\n",
       "   - Languages: French, English, Spanish\n",
       "   - Competencies: Social media, Graphic design, SEO, Video\n",
       "\u001b[1;36m6\u001b[0m. **Certifications/Projects**: Not specified\n",
       "\n",
       "### Job Match Analysis:\n",
       "\n",
       "The job description is for a data analyst with experience in SQL, Python, Power BI, or Tableau.\n",
       "\n",
       "- **Relevance to Job Description**:\n",
       "  - The resume does not mention any specific technical skills like SQL, Python, Power BI, or Tableau.\n",
       "  - There are no certifications related to data analysis mentioned.\n",
       "\n",
       "### Suitability Rating \u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m-\u001b[1;36m100\u001b[0m\u001b[1m)\u001b[0m:\n",
       "\n",
       "**Rating: \u001b[1;36m20\u001b[0m**\n",
       "\n",
       "### Justification:\n",
       "\n",
       "- **Strengths**:\n",
       "  - Strong background in communications and digital marketing.\n",
       "  - Proficient in multiple languages including English and Spanish.\n",
       "  - Demonstrated ability to manage content strategies and organize events.\n",
       "\n",
       "- **Weaknesses**:\n",
       "  - Lack of relevant technical skills such as SQL, Python, Power BI, or Tableau.\n",
       "  - No evidence of education or work experience directly related to data analysis.\n",
       "  - No certifications that indicate proficiency in data-related tools or methodologies.\n",
       "\n",
       "### Summary:\n",
       "\n",
       "**Strengths**:\n",
       "- Effective communicator with strong organizational skills.\n",
       "- Multilingual capabilities can be beneficial in diverse teams.\n",
       "- Familiarity with graphic design and video editing could complement certain aspects of data visualization.\n",
       "\n",
       "**Weaknesses**:\n",
       "- Inadequate preparation for roles requiring advanced technical expertise in data analytics.\n",
       "- Limited professional exposure to the required skill set according to the job description.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "start = datetime.now()\n",
    "\n",
    "\n",
    "\n",
    "job = \"\"\"Looking for a data analyst with 3+ years of experience, strong in SQL, Python, and Power BI or Tableau. Good communication skills are a plus.\"\"\"\n",
    "lang = \"French\"\n",
    "img_path = \"1131w-uHRaEYx8dVI (1).webp\"\n",
    "\n",
    "result = analyze_cv(cv_image_path=img_path, job_description=job, language=lang)\n",
    "\n",
    "\n",
    "end = datetime.now()\n",
    "\n",
    "elapsed = end - start\n",
    "print(f\"Elapsed time: {elapsed}\")\n",
    "print(\"🔍 CV Analysis Result:\\n\", result)\n",
    "\n",
    "# Save to a text file\n",
    "with open(\"cv_analysis_output_minicpm_o_2_6.txt\", \"w\", encoding=\"utf-8\") as file:\n",
    "    file.write(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ca254275-b10c-4223-b203-6cd14547b4d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cdfb071-912d-4dbc-b05e-3cf293df2a0d",
   "metadata": {},
   "source": [
    "### prompt 3 :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f00a351-58f5-4186-8b46-a4b53e6782af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field, ValidationError\n",
    "from typing import List, Optional, Literal\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "import torch\n",
    "from PIL import Image\n",
    "import json\n",
    "import re\n",
    "\n",
    "# --- Pydantic Models for Structured Output ---\n",
    "class PersonalInfo(BaseModel):\n",
    "    full_name: str = Field(..., description=\"Candidate's full name\")\n",
    "    email: Optional[str] = Field(None, description=\"Contact email\")\n",
    "    phone: Optional[str] = Field(None, description=\"Phone number\")\n",
    "    location: Optional[str] = Field(None, description=\"Current location\")\n",
    "    linkedin: Optional[str] = Field(None, description=\"LinkedIn URL\")\n",
    "    github: Optional[str] = Field(None, description=\"GitHub URL\")\n",
    "\n",
    "class EducationEntry(BaseModel):\n",
    "    institution: str = Field(..., description=\"School/university name\")\n",
    "    degree: Literal[\"bachelor\", \"master\", \"phd\", \"diploma\", \"certificate\", \"associate\", \"other\"] = Field(..., description=\"Degree level\")\n",
    "    field_of_study: str = Field(..., description=\"Major/specialization\")\n",
    "    start_year: int = Field(..., description=\"Start year\")\n",
    "    end_year: Optional[int] = Field(None, description=\"Graduation year\")\n",
    "\n",
    "class WorkExperienceEntry(BaseModel):\n",
    "    company: str = Field(..., description=\"Employer name\")\n",
    "    position: str = Field(..., description=\"Job title\")\n",
    "    start_date: str = Field(..., description=\"Start date (MM/YYYY)\")\n",
    "    end_date: Optional[str] = Field(None, description=\"End date (MM/YYYY or 'Present')\")\n",
    "    responsibilities: List[str] = Field(..., description=\"Key achievements\")\n",
    "\n",
    "class SkillEntry(BaseModel):\n",
    "    name: str = Field(..., description=\"Skill name\")\n",
    "    category: str = Field(..., description=\"Skill category\")\n",
    "    proficiency: Literal[\"beginner\", \"intermediate\", \"advanced\", \"expert\", \"native\"] = Field(..., description=\"Proficiency level\")\n",
    "\n",
    "class CVAnalysisResult(BaseModel):\n",
    "    personal_info: PersonalInfo = Field(..., description=\"Personal details\")\n",
    "    education: List[EducationEntry] = Field(..., description=\"Education history\")\n",
    "    work_experience: List[WorkExperienceEntry] = Field(..., description=\"Work experience\")\n",
    "    technical_skills: List[SkillEntry] = Field(..., description=\"Technical skills\")\n",
    "    soft_skills: List[str] = Field(..., description=\"Soft skills\")\n",
    "    summary: str = Field(..., description=\"Professional summary\")\n",
    "    match_score: float = Field(..., ge=0, le=1, description=\"Job match score (0-1)\")\n",
    "    strengths: List[str] = Field(..., description=\"Candidate strengths for this role\")\n",
    "    improvement_areas: List[str] = Field(..., description=\"Areas needing improvement\")\n",
    "\n",
    "# --- Advanced MiniCPM-O 2.6 Integration with Language Control ---\n",
    "class ProfessionalCVAnalyzer:\n",
    "    SUPPORTED_LANGUAGES = [\"en\", \"fr\", \"es\", \"de\", \"ar\", \"zh\", \"ja\", \"ru\"]\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.model, self.tokenizer = self.initialize_model()\n",
    "        \n",
    "    def initialize_model(self):\n",
    "        \"\"\"Initialize MiniCPM-O 2.6 with multimodal capabilities\"\"\"\n",
    "        model_id = \"/teamspace/studios/this_studio/.cache/modelscope/hub/models/OpenBMB/MiniCPM-o-2_6\"\n",
    "\n",
    "        model = AutoModel.from_pretrained(\n",
    "            model_id,\n",
    "            trust_remote_code=True,\n",
    "            attn_implementation='sdpa', # sdpa or flash_attention_2\n",
    "            torch_dtype=torch.bfloat16,\n",
    "            init_vision=True,\n",
    "            init_audio=True,\n",
    "            init_tts=True\n",
    "        )\n",
    "        model = model.eval().cuda()\n",
    "\n",
    "\n",
    "        \n",
    "        tokenizer = AutoTokenizer.from_pretrained(\n",
    "            model_id,\n",
    "            trust_remote_code=True\n",
    "        )\n",
    "        \n",
    "        return model, tokenizer\n",
    "    \n",
    "    def create_prompt(self, job_description: str, language: str = \"en\") -> list:\n",
    "        \"\"\"Precision-engineered prompt with language control\"\"\"\n",
    "        if language not in self.SUPPORTED_LANGUAGES:\n",
    "            raise ValueError(f\"Unsupported language. Choose from: {', '.join(self.SUPPORTED_LANGUAGES)}\")\n",
    "        \n",
    "        schema = CVAnalysisResult.schema_json(indent=2)\n",
    "        \n",
    "        # Language-specific instructions\n",
    "        language_instructions = {\n",
    "            \"en\": \"Output language: English\",\n",
    "            \"fr\": \"Langue de sortie: Français\",\n",
    "            \"es\": \"Idioma de salida: Español\",\n",
    "            \"de\": \"Ausgabesprache: Deutsch\",\n",
    "            \"ar\": \"لغة الإخراج: العربية\",\n",
    "            \"zh\": \"输出语言: 中文\",\n",
    "            \"ja\": \"出力言語: 日本語\",\n",
    "            \"ru\": \"Язык вывода: Русский\"\n",
    "        }\n",
    "        \n",
    "        return [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": (\n",
    "                    \"## EXPERT PROFILE ##\\n\"\n",
    "                    \"Senior CV Analyst | Fortune 500 Recruitment Expert | Multilingual Specialist\\n\\n\"\n",
    "                    \n",
    "                    \"## CORE MISSION ##\\n\"\n",
    "                    \"Extract CV data and evaluate job fit with 99.8% accuracy\\n\\n\"\n",
    "                    \n",
    "                    \"## OPERATIONAL RULES ##\\n\"\n",
    "                    \"1. OCR EXTRACTION: Digitize all CV elements with pixel-perfect accuracy\\n\"\n",
    "                    \"2. STRUCTURED OUTPUT: Generate VALID JSON matching schema exactly\\n\"\n",
    "                    \"3. LANGUAGE CONTROL: All text output must be in specified language\\n\"\n",
    "                    \"4. JOB MATCHING: Critical evaluation against requirements\\n\"\n",
    "                    \"5. DATA NORMALIZATION:\\n\"\n",
    "                    \"   - Dates: MM/YYYY\\n\"\n",
    "                    \"   - Skills: Infer proficiency from context\\n\"\n",
    "                    \"   - Scores: Objective 0-1 scale\\n\"\n",
    "                    \"6. OUTPUT FORMAT: JSON between ```json markers\\n\\n\"\n",
    "                    \n",
    "                    f\"## LANGUAGE DIRECTIVE ##\\n\"\n",
    "                    f\"{language_instructions[language]}\\n\\n\"\n",
    "                    \n",
    "                    f\"## JOB DESCRIPTION ##\\n\"\n",
    "                    f\"{job_description}\\n\\n\"\n",
    "                    \n",
    "                    f\"## OUTPUT SCHEMA ##\\n\"\n",
    "                    f\"{schema}\\n\\n\"\n",
    "                    \n",
    "                    \"## EXECUTION PROTOCOL ##\\n\"\n",
    "                    \"1. Perform high-accuracy OCR\\n\"\n",
    "                    \"2. Extract structured data\\n\"\n",
    "                    \"3. Analyze job fit\\n\"\n",
    "                    \"4. Generate localized JSON output\"\n",
    "                )\n",
    "            }\n",
    "        ]\n",
    "    \n",
    "    def extract_json(self, response: str) -> dict:\n",
    "        \"\"\"Military-grade JSON extraction\"\"\"\n",
    "        # Multi-layered extraction strategy\n",
    "        patterns = [\n",
    "            r'```json(.*?)```',  # Explicit JSON marker\n",
    "            r'```(.*?)```',      # Generic code block\n",
    "            r'\\{.*\\}',           # Raw JSON object\n",
    "        ]\n",
    "        \n",
    "        for pattern in patterns:\n",
    "            match = re.search(pattern, response, re.DOTALL)\n",
    "            if match:\n",
    "                try:\n",
    "                    json_str = match.group(1).strip() if pattern != r'\\{.*\\}' else match.group(0)\n",
    "                    # Clean non-JSON content\n",
    "                    if json_str.startswith('json\\n'):\n",
    "                        json_str = json_str[5:]\n",
    "                    return json.loads(json_str)\n",
    "                except json.JSONDecodeError:\n",
    "                    continue\n",
    "        \n",
    "        # Final fallback: AI-powered repair\n",
    "        return self.ai_json_repair(response)\n",
    "    \n",
    "    def ai_json_repair(self, response: str) -> dict:\n",
    "        \"\"\"Use model intelligence to fix malformed JSON\"\"\"\n",
    "        repair_prompt = [\n",
    "            {\"role\": \"user\", \"content\": response},\n",
    "            {\"role\": \"system\", \"content\": \"Transform this text into valid JSON matching the schema. Return ONLY valid JSON.\"}\n",
    "            \n",
    "        ]\n",
    "        fixed = self.model.chat(\n",
    "            msgs=repair_prompt,\n",
    "            tokenizer=self.tokenizer,\n",
    "            #sampling=True,\n",
    "            temperature=0.1\n",
    "        )\n",
    "        try:\n",
    "            return json.loads(fixed)\n",
    "        except:\n",
    "            # Ultimate fallback: Extract first valid JSON\n",
    "            start = fixed.find('{')\n",
    "            end = fixed.rfind('}') + 1\n",
    "            return json.loads(fixed[start:end])\n",
    "    \n",
    "    def analyze(self, cv_image_path: str, job_description: str, language: str = \"en\") -> CVAnalysisResult:\n",
    "        \"\"\"End-to-end multilingual CV analysis\"\"\"\n",
    "        # Validate language\n",
    "        if language not in self.SUPPORTED_LANGUAGES:\n",
    "            raise ValueError(f\"Unsupported language '{language}'. Valid options: {', '.join(self.SUPPORTED_LANGUAGES)}\")\n",
    "        \n",
    "        # Load CV image\n",
    "        cv_image = Image.open(cv_image_path).convert('RGB')\n",
    "        \n",
    "        # Prepare multimodal input with language control\n",
    "        messages = self.create_prompt(job_description, language)\n",
    "        messages.append({\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                cv_image,\n",
    "                \"Generate professional CV analysis:\"\n",
    "            ]\n",
    "        })\n",
    "        \n",
    "        # Call MiniCPM-O 2.6 with precision tuning\n",
    "        response = self.model.chat(\n",
    "            msgs=messages,\n",
    "            tokenizer=self.tokenizer,\n",
    "            sampling=True,\n",
    "            temperature=0.3,  # Balance creativity and accuracy\n",
    "            max_new_tokens=1800,\n",
    "            top_p=0.95,\n",
    "            repetition_penalty=1.1\n",
    "        )\n",
    "        \n",
    "        # Extract and validate JSON\n",
    "        try:\n",
    "            json_data = self.extract_json(response)\n",
    "            return CVAnalysisResult(**json_data)\n",
    "        except ValidationError as e:\n",
    "            # Self-healing validation system\n",
    "            return self.handle_validation_error(json_data, e)\n",
    "    \n",
    "    def handle_validation_error(self, data: dict, error: ValidationError) -> CVAnalysisResult:\n",
    "        \"\"\"AI-powered schema correction\"\"\"\n",
    "        error_details = str(error)\n",
    "        fix_prompt = [\n",
    "            {\"role\": \"user\", \"content\": f\"Invalid JSON:\\n{json.dumps(data, indent=2)}\\n\\nErrors:\\n{error_details}\"},\n",
    "            {\"role\": \"system\", \"content\": \"Correct this JSON to strictly match the schema. Return ONLY valid JSON.\"}\n",
    "            \n",
    "        ]\n",
    "        fixed = self.model.chat(\n",
    "            msgs=fix_prompt,\n",
    "            tokenizer=self.tokenizer,\n",
    "            sampling=True,\n",
    "            temperature=0.1\n",
    "        )\n",
    "        fixed_json = self.extract_json(fixed)\n",
    "        return CVAnalysisResult(**fixed_json)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e9c34d3-38ab-480a-bb6e-5f049c562903",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Professional Usage Interface ---\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"🚀 Launching Enterprise CV Analyzer v2.0\")\n",
    "    print(\"⚙️ Initializing MiniCPM-O 2.6 with multimodal capabilities...\")\n",
    "    analyzer = ProfessionalCVAnalyzer()\n",
    "    \n",
    "    job_desc = \"\"\"\n",
    "    Senior AI Engineer Requirements:\n",
    "    - 5+ years ML production experience\n",
    "    - Expertise in Python, PyTorch, TensorFlow\n",
    "    - Cloud deployment (AWS/Azure/GCP)\n",
    "    - PhD/MS in Computer Science\n",
    "    - Publications in top AI conferences\n",
    "    - Fluent English communication\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"\\n🌍 Language Options:\", \", \".join(analyzer.SUPPORTED_LANGUAGES))\n",
    "    target_language = input(\"Select output language (default: en): \") or \"en\"\n",
    "    \n",
    "    print(f\"\\n🔍 Analyzing CV in {target_language.upper()}...\")\n",
    "    result = analyzer.analyze(\n",
    "        cv_image_path=\"1131w-uHRaEYx8dVI (1).webp\",\n",
    "        job_description=job_desc,\n",
    "        language=target_language\n",
    "    )\n",
    "    \n",
    "    # Professional result presentation\n",
    "    print(\"\\n✅ ANALYSIS COMPLETE\")\n",
    "    print(f\"📌 Candidate: {result.personal_info.full_name}\")\n",
    "    print(f\"⭐ Match Score: {result.match_score:.0%}\")\n",
    "    print(f\"📧 Contact: {result.personal_info.email or 'Not provided'}\")\n",
    "    \n",
    "    print(\"\\n🎓 Education:\")\n",
    "    for edu in result.education:\n",
    "        print(f\"- {edu.degree.capitalize()} in {edu.field_of_study}, {edu.institution} ({edu.start_year}-{edu.end_year or 'Present'})\")\n",
    "    \n",
    "    print(\"\\n💻 Technical Skills:\")\n",
    "    for skill in result.technical_skills[:5]:\n",
    "        print(f\"- {skill.name} ({skill.proficiency})\")\n",
    "    \n",
    "    print(\"\\n🌟 Key Strengths:\")\n",
    "    for strength in result.strengths[:3]:\n",
    "        print(f\"- {strength}\")\n",
    "    \n",
    "    print(\"\\n📈 Improvement Areas:\")\n",
    "    for area in result.improvement_areas:\n",
    "        print(f\"- {area}\")\n",
    "    \n",
    "    print(\"\\n💼 Professional Summary:\")\n",
    "    print(result.summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b33a96f6-32c6-4649-a6d6-ae711fcf9773",
   "metadata": {},
   "source": [
    "## VLLM inference :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0032da2f-0b48-4a44-9652-1f0697871bb9",
   "metadata": {},
   "source": [
    "you have to see the model exstance .bin or .safetensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7deedd8-e30c-4df3-a4d2-608ff0cd5ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -l /teamspace/studios/this_studio/.cache/modelscope/hub/models/OpenBMB/MiniCPM-o-2_6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71b27253-7e13-42cd-8cb9-af11230e58ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "2.7.0+cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())  # Should return True\n",
    "print(torch.__version__)  # Should match your CUDA version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed5168e7-a3a4-42d4-875f-c2a8ccffda41",
   "metadata": {},
   "source": [
    "If False, you need to reinstall PyTorch with CUDA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8db55dd-8f2f-4a3e-9c75-6d0f3865d5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip uninstall torch torchvision torchaudio -y\n",
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121  # CUDA 11.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210a4deb-11ba-4731-bb1a-33d9d37b7bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip uninstall vllm -y\n",
    "!pip install vllm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b52a1e-c0b4-48dc-bf64-8596dd0efd0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nohup vllm serve /teamspace/studios/this_studio/.cache/modelscope/hub/models/OpenBMB/MiniCPM-o-2_6/ &"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ddb214-2dee-45a2-b6f5-cab4cccf530c",
   "metadata": {},
   "source": [
    "### inference :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e188ccd-6e8a-45c8-b3ef-c1db7abc0534",
   "metadata": {},
   "source": [
    "use the following command on terminal :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb1a31e9-5164-430f-b9c8-a24eb73a7d67",
   "metadata": {},
   "source": [
    "1. trust the code :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8573501-fbc4-41ad-9d68-136e4ba035ed",
   "metadata": {},
   "source": [
    "nohup vllm serve /teamspace/studios/this_studio/.cache/modelscope/hub/models/OpenBMB/MiniCPM-o-2_6/ --trust-remote-code > vllm.log 2>&1 &"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38624ee8-cfca-4471-aa2c-6986c712ccce",
   "metadata": {},
   "source": [
    "2. Check the process:\n",
    "\n",
    "bash\n",
    "ps aux | grep vllm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5551c3c-4f52-4fc1-9ac7-d02376b85d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tail -n 30 nohup.out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd87ea8-521a-4396-8b2c-44ad0654dd3c",
   "metadata": {},
   "source": [
    "⚡ ~ ps aux | grep vllm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af802cb9-88b6-471a-a67c-426ddf5f0f87",
   "metadata": {},
   "source": [
    "3. Monitor logs:\n",
    "\n",
    "bash\n",
    "tail -f vllm.log"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddad96bf-edb9-4da4-a23d-90e00daf73af",
   "metadata": {},
   "source": [
    "You should see initialization messages like:\n",
    "\n",
    "text\n",
    "INFO:     Started server process [PID]\n",
    "INFO:     Waiting for application startup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd05d464-8d15-408e-a386-291865300148",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc236f8c-c779-4a66-95a6-cafa0151503d",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = Image.open('1131w-uHRaEYx8dVI (1).webp').convert('RGB')\n",
    "question = 'What is in the image?'\n",
    "msgs = [{'role': 'user', 'content': [image, question]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c1fa894-1b27-4dd2-ad8c-9119b074281f",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Object of type Image is not JSON serializable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m vllm_model_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/teamspace/studios/this_studio/.cache/modelscope/hub/models/OpenBMB/MiniCPM-o-2_6\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 3\u001b[0m llm_response \u001b[38;5;241m=\u001b[39m \u001b[43mrequests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpost\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhttp://localhost:8000/v1/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mvllm_model_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprompt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmsgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.3\u001b[39;49m\n\u001b[1;32m      8\u001b[0m \u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(llm_response\u001b[38;5;241m.\u001b[39mjson())\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/requests/api.py:115\u001b[0m, in \u001b[0;36mpost\u001b[0;34m(url, data, json, **kwargs)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpost\u001b[39m(url, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, json\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    104\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a POST request.\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \n\u001b[1;32m    106\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 115\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpost\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/requests/api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/requests/sessions.py:575\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    562\u001b[0m \u001b[38;5;66;03m# Create the Request.\u001b[39;00m\n\u001b[1;32m    563\u001b[0m req \u001b[38;5;241m=\u001b[39m Request(\n\u001b[1;32m    564\u001b[0m     method\u001b[38;5;241m=\u001b[39mmethod\u001b[38;5;241m.\u001b[39mupper(),\n\u001b[1;32m    565\u001b[0m     url\u001b[38;5;241m=\u001b[39murl,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    573\u001b[0m     hooks\u001b[38;5;241m=\u001b[39mhooks,\n\u001b[1;32m    574\u001b[0m )\n\u001b[0;32m--> 575\u001b[0m prep \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprepare_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    577\u001b[0m proxies \u001b[38;5;241m=\u001b[39m proxies \u001b[38;5;129;01mor\u001b[39;00m {}\n\u001b[1;32m    579\u001b[0m settings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmerge_environment_settings(\n\u001b[1;32m    580\u001b[0m     prep\u001b[38;5;241m.\u001b[39murl, proxies, stream, verify, cert\n\u001b[1;32m    581\u001b[0m )\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/requests/sessions.py:484\u001b[0m, in \u001b[0;36mSession.prepare_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    481\u001b[0m     auth \u001b[38;5;241m=\u001b[39m get_netrc_auth(request\u001b[38;5;241m.\u001b[39murl)\n\u001b[1;32m    483\u001b[0m p \u001b[38;5;241m=\u001b[39m PreparedRequest()\n\u001b[0;32m--> 484\u001b[0m \u001b[43mp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprepare\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    485\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupper\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    486\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    487\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiles\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfiles\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmerge_setting\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    491\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdict_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCaseInsensitiveDict\u001b[49m\n\u001b[1;32m    492\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmerge_setting\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmerge_setting\u001b[49m\u001b[43m(\u001b[49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    495\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcookies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmerged_cookies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    496\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhooks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmerge_hooks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhooks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhooks\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    497\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m p\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/requests/models.py:370\u001b[0m, in \u001b[0;36mPreparedRequest.prepare\u001b[0;34m(self, method, url, headers, files, data, params, auth, cookies, hooks, json)\u001b[0m\n\u001b[1;32m    368\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_headers(headers)\n\u001b[1;32m    369\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_cookies(cookies)\n\u001b[0;32m--> 370\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprepare_body\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfiles\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    371\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_auth(auth, url)\n\u001b[1;32m    373\u001b[0m \u001b[38;5;66;03m# Note that prepare_auth must be last to enable authentication schemes\u001b[39;00m\n\u001b[1;32m    374\u001b[0m \u001b[38;5;66;03m# such as OAuth to work on a fully prepared request.\u001b[39;00m\n\u001b[1;32m    375\u001b[0m \n\u001b[1;32m    376\u001b[0m \u001b[38;5;66;03m# This MUST go after prepare_auth. Authenticators could add a hook\u001b[39;00m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/requests/models.py:510\u001b[0m, in \u001b[0;36mPreparedRequest.prepare_body\u001b[0;34m(self, data, files, json)\u001b[0m\n\u001b[1;32m    507\u001b[0m content_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapplication/json\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    509\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 510\u001b[0m     body \u001b[38;5;241m=\u001b[39m \u001b[43mcomplexjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdumps\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    511\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m ve:\n\u001b[1;32m    512\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m InvalidJSONError(ve, request\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/json/__init__.py:238\u001b[0m, in \u001b[0;36mdumps\u001b[0;34m(obj, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m JSONEncoder\n\u001b[1;32m    234\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[43m    \u001b[49m\u001b[43mskipkeys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipkeys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mensure_ascii\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_ascii\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcheck_circular\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_circular\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nan\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[43m    \u001b[49m\u001b[43mseparators\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseparators\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefault\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msort_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m--> 238\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/json/encoder.py:199\u001b[0m, in \u001b[0;36mJSONEncoder.encode\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m encode_basestring(o)\n\u001b[1;32m    196\u001b[0m \u001b[38;5;66;03m# This doesn't pass the iterator directly to ''.join() because the\u001b[39;00m\n\u001b[1;32m    197\u001b[0m \u001b[38;5;66;03m# exceptions aren't as detailed.  The list call should be roughly\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;66;03m# equivalent to the PySequence_Fast that ''.join() would do.\u001b[39;00m\n\u001b[0;32m--> 199\u001b[0m chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_one_shot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(chunks, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[1;32m    201\u001b[0m     chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(chunks)\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/json/encoder.py:257\u001b[0m, in \u001b[0;36mJSONEncoder.iterencode\u001b[0;34m(self, o, _one_shot)\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    253\u001b[0m     _iterencode \u001b[38;5;241m=\u001b[39m _make_iterencode(\n\u001b[1;32m    254\u001b[0m         markers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefault, _encoder, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindent, floatstr,\n\u001b[1;32m    255\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkey_separator, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitem_separator, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msort_keys,\n\u001b[1;32m    256\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mskipkeys, _one_shot)\n\u001b[0;32m--> 257\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_iterencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/json/encoder.py:179\u001b[0m, in \u001b[0;36mJSONEncoder.default\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdefault\u001b[39m(\u001b[38;5;28mself\u001b[39m, o):\n\u001b[1;32m    161\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Implement this method in a subclass such that it returns\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;124;03m    a serializable object for ``o``, or calls the base implementation\u001b[39;00m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;124;03m    (to raise a ``TypeError``).\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    177\u001b[0m \n\u001b[1;32m    178\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 179\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mObject of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mo\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    180\u001b[0m                     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mis not JSON serializable\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: Object of type Image is not JSON serializable"
     ]
    }
   ],
   "source": [
    "vllm_model_id = \"/teamspace/studios/this_studio/.cache/modelscope/hub/models/OpenBMB/MiniCPM-o-2_6\"\n",
    "\n",
    "llm_response = requests.post(\"http://localhost:8000/v1/completions\", json={\n",
    "    \"model\": vllm_model_id,\n",
    "    \"prompt\": msgs,\n",
    "    \"max_tokens\": 1000,\n",
    "    \"temperature\": 0.3\n",
    "})\n",
    "\n",
    "print(llm_response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef5628ec-ba76-4b4b-801c-54a7fd86978c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'object': 'error', 'message': 'The model `/teamspace/studios/this_studio/.cache/modelscope/hub/models/OpenBMB/MiniCPM-o-2_6` does not exist.', 'type': 'NotFoundError', 'param': None, 'code': 404}\n"
     ]
    }
   ],
   "source": [
    "import base64\n",
    "from PIL import Image\n",
    "import io\n",
    "import requests\n",
    "\n",
    "# Load and convert the image\n",
    "image = Image.open('1131w-uHRaEYx8dVI (1).webp').convert('RGB')\n",
    "\n",
    "# Convert image to base64\n",
    "buffered = io.BytesIO()\n",
    "image.save(buffered, format=\"JPEG\")\n",
    "img_str = base64.b64encode(buffered.getvalue()).decode('utf-8')\n",
    "\n",
    "# Format your prompt\n",
    "msgs = [{\n",
    "    'role': 'user',\n",
    "    'content': [\n",
    "        {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/jpeg;base64,{img_str}\"}},\n",
    "        {\"type\": \"text\", \"text\": \"What is in the image?\"}\n",
    "    ]\n",
    "}]\n",
    "\n",
    "vllm_model_id = \"/teamspace/studios/this_studio/.cache/modelscope/hub/models/OpenBMB/MiniCPM-o-2_6\"\n",
    "# Send to vLLM OpenAI-compatible endpoint\n",
    "response = requests.post(\"http://localhost:8000/v1/chat/completions\", json={\n",
    "    \"model\": vllm_model_id,\n",
    "    \"messages\": msgs,\n",
    "    \"max_tokens\": 1000,\n",
    "    \"temperature\": 0.3\n",
    "})\n",
    "\n",
    "print(response.json())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad27266-6e04-468c-82ab-bb3e99091d0d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
