{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3b1e693-789a-46d8-9974-66204aa083a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field, ValidationError\n",
    "from typing import List, Optional, Literal\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "import torch\n",
    "from PIL import Image\n",
    "import json\n",
    "import re\n",
    "\n",
    "# --- Pydantic Models for Structured Output ---\n",
    "class PersonalInfo(BaseModel):\n",
    "    full_name: str = Field(..., description=\"Candidate's full name\")\n",
    "    email: Optional[str] = Field(None, description=\"Contact email\")\n",
    "    phone: Optional[str] = Field(None, description=\"Phone number\")\n",
    "    location: Optional[str] = Field(None, description=\"Current location\")\n",
    "    linkedin: Optional[str] = Field(None, description=\"LinkedIn URL\")\n",
    "    github: Optional[str] = Field(None, description=\"GitHub URL\")\n",
    "\n",
    "class EducationEntry(BaseModel):\n",
    "    institution: str = Field(..., description=\"School/university name\")\n",
    "    degree: Literal[\"bachelor\", \"master\", \"phd\", \"diploma\", \"certificate\", \"associate\", \"other\"] = Field(..., description=\"Degree level\")\n",
    "    field_of_study: str = Field(..., description=\"Major/specialization\")\n",
    "    start_year: int = Field(..., description=\"Start year\")\n",
    "    end_year: Optional[int] = Field(None, description=\"Graduation year\")\n",
    "\n",
    "class WorkExperienceEntry(BaseModel):\n",
    "    company: str = Field(..., description=\"Employer name\")\n",
    "    position: str = Field(..., description=\"Job title\")\n",
    "    start_date: str = Field(..., description=\"Start date (MM/YYYY)\")\n",
    "    end_date: Optional[str] = Field(None, description=\"End date (MM/YYYY or 'Present')\")\n",
    "    responsibilities: List[str] = Field(..., description=\"Key achievements\")\n",
    "\n",
    "class SkillEntry(BaseModel):\n",
    "    name: str = Field(..., description=\"Skill name\")\n",
    "    category: str = Field(..., description=\"Skill category\")\n",
    "    proficiency: Literal[\"beginner\", \"intermediate\", \"advanced\", \"expert\", \"native\"] = Field(..., description=\"Proficiency level\")\n",
    "\n",
    "class CVAnalysisResult(BaseModel):\n",
    "    personal_info: PersonalInfo = Field(..., description=\"Personal details\")\n",
    "    education: List[EducationEntry] = Field(..., description=\"Education history\")\n",
    "    work_experience: List[WorkExperienceEntry] = Field(..., description=\"Work experience\")\n",
    "    technical_skills: List[SkillEntry] = Field(..., description=\"Technical skills\")\n",
    "    soft_skills: List[str] = Field(..., description=\"Soft skills\")\n",
    "    summary: str = Field(..., description=\"Professional summary\")\n",
    "    match_score: float = Field(..., ge=0, le=1, description=\"Job match score (0-1)\")\n",
    "    strengths: List[str] = Field(..., description=\"Candidate strengths for this role\")\n",
    "    improvement_areas: List[str] = Field(..., description=\"Areas needing improvement\")\n",
    "\n",
    "# --- Advanced MiniCPM-O 2.6 Integration with Language Control ---\n",
    "class ProfessionalCVAnalyzer:\n",
    "    SUPPORTED_LANGUAGES = [\"en\", \"fr\", \"es\", \"de\", \"ar\", \"zh\", \"ja\", \"ru\"]\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.model, self.tokenizer = self.initialize_model()\n",
    "        \n",
    "    def initialize_model(self):\n",
    "        \"\"\"Initialize MiniCPM-O 2.6 with multimodal capabilities\"\"\"\n",
    "        model_id = \"/teamspace/studios/this_studio/.cache/modelscope/hub/models/OpenBMB/MiniCPM-o-2_6\"\n",
    "\n",
    "\n",
    "        model = AutoModel.from_pretrained(\n",
    "            model_id,\n",
    "            trust_remote_code=True,\n",
    "            attn_implementation='sdpa', # sdpa or flash_attention_2\n",
    "            torch_dtype=torch.bfloat16,\n",
    "            init_vision=True,\n",
    "            init_audio=True,\n",
    "            init_tts=True\n",
    "        )\n",
    "        model = model.eval().cuda()\n",
    "\n",
    "\n",
    "        \n",
    "        tokenizer = AutoTokenizer.from_pretrained(\n",
    "            model_id,\n",
    "            trust_remote_code=True\n",
    "        )\n",
    "        \n",
    "        return model, tokenizer\n",
    "    \n",
    "    def create_prompt(self, job_description: str, language: str = \"en\") -> list:\n",
    "        \"\"\"Precision-engineered prompt with language control\"\"\"\n",
    "        if language not in self.SUPPORTED_LANGUAGES:\n",
    "            raise ValueError(f\"Unsupported language. Choose from: {', '.join(self.SUPPORTED_LANGUAGES)}\")\n",
    "        \n",
    "        schema = CVAnalysisResult.schema_json(indent=2)\n",
    "        \n",
    "        # Language-specific instructions\n",
    "        language_instructions = {\n",
    "            \"en\": \"Output language: English\",\n",
    "            \"fr\": \"Langue de sortie: FranÃ§ais\",\n",
    "            \"es\": \"Idioma de salida: EspaÃ±ol\",\n",
    "            \"de\": \"Ausgabesprache: Deutsch\",\n",
    "            \"ar\": \"Ù„ØºØ© Ø§Ù„Ø¥Ø®Ø±Ø§Ø¬: Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©\",\n",
    "            \"zh\": \"è¾“å‡ºè¯­è¨€: ä¸­æ–‡\",\n",
    "            \"ja\": \"å‡ºåŠ›è¨€èªž: æ—¥æœ¬èªž\",\n",
    "            \"ru\": \"Ð¯Ð·Ñ‹Ðº Ð²Ñ‹Ð²Ð¾Ð´Ð°: Ð ÑƒÑÑÐºÐ¸Ð¹\"\n",
    "        }\n",
    "        \n",
    "        return [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": (\n",
    "                    \"## EXPERT PROFILE ##\\n\"\n",
    "                    \"Senior CV Analyst | Fortune 500 Recruitment Expert | Multilingual Specialist\\n\\n\"\n",
    "                    \n",
    "                    \"## CORE MISSION ##\\n\"\n",
    "                    \"Extract CV data and evaluate job fit with 99.8% accuracy\\n\\n\"\n",
    "                    \n",
    "                    \"## OPERATIONAL RULES ##\\n\"\n",
    "                    \"1. OCR EXTRACTION: Digitize all CV elements with pixel-perfect accuracy\\n\"\n",
    "                    \"2. STRUCTURED OUTPUT: Generate VALID JSON matching schema exactly\\n\"\n",
    "                    \"3. LANGUAGE CONTROL: All text output must be in specified language\\n\"\n",
    "                    \"4. JOB MATCHING: Critical evaluation against requirements\\n\"\n",
    "                    \"5. DATA NORMALIZATION:\\n\"\n",
    "                    \"   - Dates: MM/YYYY\\n\"\n",
    "                    \"   - Skills: Infer proficiency from context\\n\"\n",
    "                    \"   - Scores: Objective 0-1 scale\\n\"\n",
    "                    \"6. OUTPUT FORMAT: JSON between ```json markers\\n\\n\"\n",
    "                    \n",
    "                    f\"## LANGUAGE DIRECTIVE ##\\n\"\n",
    "                    f\"{language_instructions[language]}\\n\\n\"\n",
    "                    \n",
    "                    f\"## JOB DESCRIPTION ##\\n\"\n",
    "                    f\"{job_description}\\n\\n\"\n",
    "                    \n",
    "                    f\"## OUTPUT SCHEMA ##\\n\"\n",
    "                    f\"{schema}\\n\\n\"\n",
    "                    \n",
    "                    \"## EXECUTION PROTOCOL ##\\n\"\n",
    "                    \"1. Perform high-accuracy OCR\\n\"\n",
    "                    \"2. Extract structured data\\n\"\n",
    "                    \"3. Analyze job fit\\n\"\n",
    "                    \"4. Generate localized JSON output\"\n",
    "                )\n",
    "            }\n",
    "        ]\n",
    "    \n",
    "    def extract_json(self, response: str) -> dict:\n",
    "        \"\"\"Military-grade JSON extraction\"\"\"\n",
    "        # Multi-layered extraction strategy\n",
    "        patterns = [\n",
    "            r'```json(.*?)```',  # Explicit JSON marker\n",
    "            r'```(.*?)```',      # Generic code block\n",
    "            r'\\{.*\\}',           # Raw JSON object\n",
    "        ]\n",
    "        \n",
    "        for pattern in patterns:\n",
    "            match = re.search(pattern, response, re.DOTALL)\n",
    "            if match:\n",
    "                try:\n",
    "                    json_str = match.group(1).strip() if pattern != r'\\{.*\\}' else match.group(0)\n",
    "                    # Clean non-JSON content\n",
    "                    if json_str.startswith('json\\n'):\n",
    "                        json_str = json_str[5:]\n",
    "                    return json.loads(json_str)\n",
    "                except json.JSONDecodeError:\n",
    "                    continue\n",
    "        \n",
    "        # Final fallback: AI-powered repair\n",
    "        return self.ai_json_repair(response)\n",
    "    \n",
    "    def ai_json_repair(self, response: str) -> dict:\n",
    "        \"\"\"Use model intelligence to fix malformed JSON\"\"\"\n",
    "        repair_prompt = [\n",
    "            {\"role\": \"user\", \"content\": response},\n",
    "            {\"role\": \"system\", \"content\": \"Transform this text into valid JSON matching the schema. Return ONLY valid JSON.\"}\n",
    "            \n",
    "        ]\n",
    "        fixed = self.model.chat(\n",
    "            msgs=repair_prompt,\n",
    "            tokenizer=self.tokenizer,\n",
    "            #sampling=True,\n",
    "            temperature=0.1\n",
    "        )\n",
    "        try:\n",
    "            return json.loads(fixed)\n",
    "        except:\n",
    "            # Ultimate fallback: Extract first valid JSON\n",
    "            start = fixed.find('{')\n",
    "            end = fixed.rfind('}') + 1\n",
    "            return json.loads(fixed[start:end])\n",
    "    \n",
    "    def analyze(self, cv_image_path: str, job_description: str, language: str = \"en\") -> CVAnalysisResult:\n",
    "        \"\"\"End-to-end multilingual CV analysis\"\"\"\n",
    "        # Validate language\n",
    "        if language not in self.SUPPORTED_LANGUAGES:\n",
    "            raise ValueError(f\"Unsupported language '{language}'. Valid options: {', '.join(self.SUPPORTED_LANGUAGES)}\")\n",
    "        \n",
    "        # Load CV image\n",
    "        cv_image = Image.open(cv_image_path).convert('RGB')\n",
    "        \n",
    "        # Prepare multimodal input with language control\n",
    "        messages = self.create_prompt(job_description, language)\n",
    "        messages.append({\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                cv_image,\n",
    "                \"Generate professional CV analysis:\"\n",
    "            ]\n",
    "        })\n",
    "        \n",
    "        # Call MiniCPM-O 2.6 with precision tuning\n",
    "        response = self.model.chat(\n",
    "            msgs=messages,\n",
    "            tokenizer=self.tokenizer,\n",
    "            sampling=True,\n",
    "            temperature=0.3,  # Balance creativity and accuracy\n",
    "            max_new_tokens=1800,\n",
    "            top_p=0.95,\n",
    "            repetition_penalty=1.1\n",
    "        )\n",
    "        \n",
    "        # Extract and validate JSON\n",
    "        try:\n",
    "            json_data = self.extract_json(response)\n",
    "            return CVAnalysisResult(**json_data)\n",
    "        except ValidationError as e:\n",
    "            # Self-healing validation system\n",
    "            return self.handle_validation_error(json_data, e)\n",
    "    \n",
    "    def handle_validation_error(self, data: dict, error: ValidationError) -> CVAnalysisResult:\n",
    "        \"\"\"AI-powered schema correction\"\"\"\n",
    "        error_details = str(error)\n",
    "        fix_prompt = [\n",
    "            {\"role\": \"user\", \"content\": f\"Invalid JSON:\\n{json.dumps(data, indent=2)}\\n\\nErrors:\\n{error_details}\"},\n",
    "            {\"role\": \"system\", \"content\": \"Correct this JSON to strictly match the schema. Return ONLY valid JSON.\"}\n",
    "            \n",
    "        ]\n",
    "        fixed = self.model.chat(\n",
    "            msgs=fix_prompt,\n",
    "            tokenizer=self.tokenizer,\n",
    "            sampling=True,\n",
    "            temperature=0.1\n",
    "        )\n",
    "        fixed_json = self.extract_json(fixed)\n",
    "        return CVAnalysisResult(**fixed_json)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fd5280a5-325d-4251-83e9-3f47b2b75f1d",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Resampler' object has no attribute '_initialize_weights'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 9\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# to see the path you can execute the download command :\u001b[39;00m\n\u001b[1;32m      7\u001b[0m my_model_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/teamspace/studios/this_studio/.cache/modelscope/hub/models/OpenBMB/MiniCPM-o-2_6\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 9\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmy_model_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattn_implementation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msdpa\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# sdpa or flash_attention_2\u001b[39;49;00m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtorch_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbfloat16\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43minit_vision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43minit_audio\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43minit_tts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m     17\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m model \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39meval()\u001b[38;5;241m.\u001b[39mcuda()\n\u001b[1;32m     19\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(my_model_dir, trust_remote_code\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/modelscope/utils/hf_util/patcher.py:291\u001b[0m, in \u001b[0;36m_patch_pretrained_class.<locals>.get_wrapped_class.<locals>.ClassWrapper.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m file_pattern_context(kwargs, module_class, \u001b[38;5;28mcls\u001b[39m):\n\u001b[1;32m    288\u001b[0m     model_dir \u001b[38;5;241m=\u001b[39m get_model_dir(pretrained_model_name_or_path,\n\u001b[1;32m    289\u001b[0m                               \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 291\u001b[0m module_obj \u001b[38;5;241m=\u001b[39m \u001b[43mmodule_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m module_class\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAutoModel\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    295\u001b[0m     module_obj\u001b[38;5;241m.\u001b[39mmodel_dir \u001b[38;5;241m=\u001b[39m model_dir\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py:564\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    562\u001b[0m     \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mregister(config\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m, model_class, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    563\u001b[0m     model_class \u001b[38;5;241m=\u001b[39m add_generation_mixin_to_remote_model(model_class)\n\u001b[0;32m--> 564\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    565\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    566\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    567\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    568\u001b[0m     model_class \u001b[38;5;241m=\u001b[39m _get_model_class(config, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping)\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/transformers/modeling_utils.py:309\u001b[0m, in \u001b[0;36mrestore_default_torch_dtype.<locals>._wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    307\u001b[0m old_dtype \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mget_default_dtype()\n\u001b[1;32m    308\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 309\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    310\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    311\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_default_dtype(old_dtype)\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/transformers/modeling_utils.py:4574\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   4564\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype_orig \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   4565\u001b[0m         torch\u001b[38;5;241m.\u001b[39mset_default_dtype(dtype_orig)\n\u001b[1;32m   4567\u001b[0m     (\n\u001b[1;32m   4568\u001b[0m         model,\n\u001b[1;32m   4569\u001b[0m         missing_keys,\n\u001b[1;32m   4570\u001b[0m         unexpected_keys,\n\u001b[1;32m   4571\u001b[0m         mismatched_keys,\n\u001b[1;32m   4572\u001b[0m         offload_index,\n\u001b[1;32m   4573\u001b[0m         error_msgs,\n\u001b[0;32m-> 4574\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_pretrained_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4575\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4576\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4577\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheckpoint_files\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4578\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4579\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4580\u001b[0m \u001b[43m        \u001b[49m\u001b[43msharded_metadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msharded_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4581\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4582\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdisk_offload_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4583\u001b[0m \u001b[43m        \u001b[49m\u001b[43moffload_state_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_state_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4584\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4585\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhf_quantizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhf_quantizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4586\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeep_in_fp32_regex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_in_fp32_regex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4587\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice_mesh\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice_mesh\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4588\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkey_mapping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4589\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweights_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweights_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4590\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4592\u001b[0m \u001b[38;5;66;03m# record tp degree the model sharded to\u001b[39;00m\n\u001b[1;32m   4593\u001b[0m model\u001b[38;5;241m.\u001b[39m_tp_size \u001b[38;5;241m=\u001b[39m tp_size\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/transformers/modeling_utils.py:4884\u001b[0m, in \u001b[0;36mPreTrainedModel._load_pretrained_model\u001b[0;34m(cls, model, state_dict, checkpoint_files, pretrained_model_name_or_path, ignore_mismatched_sizes, sharded_metadata, device_map, disk_offload_folder, offload_state_dict, dtype, hf_quantizer, keep_in_fp32_regex, device_mesh, key_mapping, weights_only)\u001b[0m\n\u001b[1;32m   4881\u001b[0m model\u001b[38;5;241m.\u001b[39m_move_missing_keys_from_meta_to_cpu(missing_keys \u001b[38;5;241m+\u001b[39m mismatched_keys, unexpected_keys, dtype, hf_quantizer)\n\u001b[1;32m   4883\u001b[0m \u001b[38;5;66;03m# correctly initialize the missing (and potentially mismatched) keys\u001b[39;00m\n\u001b[0;32m-> 4884\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_initialize_missing_keys\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheckpoint_keys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_quantized\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4886\u001b[0m \u001b[38;5;66;03m# Set some modules to fp32 if needed\u001b[39;00m\n\u001b[1;32m   4887\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m keep_in_fp32_regex \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/transformers/modeling_utils.py:5477\u001b[0m, in \u001b[0;36mPreTrainedModel._initialize_missing_keys\u001b[0;34m(self, loaded_keys, ignore_mismatched_sizes, is_quantized)\u001b[0m\n\u001b[1;32m   5475\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minitialize_weights()\n\u001b[1;32m   5476\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 5477\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minitialize_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/transformers/modeling_utils.py:2556\u001b[0m, in \u001b[0;36mPreTrainedModel.initialize_weights\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2553\u001b[0m     torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mModule\u001b[38;5;241m.\u001b[39msmart_apply \u001b[38;5;241m=\u001b[39m smart_apply\n\u001b[1;32m   2555\u001b[0m \u001b[38;5;66;03m# Let the magic happen with this simple call\u001b[39;00m\n\u001b[0;32m-> 2556\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msmart_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_initialize_weights\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/transformers/modeling_utils.py:2547\u001b[0m, in \u001b[0;36mPreTrainedModel.initialize_weights.<locals>.smart_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m   2544\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[1;32m   2545\u001b[0m     \u001b[38;5;66;03m# We found a sub-model: recursively dispatch its own init function now!\u001b[39;00m\n\u001b[1;32m   2546\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(module, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_init_weights\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 2547\u001b[0m         module\u001b[38;5;241m.\u001b[39msmart_apply(\u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_initialize_weights\u001b[49m)\n\u001b[1;32m   2548\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2549\u001b[0m         module\u001b[38;5;241m.\u001b[39msmart_apply(fn)\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/nn/modules/module.py:1940\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1938\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[1;32m   1939\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1940\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[1;32m   1941\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1942\u001b[0m )\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Resampler' object has no attribute '_initialize_weights'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "from modelscope import AutoModel, AutoTokenizer\n",
    "\n",
    "# to see the path you can execute the download command :\n",
    "\n",
    "my_model_dir = \"/teamspace/studios/this_studio/.cache/modelscope/hub/models/OpenBMB/MiniCPM-o-2_6\"\n",
    "\n",
    "model = AutoModel.from_pretrained(\n",
    "    my_model_dir,\n",
    "    trust_remote_code=True,\n",
    "    attn_implementation='sdpa', # sdpa or flash_attention_2\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    init_vision=True,\n",
    "    init_audio=True,\n",
    "    init_tts=True\n",
    ")\n",
    "model = model.eval().cuda()\n",
    "tokenizer = AutoTokenizer.from_pretrained(my_model_dir, trust_remote_code=True)\n",
    "\n",
    "# In addition to vision-only mode, tts processor and vocos also needs to be initialized\n",
    "model.init_tts()\n",
    "\n",
    "image = Image.open('1131w-uHRaEYx8dVI (1).webp').convert('RGB')\n",
    "question = 'What is in the image?'\n",
    "msgs = [{'role': 'user', 'content': [image, question]}]\n",
    "\n",
    "res = model.chat(\n",
    "    image=None,\n",
    "    msgs=msgs,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "print(\"the response of the model is : \",res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e12dd742-8125-46ee-92cb-1566ef4fb84e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ Launching Enterprise CV Analyzer v2.0\n",
      "âš™ï¸ Initializing MiniCPM-O 2.6 with multimodal capabilities...\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Resampler' object has no attribute '_initialize_weights'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mðŸš€ Launching Enterprise CV Analyzer v2.0\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mâš™ï¸ Initializing MiniCPM-O 2.6 with multimodal capabilities...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m analyzer \u001b[38;5;241m=\u001b[39m \u001b[43mProfessionalCVAnalyzer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m job_desc \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;124mSenior AI Engineer Requirements:\u001b[39m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;124m- 5+ years ML production experience\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;124m- Fluent English communication\u001b[39m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124m\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mðŸŒ Language Options:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(analyzer\u001b[38;5;241m.\u001b[39mSUPPORTED_LANGUAGES))\n",
      "Cell \u001b[0;32mIn[6], line 53\u001b[0m, in \u001b[0;36mProfessionalCVAnalyzer.__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m---> 53\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minitialize_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[6], line 60\u001b[0m, in \u001b[0;36mProfessionalCVAnalyzer.initialize_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Initialize MiniCPM-O 2.6 with multimodal capabilities\"\"\"\u001b[39;00m\n\u001b[1;32m     57\u001b[0m model_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/teamspace/studios/this_studio/.cache/modelscope/hub/models/OpenBMB/MiniCPM-o-2_6\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 60\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattn_implementation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msdpa\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# sdpa or flash_attention_2\u001b[39;49;00m\n\u001b[1;32m     64\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtorch_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbfloat16\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m    \u001b[49m\u001b[43minit_vision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m    \u001b[49m\u001b[43minit_audio\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m    \u001b[49m\u001b[43minit_tts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m     68\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     69\u001b[0m model \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39meval()\u001b[38;5;241m.\u001b[39mcuda()\n\u001b[1;32m     73\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[1;32m     74\u001b[0m     model_id,\n\u001b[1;32m     75\u001b[0m     trust_remote_code\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     76\u001b[0m )\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py:564\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    562\u001b[0m     \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mregister(config\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m, model_class, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    563\u001b[0m     model_class \u001b[38;5;241m=\u001b[39m add_generation_mixin_to_remote_model(model_class)\n\u001b[0;32m--> 564\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    565\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    566\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    567\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    568\u001b[0m     model_class \u001b[38;5;241m=\u001b[39m _get_model_class(config, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping)\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/transformers/modeling_utils.py:309\u001b[0m, in \u001b[0;36mrestore_default_torch_dtype.<locals>._wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    307\u001b[0m old_dtype \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mget_default_dtype()\n\u001b[1;32m    308\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 309\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    310\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    311\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_default_dtype(old_dtype)\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/transformers/modeling_utils.py:4574\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   4564\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype_orig \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   4565\u001b[0m         torch\u001b[38;5;241m.\u001b[39mset_default_dtype(dtype_orig)\n\u001b[1;32m   4567\u001b[0m     (\n\u001b[1;32m   4568\u001b[0m         model,\n\u001b[1;32m   4569\u001b[0m         missing_keys,\n\u001b[1;32m   4570\u001b[0m         unexpected_keys,\n\u001b[1;32m   4571\u001b[0m         mismatched_keys,\n\u001b[1;32m   4572\u001b[0m         offload_index,\n\u001b[1;32m   4573\u001b[0m         error_msgs,\n\u001b[0;32m-> 4574\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_pretrained_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4575\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4576\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4577\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheckpoint_files\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4578\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4579\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4580\u001b[0m \u001b[43m        \u001b[49m\u001b[43msharded_metadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msharded_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4581\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4582\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdisk_offload_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4583\u001b[0m \u001b[43m        \u001b[49m\u001b[43moffload_state_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_state_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4584\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4585\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhf_quantizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhf_quantizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4586\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeep_in_fp32_regex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_in_fp32_regex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4587\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice_mesh\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice_mesh\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4588\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkey_mapping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4589\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweights_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweights_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4590\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4592\u001b[0m \u001b[38;5;66;03m# record tp degree the model sharded to\u001b[39;00m\n\u001b[1;32m   4593\u001b[0m model\u001b[38;5;241m.\u001b[39m_tp_size \u001b[38;5;241m=\u001b[39m tp_size\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/transformers/modeling_utils.py:4884\u001b[0m, in \u001b[0;36mPreTrainedModel._load_pretrained_model\u001b[0;34m(cls, model, state_dict, checkpoint_files, pretrained_model_name_or_path, ignore_mismatched_sizes, sharded_metadata, device_map, disk_offload_folder, offload_state_dict, dtype, hf_quantizer, keep_in_fp32_regex, device_mesh, key_mapping, weights_only)\u001b[0m\n\u001b[1;32m   4881\u001b[0m model\u001b[38;5;241m.\u001b[39m_move_missing_keys_from_meta_to_cpu(missing_keys \u001b[38;5;241m+\u001b[39m mismatched_keys, unexpected_keys, dtype, hf_quantizer)\n\u001b[1;32m   4883\u001b[0m \u001b[38;5;66;03m# correctly initialize the missing (and potentially mismatched) keys\u001b[39;00m\n\u001b[0;32m-> 4884\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_initialize_missing_keys\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheckpoint_keys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_quantized\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4886\u001b[0m \u001b[38;5;66;03m# Set some modules to fp32 if needed\u001b[39;00m\n\u001b[1;32m   4887\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m keep_in_fp32_regex \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/transformers/modeling_utils.py:5477\u001b[0m, in \u001b[0;36mPreTrainedModel._initialize_missing_keys\u001b[0;34m(self, loaded_keys, ignore_mismatched_sizes, is_quantized)\u001b[0m\n\u001b[1;32m   5475\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minitialize_weights()\n\u001b[1;32m   5476\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 5477\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minitialize_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/transformers/modeling_utils.py:2556\u001b[0m, in \u001b[0;36mPreTrainedModel.initialize_weights\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2553\u001b[0m     torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mModule\u001b[38;5;241m.\u001b[39msmart_apply \u001b[38;5;241m=\u001b[39m smart_apply\n\u001b[1;32m   2555\u001b[0m \u001b[38;5;66;03m# Let the magic happen with this simple call\u001b[39;00m\n\u001b[0;32m-> 2556\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msmart_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_initialize_weights\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/transformers/modeling_utils.py:2547\u001b[0m, in \u001b[0;36mPreTrainedModel.initialize_weights.<locals>.smart_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m   2544\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[1;32m   2545\u001b[0m     \u001b[38;5;66;03m# We found a sub-model: recursively dispatch its own init function now!\u001b[39;00m\n\u001b[1;32m   2546\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(module, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_init_weights\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 2547\u001b[0m         module\u001b[38;5;241m.\u001b[39msmart_apply(\u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_initialize_weights\u001b[49m)\n\u001b[1;32m   2548\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2549\u001b[0m         module\u001b[38;5;241m.\u001b[39msmart_apply(fn)\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/nn/modules/module.py:1940\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1938\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[1;32m   1939\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1940\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[1;32m   1941\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1942\u001b[0m )\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Resampler' object has no attribute '_initialize_weights'"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- Professional Usage Interface ---\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"ðŸš€ Launching Enterprise CV Analyzer v2.0\")\n",
    "    print(\"âš™ï¸ Initializing MiniCPM-O 2.6 with multimodal capabilities...\")\n",
    "    analyzer = ProfessionalCVAnalyzer()\n",
    "    \n",
    "    job_desc = \"\"\"\n",
    "    Senior AI Engineer Requirements:\n",
    "    - 5+ years ML production experience\n",
    "    - Expertise in Python, PyTorch, TensorFlow\n",
    "    - Cloud deployment (AWS/Azure/GCP)\n",
    "    - PhD/MS in Computer Science\n",
    "    - Publications in top AI conferences\n",
    "    - Fluent English communication\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"\\nðŸŒ Language Options:\", \", \".join(analyzer.SUPPORTED_LANGUAGES))\n",
    "    target_language = input(\"Select output language (default: en): \") or \"en\"\n",
    "    \n",
    "    print(f\"\\nðŸ” Analyzing CV in {target_language.upper()}...\")\n",
    "    result = analyzer.analyze(\n",
    "        cv_image_path=\"1131w-uHRaEYx8dVI (1).webp\",\n",
    "        job_description=job_desc,\n",
    "        language=target_language\n",
    "    )\n",
    "    \n",
    "    # Professional result presentation\n",
    "    print(\"\\nâœ… ANALYSIS COMPLETE\")\n",
    "    print(f\"ðŸ“Œ Candidate: {result.personal_info.full_name}\")\n",
    "    print(f\"â­ Match Score: {result.match_score:.0%}\")\n",
    "    print(f\"ðŸ“§ Contact: {result.personal_info.email or 'Not provided'}\")\n",
    "    \n",
    "    print(\"\\nðŸŽ“ Education:\")\n",
    "    for edu in result.education:\n",
    "        print(f\"- {edu.degree.capitalize()} in {edu.field_of_study}, {edu.institution} ({edu.start_year}-{edu.end_year or 'Present'})\")\n",
    "    \n",
    "    print(\"\\nðŸ’» Technical Skills:\")\n",
    "    for skill in result.technical_skills[:5]:\n",
    "        print(f\"- {skill.name} ({skill.proficiency})\")\n",
    "    \n",
    "    print(\"\\nðŸŒŸ Key Strengths:\")\n",
    "    for strength in result.strengths[:3]:\n",
    "        print(f\"- {strength}\")\n",
    "    \n",
    "    print(\"\\nðŸ“ˆ Improvement Areas:\")\n",
    "    for area in result.improvement_areas:\n",
    "        print(f\"- {area}\")\n",
    "    \n",
    "    print(\"\\nðŸ’¼ Professional Summary:\")\n",
    "    print(result.summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "950d2ac3-ced3-43e1-ba27-c77c8689e220",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
